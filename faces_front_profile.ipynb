{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ed73e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7998d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/miniconda3/envs/circuit_pruner/lib/python3.7/site-packages/torch/cuda/__init__.py:125: UserWarning: \n",
      "Tesla K40c with CUDA capability sm_35 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the Tesla K40c GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "#hardware\n",
    "device = 'cuda:0'\n",
    "\n",
    "from circuit_pruner.utils import load_config\n",
    "\n",
    "config = load_config('/mnt/data/chris/dropbox/Research-Hamblin/Projects/circuit_pruner_cvpr2022/configs/alexnet_sparse_config.py')\n",
    "model = config.model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "#general\n",
    "import torch\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from circuit_pruner.force import setup_net_for_circuit_prune, show_model_layer_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93141ec3",
   "metadata": {},
   "source": [
    "### feature target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1bf061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature target\n",
    "\n",
    "layer = 'features_8'\n",
    "unit = 150\n",
    "\n",
    "feature_targets = {layer:[unit]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856027dd",
   "metadata": {},
   "source": [
    "### general circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce0294a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "general_ranks_folder = 'circuit_ranks/alexnet_sparse/imagenet_2/actxgrad/'\n",
    "general_rank_files = os.listdir(general_ranks_folder)\n",
    "for file in general_rank_files:\n",
    "    if '_'+layer+':'+str(unit)+'_' in file:\n",
    "        print('found')\n",
    "        general_ranks = torch.load(general_ranks_folder+file)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79598b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "df = pickle.load(open('./extracted_circuits/circuit_with20force_df.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2609594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sparsity</th>\n",
       "      <th>effective_sparsity</th>\n",
       "      <th>pruned_pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40058</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40059</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-0.031949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40060</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.157514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40061</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.040685</td>\n",
       "      <td>0.382373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40062</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.097711</td>\n",
       "      <td>0.765643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40063</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.199730</td>\n",
       "      <td>0.945112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40064</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.299982</td>\n",
       "      <td>0.993931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40065</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.399933</td>\n",
       "      <td>0.999968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40066</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.499307</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40067</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.599744</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40068</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.699995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40069</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800005</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40070</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900002</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sparsity  effective_sparsity  pruned_pearson\n",
       "40058     0.001            0.000000        0.000000\n",
       "40059     0.005            0.000300       -0.031949\n",
       "40060     0.010            0.002275        0.157514\n",
       "40061     0.050            0.040685        0.382373\n",
       "40062     0.100            0.097711        0.765643\n",
       "40063     0.200            0.199730        0.945112\n",
       "40064     0.300            0.299982        0.993931\n",
       "40065     0.400            0.399933        0.999968\n",
       "40066     0.500            0.499307        1.000000\n",
       "40067     0.600            0.599744        1.000000\n",
       "40068     0.700            0.699995        1.000000\n",
       "40069     0.800            0.800005        1.000000\n",
       "40070     0.900            0.900002        1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['model']=='alexnet_sparse') & (df['layer']==layer) & (df['method']=='actxgrad') & (df['unit']==unit)][['sparsity','effective_sparsity','pruned_pearson']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e32f596d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "target sparsity: 0.4\n",
      "total params to feature: 86592\n",
      "\n",
      "kept params in original mask: 34637      (total params * sparsity)\n",
      "original mask: 495308 params\n",
      "effective mask: 495254 params\n",
      "effective_sparsity: 0.39992147080561713\n",
      "filter sparsity: 0.6545292867701404\n",
      "kernel sparsity: 0.6110062282760202\n"
     ]
    }
   ],
   "source": [
    "from circuit_pruner.extraction import model_ranks_2_circuit_model\n",
    "from circuit_pruner.utils import circuit_2_model_sparsity\n",
    "\n",
    "sparsity = .4\n",
    "\n",
    "general_circuit,general_mask = model_ranks_2_circuit_model(general_ranks,sparsity,model,\n",
    "                                                                     feature_targets,device,structure='edges',\n",
    "                                                                     use_effective_mask=True)\n",
    "\n",
    "general_circuit = general_circuit.eval().to('cpu')\n",
    "\n",
    "for l in general_mask:\n",
    "    l = l.to('cpu')\n",
    "    \n",
    "    \n",
    "circuit_feature_targets = {layer:[0]}\n",
    "\n",
    "general_circuit_sparsity_factor = circuit_2_model_sparsity(general_circuit,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462531ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39992147080561713"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_circuit_sparsity_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e6c067",
   "metadata": {},
   "source": [
    "#### feature visualization of general circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6d5550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:17<00:00, 28.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; flex-direction: row;\"><div style=\"margin-right:10px; margin-top: 4px;\">\n",
       "                            0 <br/>\n",
       "                            <img src=\"data:image/PNG;base64,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\" style=\"image-rendering: pixelated;\">\n",
       "                        </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lucent_fresh.optvis import render, param, transform, objectives   #lucent fresh is a version of lucent with some of my edits\n",
    "from lucent_fresh.modelzoo.util import get_model_layers\n",
    "\n",
    "\n",
    "#this is a bit of a hack to get visualizations to work\n",
    "\n",
    "from copy import deepcopy\n",
    "from circuit_pruner.dissected_Conv2d import dissect_model\n",
    "\n",
    "dis_general_circuit = dissect_model(deepcopy(general_circuit), store_ranks = True, device=device)\n",
    "dis_general_circuit = dis_general_circuit.to(device).eval()\n",
    "\n",
    "\n",
    "\n",
    "param_f = lambda: param.image(224)\n",
    "\n",
    "obj  = objectives.neuron(layer,0)\n",
    "\n",
    "featviz = render.render_vis(dis_general_circuit,  obj, param_f, show_inline=True) #weird hack here using the 'dissected_model' works better for neuron-wise feature visualizations, not sure why\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ac4c7",
   "metadata": {},
   "source": [
    "### Extracting Profile and Frontal Circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0067835",
   "metadata": {},
   "source": [
    "### dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16676eab",
   "metadata": {},
   "source": [
    "#### preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a7173d",
   "metadata": {},
   "source": [
    "We want our images to be 'fit' inside the receptive field of our target, we can integrate this step right into the dataloader's transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "735aa988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "        Layer (type)    map size      start       jump receptive_field \n",
      "==============================================================================\n",
      "        0             [244, 244]        0.5        1.0             1.0 \n",
      "        1               [60, 60]        3.5        4.0            11.0 \n",
      "        2               [60, 60]        3.5        4.0            11.0 \n",
      "        3               [29, 29]        7.5        8.0            19.0 \n",
      "        4               [29, 29]        7.5        8.0            51.0 \n",
      "        5               [29, 29]        7.5        8.0            51.0 \n",
      "        6               [14, 14]       15.5       16.0            67.0 \n",
      "        7               [14, 14]       15.5       16.0            99.0 \n",
      "        8               [14, 14]       15.5       16.0            99.0 \n",
      "        9               [14, 14]       15.5       16.0           131.0 \n",
      "==============================================================================\n",
      "[(30.0, 161.0), (30.0, 161.0)]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from circuit_pruner.receptive_fields import receptive_field_fit_transform\n",
    "\n",
    "target_position = [5,5]   #which location of the target filter's activation map do we want to fit these images to\n",
    "rff_transform = receptive_field_fit_transform(layer,target_position,model=general_circuit,shrinkage=.8)\n",
    "#try adding the argument \"shrinkage = .5\" above\n",
    "\n",
    "preprocess = config.preprocess\n",
    "preprocess =  transforms.Compose([preprocess,\n",
    "                                  rff_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4206ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/miniconda3/envs/circuit_pruner/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224 at 0x7F769F00EB90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "from torchvision import transforms\n",
    "\n",
    "topil = transforms.ToPILImage()\n",
    "\n",
    "img_path = '/mnt/data/chris/dropbox/Research-Hamblin/Projects/circuit_pruner_cvpr2022/image_data/faces/profile/f19_s_r.jpg'\n",
    "img = Image.open(img_path)\n",
    "img_t = preprocess(img)\n",
    "img = topil(img_t)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba697e72",
   "metadata": {},
   "source": [
    "#### dataloader classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d63f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_pruner.data_loading import rank_image_data\n",
    "from circuit_pruner.data_loading import single_image_data\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "root_faces_dir ='/mnt/data/chris/dropbox/Research-Hamblin/Projects/circuit_pruner_cvpr2022/image_data/faces/'\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True, 'sampler':None} if 'cuda' in device else {}\n",
    "\n",
    "aspects = ['front','left','right']\n",
    "\n",
    "dataloaders = {}\n",
    "\n",
    "for aspect in aspects:\n",
    "    dataloaders[aspect] = data.DataLoader(rank_image_data(root_faces_dir+aspect,preprocess),\n",
    "                                        batch_size=5,shuffle=False,**kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03cbd43",
   "metadata": {},
   "source": [
    "#### generate ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1faf5d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front\n",
      "left\n",
      "right\n"
     ]
    }
   ],
   "source": [
    "from circuit_pruner.dissected_Conv2d import set_across_model, set_model_target_node\n",
    "from circuit_pruner.dissected_Conv2d import get_ranklist_from_dissected_Conv2d_modules, clear_ranks_across_model\n",
    "from copy import deepcopy\n",
    "from circuit_pruner.dissected_Conv2d import dissect_model\n",
    "\n",
    "structure = 'kernels'\n",
    "\n",
    "ranks = {}\n",
    "\n",
    "\n",
    "for aspect in aspects:\n",
    "    print(aspect)\n",
    "    \n",
    "    rankable_model = dissect_model(deepcopy(general_circuit), dissect=True,store_ranks = True, device=device)\n",
    "    rankable_model.to(device)\n",
    "\n",
    "    set_model_target_node(rankable_model,layer,0)\n",
    "\n",
    "    set_across_model(rankable_model,'rank_field',target_position)#we want to get ranks with respect to our filters response at the target position \n",
    "\n",
    "    set_across_model(rankable_model,'absolute_rank',True)\n",
    "    \n",
    "    iter_dataloader = iter(dataloaders[aspect])\n",
    "    iters = len(iter_dataloader)\n",
    "\n",
    "    #actually extract ranks by running images through model\n",
    "    clear_ranks_across_model(rankable_model)\n",
    "\n",
    "    for it in range(iters):\n",
    "\n",
    "        inputs, label = next(iter_dataloader)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        rankable_model.zero_grad()\n",
    "\n",
    "        try:\n",
    "            outputs = rankable_model(inputs)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    ranks[aspect] = get_ranklist_from_dissected_Conv2d_modules(rankable_model)\n",
    "    \n",
    "    del rankable_model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6ecc59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_pruner.ranks import minmax_norm_ranks\n",
    "\n",
    "normed_ranks = {}\n",
    "for aspect in aspects:\n",
    "    normed_ranks[aspect] = minmax_norm_ranks(ranks[aspect])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda9ade",
   "metadata": {},
   "source": [
    "#### dataloaders with larger batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "268b0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_pruner.data_loading import rank_image_data\n",
    "from circuit_pruner.data_loading import single_image_data\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "root_faces_dir ='/mnt/data/chris/dropbox/Research-Hamblin/Projects/circuit_pruner_cvpr2022/image_data/faces/'\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True, 'sampler':None} if 'cuda' in device else {}\n",
    "\n",
    "aspects = ['front','left','right']\n",
    "\n",
    "dataloaders = {}\n",
    "\n",
    "for aspect in aspects:\n",
    "    dataloaders[aspect] = data.DataLoader(rank_image_data(root_faces_dir+aspect,preprocess),\n",
    "                                        batch_size=40,shuffle=False,**kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d305b",
   "metadata": {},
   "source": [
    "#### activation preservation as function of sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eb27fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "front\n",
      "front\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original\n",
      "features_8 effective last layer\n",
      "average orig acts:\n",
      "feature features_8:0: 21.704315185546875\n",
      "Target Sparsity: 0.9999\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9999\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34627      (total params * sparsity)\n",
      "gradients from this feature are sparse,the minimum acceptable rank at this sparsity has a score of zero! we will return a mask thats smaller than you asked, by masking all parameters with a score of zero.\n",
      "original mask: 495254 params\n",
      "effective mask: 495254 params\n",
      "effective_sparsity: 1.0\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.704315185546875\n",
      "Target Sparsity: 0.9855536231884058\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9855536231884058\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34130      (total params * sparsity)\n",
      "original mask: 490370 params\n",
      "effective mask: 490361 params\n",
      "effective_sparsity: 0.9855327750505343\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.704692840576172\n",
      "Target Sparsity: 0.9712072463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9712072463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33633      (total params * sparsity)\n",
      "original mask: 485897 params\n",
      "effective mask: 485861 params\n",
      "effective_sparsity: 0.9710944267975744\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.704620361328125\n",
      "Target Sparsity: 0.9568608695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9568608695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33137      (total params * sparsity)\n",
      "original mask: 481417 params\n",
      "effective mask: 481318 params\n",
      "effective_sparsity: 0.9565694484550967\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.782251358032227\n",
      "Target Sparsity: 0.9425144927536232\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9425144927536232\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32640      (total params * sparsity)\n",
      "original mask: 476896 params\n",
      "effective mask: 476887 params\n",
      "effective_sparsity: 0.9425064972567139\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.702960968017578\n",
      "Target Sparsity: 0.928168115942029\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.928168115942029\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32143      (total params * sparsity)\n",
      "original mask: 472327 params\n",
      "effective mask: 472165 params\n",
      "effective_sparsity: 0.9276638752526711\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.71067237854004\n",
      "Target Sparsity: 0.9138217391304349\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9138217391304349\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31646      (total params * sparsity)\n",
      "original mask: 467582 params\n",
      "effective mask: 467150 params\n",
      "effective_sparsity: 0.9124458561940514\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.710695266723633\n",
      "Target Sparsity: 0.8994753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8994753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31149      (total params * sparsity)\n",
      "original mask: 462805 params\n",
      "effective mask: 462427 params\n",
      "effective_sparsity: 0.8982673982096449\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.73611068725586\n",
      "Target Sparsity: 0.8851289855072464\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8851289855072464\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30653      (total params * sparsity)\n",
      "original mask: 457829 params\n",
      "effective mask: 457505 params\n",
      "effective_sparsity: 0.8841178169217442\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.737167358398438\n",
      "Target Sparsity: 0.8707826086956522\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8707826086956522\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30156      (total params * sparsity)\n",
      "original mask: 452812 params\n",
      "effective mask: 452272 params\n",
      "effective_sparsity: 0.86907305804216\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.970190048217773\n",
      "Target Sparsity: 0.8564362318840579\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8564362318840579\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29659      (total params * sparsity)\n",
      "original mask: 447459 params\n",
      "effective mask: 446928 params\n",
      "effective_sparsity: 0.8547502165752238\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.130212783813477\n",
      "Target Sparsity: 0.8420898550724638\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8420898550724638\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29162      (total params * sparsity)\n",
      "original mask: 442074 params\n",
      "effective mask: 441309 params\n",
      "effective_sparsity: 0.8396477043026278\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.758270263671875\n",
      "Target Sparsity: 0.8277434782608696\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8277434782608696\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28665      (total params * sparsity)\n",
      "original mask: 436625 params\n",
      "effective mask: 435905 params\n",
      "effective_sparsity: 0.8254403696217153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.755205154418945\n",
      "Target Sparsity: 0.8133971014492754\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8133971014492754\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28168      (total params * sparsity)\n",
      "original mask: 431272 params\n",
      "effective mask: 430696 params\n",
      "effective_sparsity: 0.8115506786023678\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.76797866821289\n",
      "Target Sparsity: 0.7990507246376812\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7990507246376812\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27672      (total params * sparsity)\n",
      "original mask: 425784 params\n",
      "effective mask: 425352 params\n",
      "effective_sparsity: 0.7976898642795264\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.779909133911133\n",
      "Target Sparsity: 0.784704347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.784704347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27175      (total params * sparsity)\n",
      "original mask: 420079 params\n",
      "effective mask: 419719 params\n",
      "effective_sparsity: 0.7835691596881317\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.73305320739746\n",
      "Target Sparsity: 0.7703579710144928\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7703579710144928\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26678      (total params * sparsity)\n",
      "original mask: 414198 params\n",
      "effective mask: 413964 params\n",
      "effective_sparsity: 0.7696217152757725\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.634767532348633\n",
      "Target Sparsity: 0.7560115942028985\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7560115942028985\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26181      (total params * sparsity)\n",
      "original mask: 408269 params\n",
      "effective mask: 408071 params\n",
      "effective_sparsity: 0.755385503898354\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.513002395629883\n",
      "Target Sparsity: 0.7416652173913043\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7416652173913043\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25684      (total params * sparsity)\n",
      "original mask: 402484 params\n",
      "effective mask: 402331 params\n",
      "effective_sparsity: 0.7411781692174415\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.600982666015625\n",
      "Target Sparsity: 0.7273188405797102\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7273188405797102\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25188      (total params * sparsity)\n",
      "original mask: 396532 params\n",
      "effective mask: 395992 params\n",
      "effective_sparsity: 0.7256136298007508\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.458913803100586\n",
      "Target Sparsity: 0.712972463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.712972463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24691      (total params * sparsity)\n",
      "original mask: 390603 params\n",
      "effective mask: 390153 params\n",
      "effective_sparsity: 0.7115506786023679\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.20914077758789\n",
      "Target Sparsity: 0.6986260869565217\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6986260869565217\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24194      (total params * sparsity)\n",
      "original mask: 384482 params\n",
      "effective mask: 384068 params\n",
      "effective_sparsity: 0.6973144672249495\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.688365936279297\n",
      "Target Sparsity: 0.6842797101449276\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6842797101449276\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23697      (total params * sparsity)\n",
      "original mask: 378249 params\n",
      "effective mask: 377880 params\n",
      "effective_sparsity: 0.683107132544037\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.72329330444336\n",
      "Target Sparsity: 0.6699333333333334\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6699333333333334\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23200      (total params * sparsity)\n",
      "original mask: 372080 params\n",
      "effective mask: 371585 params\n",
      "effective_sparsity: 0.668351140629512\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.41883087158203\n",
      "Target Sparsity: 0.6555869565217392\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6555869565217392\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22703      (total params * sparsity)\n",
      "original mask: 365703 params\n",
      "effective mask: 365253 params\n",
      "effective_sparsity: 0.6541438059485994\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.55532455444336\n",
      "Target Sparsity: 0.6412405797101449\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6412405797101449\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22207      (total params * sparsity)\n",
      "original mask: 359415 params\n",
      "effective mask: 359046 params\n",
      "effective_sparsity: 0.6400808547502166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.80732536315918\n",
      "Target Sparsity: 0.6268942028985507\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6268942028985507\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21710      (total params * sparsity)\n",
      "original mask: 353150 params\n",
      "effective mask: 352846 params\n",
      "effective_sparsity: 0.6259890268553278\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.100101470947266\n",
      "Target Sparsity: 0.6125478260869566\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6125478260869566\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21213      (total params * sparsity)\n",
      "original mask: 346469 params\n",
      "effective mask: 346129 params\n",
      "effective_sparsity: 0.6115218019058619\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.350872039794922\n",
      "Target Sparsity: 0.5982014492753623\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5982014492753623\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20716      (total params * sparsity)\n",
      "original mask: 340108 params\n",
      "effective mask: 339723 params\n",
      "effective_sparsity: 0.5970257002598903\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.149606704711914\n",
      "Target Sparsity: 0.5838550724637681\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5838550724637681\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20219      (total params * sparsity)\n",
      "original mask: 333507 params\n",
      "effective mask: 333149 params\n",
      "effective_sparsity: 0.582760612185966\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 23.057159423828125\n",
      "Target Sparsity: 0.569508695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.569508695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19723      (total params * sparsity)\n",
      "original mask: 326931 params\n",
      "effective mask: 326625 params\n",
      "effective_sparsity: 0.5685532775050535\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.95734977722168\n",
      "Target Sparsity: 0.5551623188405798\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5551623188405798\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19226      (total params * sparsity)\n",
      "original mask: 320346 params\n",
      "effective mask: 320058 params\n",
      "effective_sparsity: 0.5542593127346231\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.70056915283203\n",
      "Target Sparsity: 0.5408159420289855\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5408159420289855\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18729      (total params * sparsity)\n",
      "original mask: 313649 params\n",
      "effective mask: 313406 params\n",
      "effective_sparsity: 0.5400519780537106\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.59663200378418\n",
      "Target Sparsity: 0.5264695652173913\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5264695652173913\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18232      (total params * sparsity)\n",
      "original mask: 307032 params\n",
      "effective mask: 306807 params\n",
      "effective_sparsity: 0.5257580132832804\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.631710052490234\n",
      "Target Sparsity: 0.5121231884057971\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5121231884057971\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17735      (total params * sparsity)\n",
      "original mask: 300607 params\n",
      "effective mask: 300391 params\n",
      "effective_sparsity: 0.5114351718163442\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.346057891845703\n",
      "Target Sparsity: 0.49777681159420295\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.49777681159420295\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17239      (total params * sparsity)\n",
      "original mask: 293679 params\n",
      "effective mask: 293427 params\n",
      "effective_sparsity: 0.49699682356338437\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.223081588745117\n",
      "Target Sparsity: 0.4834304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4834304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16742      (total params * sparsity)\n",
      "original mask: 286726 params\n",
      "effective mask: 286429 params\n",
      "effective_sparsity: 0.48250072191741267\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.792888641357422\n",
      "Target Sparsity: 0.4690840579710145\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4690840579710145\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16245      (total params * sparsity)\n",
      "original mask: 279661 params\n",
      "effective mask: 279382 params\n",
      "effective_sparsity: 0.4682067571469824\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.469392776489258\n",
      "Target Sparsity: 0.45473768115942037\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.45473768115942037\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15748      (total params * sparsity)\n",
      "original mask: 272484 params\n",
      "effective mask: 272178 params\n",
      "effective_sparsity: 0.45376840889402253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.30923843383789\n",
      "Target Sparsity: 0.44039130434782614\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.44039130434782614\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15251      (total params * sparsity)\n",
      "original mask: 265259 params\n",
      "effective mask: 264791 params\n",
      "effective_sparsity: 0.4388969101934739\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.371479034423828\n",
      "Target Sparsity: 0.4260449275362319\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4260449275362319\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14754      (total params * sparsity)\n",
      "original mask: 257858 params\n",
      "effective mask: 257275 params\n",
      "effective_sparsity: 0.42422754836846666\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.705507278442383\n",
      "Target Sparsity: 0.4116985507246377\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4116985507246377\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14258      (total params * sparsity)\n",
      "original mask: 250818 params\n",
      "effective mask: 250199 params\n",
      "effective_sparsity: 0.4097892001155068\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.416418075561523\n",
      "Target Sparsity: 0.39735217391304345\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.39735217391304345\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13761      (total params * sparsity)\n",
      "original mask: 243257 params\n",
      "effective mask: 242683 params\n",
      "effective_sparsity: 0.3955818654345943\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.98773765563965\n",
      "Target Sparsity: 0.38300579710144933\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.38300579710144933\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13264      (total params * sparsity)\n",
      "original mask: 235840 params\n",
      "effective mask: 235356 params\n",
      "effective_sparsity: 0.38151891423621137\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.733522415161133\n",
      "Target Sparsity: 0.3686594202898551\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3686594202898551\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12767      (total params * sparsity)\n",
      "original mask: 228215 params\n",
      "effective mask: 227794 params\n",
      "effective_sparsity: 0.3673693329483107\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.79479217529297\n",
      "Target Sparsity: 0.35431304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.35431304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12270      (total params * sparsity)\n",
      "original mask: 220366 params\n",
      "effective mask: 219927 params\n",
      "effective_sparsity: 0.35295986139185676\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.211406707763672\n",
      "Target Sparsity: 0.33996666666666675\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.33996666666666675\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11774      (total params * sparsity)\n",
      "original mask: 212542 params\n",
      "effective mask: 212128 params\n",
      "effective_sparsity: 0.3386658966214265\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.99966049194336\n",
      "Target Sparsity: 0.3256202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3256202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11277      (total params * sparsity)\n",
      "original mask: 204613 params\n",
      "effective mask: 204217 params\n",
      "effective_sparsity: 0.3243719318509962\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.966676712036133\n",
      "Target Sparsity: 0.3112739130434783\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3112739130434783\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10780      (total params * sparsity)\n",
      "original mask: 196604 params\n",
      "effective mask: 196253 params\n",
      "effective_sparsity: 0.31016459717008377\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.655803680419922\n",
      "Target Sparsity: 0.29692753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.29692753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10283      (total params * sparsity)\n",
      "original mask: 188659 params\n",
      "effective mask: 188353 params\n",
      "effective_sparsity: 0.29595726248917126\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.968158721923828\n",
      "Target Sparsity: 0.28258115942028983\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.28258115942028983\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9786      (total params * sparsity)\n",
      "original mask: 180714 params\n",
      "effective mask: 180453 params\n",
      "effective_sparsity: 0.28174992780825875\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.43699073791504\n",
      "Target Sparsity: 0.2682347826086957\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2682347826086957\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9289      (total params * sparsity)\n",
      "original mask: 172609 params\n",
      "effective mask: 172321 params\n",
      "effective_sparsity: 0.2673115795552989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.220060348510742\n",
      "Target Sparsity: 0.2538884057971015\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2538884057971015\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8793      (total params * sparsity)\n",
      "original mask: 164721 params\n",
      "effective mask: 164451 params\n",
      "effective_sparsity: 0.25304649148137454\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.25502586364746\n",
      "Target Sparsity: 0.23954202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.23954202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8296      (total params * sparsity)\n",
      "original mask: 156504 params\n",
      "effective mask: 156216 params\n",
      "effective_sparsity: 0.2386370199249206\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.196168899536133\n",
      "Target Sparsity: 0.22519565217391313\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.22519565217391313\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7799      (total params * sparsity)\n",
      "original mask: 147951 params\n",
      "effective mask: 147303 params\n",
      "effective_sparsity: 0.2231302339012417\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.130573272705078\n",
      "Target Sparsity: 0.2108492753623189\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2108492753623189\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7302      (total params * sparsity)\n",
      "original mask: 139350 params\n",
      "effective mask: 138540 params\n",
      "effective_sparsity: 0.20825873520069305\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 18.342554092407227\n",
      "Target Sparsity: 0.19650289855072467\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.19650289855072467\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6805      (total params * sparsity)\n",
      "original mask: 130957 params\n",
      "effective mask: 130111 params\n",
      "effective_sparsity: 0.19379151025122726\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 17.09482765197754\n",
      "Target Sparsity: 0.18215652173913044\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.18215652173913044\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6309      (total params * sparsity)\n",
      "original mask: 122333 params\n",
      "effective mask: 121469 params\n",
      "effective_sparsity: 0.17941091539127924\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 17.296207427978516\n",
      "Target Sparsity: 0.1678101449275362\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1678101449275362\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5812      (total params * sparsity)\n",
      "original mask: 113620 params\n",
      "effective mask: 112674 params\n",
      "effective_sparsity: 0.1650014438348253\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 16.049175262451172\n",
      "Target Sparsity: 0.1534637681159421\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1534637681159421\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5315      (total params * sparsity)\n",
      "original mask: 105083 params\n",
      "effective mask: 103911 params\n",
      "effective_sparsity: 0.15012994513427663\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 15.150837898254395\n",
      "Target Sparsity: 0.13911739130434786\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.13911739130434786\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4818      (total params * sparsity)\n",
      "original mask: 96018 params\n",
      "effective mask: 94799 params\n",
      "effective_sparsity: 0.1355760900952931\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.461692810058594\n",
      "Target Sparsity: 0.12477101449275363\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.12477101449275363\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4321      (total params * sparsity)\n",
      "original mask: 87769 params\n",
      "effective mask: 86181 params\n",
      "effective_sparsity: 0.12004042737510828\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.742049217224121\n",
      "Target Sparsity: 0.11042463768115951\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.11042463768115951\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3825      (total params * sparsity)\n",
      "original mask: 78953 params\n",
      "effective mask: 76653 params\n",
      "effective_sparsity: 0.10502454519203003\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.105335235595703\n",
      "Target Sparsity: 0.09607826086956528\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.09607826086956528\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3328      (total params * sparsity)\n",
      "original mask: 69168 params\n",
      "effective mask: 66761 params\n",
      "effective_sparsity: 0.09012416979497545\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.880843162536621\n",
      "Target Sparsity: 0.08173188405797105\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.08173188405797105\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2831      (total params * sparsity)\n",
      "original mask: 60007 params\n",
      "effective mask: 57016 params\n",
      "effective_sparsity: 0.07369332948310713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.672396659851074\n",
      "Target Sparsity: 0.06738550724637682\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.06738550724637682\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2334      (total params * sparsity)\n",
      "original mask: 50222 params\n",
      "effective mask: 46281 params\n",
      "effective_sparsity: 0.057782269708345366\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.532295227050781\n",
      "Target Sparsity: 0.05303913043478259\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.05303913043478259\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1837      (total params * sparsity)\n",
      "original mask: 39893 params\n",
      "effective mask: 35803 params\n",
      "effective_sparsity: 0.043055154490326306\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 14.386983871459961\n",
      "Target Sparsity: 0.03869275362318847\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.03869275362318847\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1340      (total params * sparsity)\n",
      "original mask: 29212 params\n",
      "effective mask: 24528 params\n",
      "effective_sparsity: 0.027259601501588217\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.942841529846191\n",
      "Target Sparsity: 0.02434637681159424\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.02434637681159424\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 844      (total params * sparsity)\n",
      "original mask: 19036 params\n",
      "effective mask: 14617 params\n",
      "effective_sparsity: 0.014813745307536819\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 7.858356952667236\n",
      "Target Sparsity: 0.01\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.01\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 347      (total params * sparsity)\n",
      "original mask: 7827 params\n",
      "effective mask: 2839 params\n",
      "effective_sparsity: 0.0027432861680623736\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.3593058586120605\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "front\n",
      "left\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original\n",
      "features_8 effective last layer\n",
      "average orig acts:\n",
      "feature features_8:0: 11.71319580078125\n",
      "Target Sparsity: 0.9999\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9999\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34627      (total params * sparsity)\n",
      "gradients from this feature are sparse,the minimum acceptable rank at this sparsity has a score of zero! we will return a mask thats smaller than you asked, by masking all parameters with a score of zero.\n",
      "original mask: 495254 params\n",
      "effective mask: 495254 params\n",
      "effective_sparsity: 1.0\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.71319580078125\n",
      "Target Sparsity: 0.9855536231884058\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9855536231884058\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34130      (total params * sparsity)\n",
      "original mask: 490370 params\n",
      "effective mask: 490361 params\n",
      "effective_sparsity: 0.9855327750505343\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.700118064880371\n",
      "Target Sparsity: 0.9712072463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9712072463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33633      (total params * sparsity)\n",
      "original mask: 485897 params\n",
      "effective mask: 485861 params\n",
      "effective_sparsity: 0.9710944267975744\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.694934844970703\n",
      "Target Sparsity: 0.9568608695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9568608695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33137      (total params * sparsity)\n",
      "original mask: 481417 params\n",
      "effective mask: 481318 params\n",
      "effective_sparsity: 0.9565694484550967\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.796747207641602\n",
      "Target Sparsity: 0.9425144927536232\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9425144927536232\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32640      (total params * sparsity)\n",
      "original mask: 476896 params\n",
      "effective mask: 476887 params\n",
      "effective_sparsity: 0.9425064972567139\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.699177742004395\n",
      "Target Sparsity: 0.928168115942029\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.928168115942029\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32143      (total params * sparsity)\n",
      "original mask: 472327 params\n",
      "effective mask: 472165 params\n",
      "effective_sparsity: 0.9276638752526711\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.726778030395508\n",
      "Target Sparsity: 0.9138217391304349\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9138217391304349\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31646      (total params * sparsity)\n",
      "original mask: 467582 params\n",
      "effective mask: 467150 params\n",
      "effective_sparsity: 0.9124458561940514\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.74825382232666\n",
      "Target Sparsity: 0.8994753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8994753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31149      (total params * sparsity)\n",
      "original mask: 462805 params\n",
      "effective mask: 462427 params\n",
      "effective_sparsity: 0.8982673982096449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.88890266418457\n",
      "Target Sparsity: 0.8851289855072464\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8851289855072464\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30653      (total params * sparsity)\n",
      "original mask: 457829 params\n",
      "effective mask: 457505 params\n",
      "effective_sparsity: 0.8841178169217442\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.878700256347656\n",
      "Target Sparsity: 0.8707826086956522\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8707826086956522\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30156      (total params * sparsity)\n",
      "original mask: 452812 params\n",
      "effective mask: 452272 params\n",
      "effective_sparsity: 0.86907305804216\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.021224975585938\n",
      "Target Sparsity: 0.8564362318840579\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8564362318840579\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29659      (total params * sparsity)\n",
      "original mask: 447459 params\n",
      "effective mask: 446928 params\n",
      "effective_sparsity: 0.8547502165752238\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.982353210449219\n",
      "Target Sparsity: 0.8420898550724638\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8420898550724638\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29162      (total params * sparsity)\n",
      "original mask: 442074 params\n",
      "effective mask: 441309 params\n",
      "effective_sparsity: 0.8396477043026278\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.726813316345215\n",
      "Target Sparsity: 0.8277434782608696\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8277434782608696\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28665      (total params * sparsity)\n",
      "original mask: 436625 params\n",
      "effective mask: 435905 params\n",
      "effective_sparsity: 0.8254403696217153\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.749258041381836\n",
      "Target Sparsity: 0.8133971014492754\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8133971014492754\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28168      (total params * sparsity)\n",
      "original mask: 431272 params\n",
      "effective mask: 430696 params\n",
      "effective_sparsity: 0.8115506786023678\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.717564582824707\n",
      "Target Sparsity: 0.7990507246376812\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7990507246376812\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27672      (total params * sparsity)\n",
      "original mask: 425784 params\n",
      "effective mask: 425352 params\n",
      "effective_sparsity: 0.7976898642795264\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.745140075683594\n",
      "Target Sparsity: 0.784704347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.784704347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27175      (total params * sparsity)\n",
      "original mask: 420079 params\n",
      "effective mask: 419719 params\n",
      "effective_sparsity: 0.7835691596881317\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.658820152282715\n",
      "Target Sparsity: 0.7703579710144928\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7703579710144928\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26678      (total params * sparsity)\n",
      "original mask: 414198 params\n",
      "effective mask: 413964 params\n",
      "effective_sparsity: 0.7696217152757725\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.634132385253906\n",
      "Target Sparsity: 0.7560115942028985\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7560115942028985\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26181      (total params * sparsity)\n",
      "original mask: 408269 params\n",
      "effective mask: 408071 params\n",
      "effective_sparsity: 0.755385503898354\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.519044876098633\n",
      "Target Sparsity: 0.7416652173913043\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7416652173913043\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25684      (total params * sparsity)\n",
      "original mask: 402484 params\n",
      "effective mask: 402331 params\n",
      "effective_sparsity: 0.7411781692174415\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.616801261901855\n",
      "Target Sparsity: 0.7273188405797102\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7273188405797102\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25188      (total params * sparsity)\n",
      "original mask: 396532 params\n",
      "effective mask: 395992 params\n",
      "effective_sparsity: 0.7256136298007508\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.528133392333984\n",
      "Target Sparsity: 0.712972463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.712972463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24691      (total params * sparsity)\n",
      "original mask: 390603 params\n",
      "effective mask: 390153 params\n",
      "effective_sparsity: 0.7115506786023679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.33765697479248\n",
      "Target Sparsity: 0.6986260869565217\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6986260869565217\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24194      (total params * sparsity)\n",
      "original mask: 384482 params\n",
      "effective mask: 384068 params\n",
      "effective_sparsity: 0.6973144672249495\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.724108695983887\n",
      "Target Sparsity: 0.6842797101449276\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6842797101449276\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23697      (total params * sparsity)\n",
      "original mask: 378249 params\n",
      "effective mask: 377880 params\n",
      "effective_sparsity: 0.683107132544037\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.84053897857666\n",
      "Target Sparsity: 0.6699333333333334\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6699333333333334\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23200      (total params * sparsity)\n",
      "original mask: 372080 params\n",
      "effective mask: 371585 params\n",
      "effective_sparsity: 0.668351140629512\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.885680198669434\n",
      "Target Sparsity: 0.6555869565217392\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6555869565217392\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22703      (total params * sparsity)\n",
      "original mask: 365703 params\n",
      "effective mask: 365253 params\n",
      "effective_sparsity: 0.6541438059485994\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.022866249084473\n",
      "Target Sparsity: 0.6412405797101449\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6412405797101449\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22207      (total params * sparsity)\n",
      "original mask: 359415 params\n",
      "effective mask: 359046 params\n",
      "effective_sparsity: 0.6400808547502166\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.364947319030762\n",
      "Target Sparsity: 0.6268942028985507\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6268942028985507\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21710      (total params * sparsity)\n",
      "original mask: 353150 params\n",
      "effective mask: 352846 params\n",
      "effective_sparsity: 0.6259890268553278\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.36673641204834\n",
      "Target Sparsity: 0.6125478260869566\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6125478260869566\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21213      (total params * sparsity)\n",
      "original mask: 346469 params\n",
      "effective mask: 346129 params\n",
      "effective_sparsity: 0.6115218019058619\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.594176292419434\n",
      "Target Sparsity: 0.5982014492753623\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5982014492753623\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20716      (total params * sparsity)\n",
      "original mask: 340108 params\n",
      "effective mask: 339723 params\n",
      "effective_sparsity: 0.5970257002598903\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.337526321411133\n",
      "Target Sparsity: 0.5838550724637681\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5838550724637681\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20219      (total params * sparsity)\n",
      "original mask: 333507 params\n",
      "effective mask: 333149 params\n",
      "effective_sparsity: 0.582760612185966\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.855096817016602\n",
      "Target Sparsity: 0.569508695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.569508695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19723      (total params * sparsity)\n",
      "original mask: 326931 params\n",
      "effective mask: 326625 params\n",
      "effective_sparsity: 0.5685532775050535\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.675822257995605\n",
      "Target Sparsity: 0.5551623188405798\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5551623188405798\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19226      (total params * sparsity)\n",
      "original mask: 320346 params\n",
      "effective mask: 320058 params\n",
      "effective_sparsity: 0.5542593127346231\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.523566246032715\n",
      "Target Sparsity: 0.5408159420289855\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5408159420289855\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18729      (total params * sparsity)\n",
      "original mask: 313649 params\n",
      "effective mask: 313406 params\n",
      "effective_sparsity: 0.5400519780537106\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.473897933959961\n",
      "Target Sparsity: 0.5264695652173913\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5264695652173913\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18232      (total params * sparsity)\n",
      "original mask: 307032 params\n",
      "effective mask: 306807 params\n",
      "effective_sparsity: 0.5257580132832804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.353696823120117\n",
      "Target Sparsity: 0.5121231884057971\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5121231884057971\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17735      (total params * sparsity)\n",
      "original mask: 300607 params\n",
      "effective mask: 300391 params\n",
      "effective_sparsity: 0.5114351718163442\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.04865550994873\n",
      "Target Sparsity: 0.49777681159420295\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.49777681159420295\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17239      (total params * sparsity)\n",
      "original mask: 293679 params\n",
      "effective mask: 293427 params\n",
      "effective_sparsity: 0.49699682356338437\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.061534881591797\n",
      "Target Sparsity: 0.4834304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4834304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16742      (total params * sparsity)\n",
      "original mask: 286726 params\n",
      "effective mask: 286429 params\n",
      "effective_sparsity: 0.48250072191741267\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.734768867492676\n",
      "Target Sparsity: 0.4690840579710145\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4690840579710145\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16245      (total params * sparsity)\n",
      "original mask: 279661 params\n",
      "effective mask: 279382 params\n",
      "effective_sparsity: 0.4682067571469824\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.532915115356445\n",
      "Target Sparsity: 0.45473768115942037\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.45473768115942037\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15748      (total params * sparsity)\n",
      "original mask: 272484 params\n",
      "effective mask: 272178 params\n",
      "effective_sparsity: 0.45376840889402253\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.197746276855469\n",
      "Target Sparsity: 0.44039130434782614\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.44039130434782614\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15251      (total params * sparsity)\n",
      "original mask: 265259 params\n",
      "effective mask: 264791 params\n",
      "effective_sparsity: 0.4388969101934739\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.027098655700684\n",
      "Target Sparsity: 0.4260449275362319\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4260449275362319\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14754      (total params * sparsity)\n",
      "original mask: 257858 params\n",
      "effective mask: 257275 params\n",
      "effective_sparsity: 0.42422754836846666\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.377230644226074\n",
      "Target Sparsity: 0.4116985507246377\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4116985507246377\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14258      (total params * sparsity)\n",
      "original mask: 250818 params\n",
      "effective mask: 250199 params\n",
      "effective_sparsity: 0.4097892001155068\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.13222599029541\n",
      "Target Sparsity: 0.39735217391304345\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.39735217391304345\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13761      (total params * sparsity)\n",
      "original mask: 243257 params\n",
      "effective mask: 242683 params\n",
      "effective_sparsity: 0.3955818654345943\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.628249168395996\n",
      "Target Sparsity: 0.38300579710144933\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.38300579710144933\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13264      (total params * sparsity)\n",
      "original mask: 235840 params\n",
      "effective mask: 235356 params\n",
      "effective_sparsity: 0.38151891423621137\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.190458297729492\n",
      "Target Sparsity: 0.3686594202898551\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3686594202898551\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12767      (total params * sparsity)\n",
      "original mask: 228215 params\n",
      "effective mask: 227794 params\n",
      "effective_sparsity: 0.3673693329483107\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.080079078674316\n",
      "Target Sparsity: 0.35431304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.35431304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12270      (total params * sparsity)\n",
      "original mask: 220366 params\n",
      "effective mask: 219927 params\n",
      "effective_sparsity: 0.35295986139185676\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.665339469909668\n",
      "Target Sparsity: 0.33996666666666675\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.33996666666666675\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11774      (total params * sparsity)\n",
      "original mask: 212542 params\n",
      "effective mask: 212128 params\n",
      "effective_sparsity: 0.3386658966214265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.077574729919434\n",
      "Target Sparsity: 0.3256202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3256202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11277      (total params * sparsity)\n",
      "original mask: 204613 params\n",
      "effective mask: 204217 params\n",
      "effective_sparsity: 0.3243719318509962\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.978389739990234\n",
      "Target Sparsity: 0.3112739130434783\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3112739130434783\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10780      (total params * sparsity)\n",
      "original mask: 196604 params\n",
      "effective mask: 196253 params\n",
      "effective_sparsity: 0.31016459717008377\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.601156234741211\n",
      "Target Sparsity: 0.29692753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.29692753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10283      (total params * sparsity)\n",
      "original mask: 188659 params\n",
      "effective mask: 188353 params\n",
      "effective_sparsity: 0.29595726248917126\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.022706031799316\n",
      "Target Sparsity: 0.28258115942028983\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.28258115942028983\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9786      (total params * sparsity)\n",
      "original mask: 180714 params\n",
      "effective mask: 180453 params\n",
      "effective_sparsity: 0.28174992780825875\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.212014198303223\n",
      "Target Sparsity: 0.2682347826086957\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2682347826086957\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9289      (total params * sparsity)\n",
      "original mask: 172609 params\n",
      "effective mask: 172321 params\n",
      "effective_sparsity: 0.2673115795552989\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.774853706359863\n",
      "Target Sparsity: 0.2538884057971015\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2538884057971015\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8793      (total params * sparsity)\n",
      "original mask: 164721 params\n",
      "effective mask: 164451 params\n",
      "effective_sparsity: 0.25304649148137454\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.504048347473145\n",
      "Target Sparsity: 0.23954202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.23954202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8296      (total params * sparsity)\n",
      "original mask: 156504 params\n",
      "effective mask: 156216 params\n",
      "effective_sparsity: 0.2386370199249206\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.86440658569336\n",
      "Target Sparsity: 0.22519565217391313\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.22519565217391313\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7799      (total params * sparsity)\n",
      "original mask: 147951 params\n",
      "effective mask: 147303 params\n",
      "effective_sparsity: 0.2231302339012417\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.569184303283691\n",
      "Target Sparsity: 0.2108492753623189\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2108492753623189\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7302      (total params * sparsity)\n",
      "original mask: 139350 params\n",
      "effective mask: 138540 params\n",
      "effective_sparsity: 0.20825873520069305\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.445953369140625\n",
      "Target Sparsity: 0.19650289855072467\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.19650289855072467\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6805      (total params * sparsity)\n",
      "original mask: 130957 params\n",
      "effective mask: 130111 params\n",
      "effective_sparsity: 0.19379151025122726\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 7.290927410125732\n",
      "Target Sparsity: 0.18215652173913044\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.18215652173913044\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6309      (total params * sparsity)\n",
      "original mask: 122333 params\n",
      "effective mask: 121469 params\n",
      "effective_sparsity: 0.17941091539127924\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 7.338541507720947\n",
      "Target Sparsity: 0.1678101449275362\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1678101449275362\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5812      (total params * sparsity)\n",
      "original mask: 113620 params\n",
      "effective mask: 112674 params\n",
      "effective_sparsity: 0.1650014438348253\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.816221237182617\n",
      "Target Sparsity: 0.1534637681159421\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1534637681159421\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5315      (total params * sparsity)\n",
      "original mask: 105083 params\n",
      "effective mask: 103911 params\n",
      "effective_sparsity: 0.15012994513427663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.027097702026367\n",
      "Target Sparsity: 0.13911739130434786\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.13911739130434786\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4818      (total params * sparsity)\n",
      "original mask: 96018 params\n",
      "effective mask: 94799 params\n",
      "effective_sparsity: 0.1355760900952931\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.975279808044434\n",
      "Target Sparsity: 0.12477101449275363\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.12477101449275363\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4321      (total params * sparsity)\n",
      "original mask: 87769 params\n",
      "effective mask: 86181 params\n",
      "effective_sparsity: 0.12004042737510828\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.467512607574463\n",
      "Target Sparsity: 0.11042463768115951\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.11042463768115951\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3825      (total params * sparsity)\n",
      "original mask: 78953 params\n",
      "effective mask: 76653 params\n",
      "effective_sparsity: 0.10502454519203003\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.259450435638428\n",
      "Target Sparsity: 0.09607826086956528\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.09607826086956528\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3328      (total params * sparsity)\n",
      "original mask: 69168 params\n",
      "effective mask: 66761 params\n",
      "effective_sparsity: 0.09012416979497545\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.908347129821777\n",
      "Target Sparsity: 0.08173188405797105\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.08173188405797105\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2831      (total params * sparsity)\n",
      "original mask: 60007 params\n",
      "effective mask: 57016 params\n",
      "effective_sparsity: 0.07369332948310713\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.758863925933838\n",
      "Target Sparsity: 0.06738550724637682\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.06738550724637682\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2334      (total params * sparsity)\n",
      "original mask: 50222 params\n",
      "effective mask: 46281 params\n",
      "effective_sparsity: 0.057782269708345366\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.851020812988281\n",
      "Target Sparsity: 0.05303913043478259\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.05303913043478259\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1837      (total params * sparsity)\n",
      "original mask: 39893 params\n",
      "effective mask: 35803 params\n",
      "effective_sparsity: 0.043055154490326306\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.685554504394531\n",
      "Target Sparsity: 0.03869275362318847\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.03869275362318847\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1340      (total params * sparsity)\n",
      "original mask: 29212 params\n",
      "effective mask: 24528 params\n",
      "effective_sparsity: 0.027259601501588217\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.669006824493408\n",
      "Target Sparsity: 0.02434637681159424\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.02434637681159424\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 844      (total params * sparsity)\n",
      "original mask: 19036 params\n",
      "effective mask: 14617 params\n",
      "effective_sparsity: 0.014813745307536819\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.801717281341553\n",
      "Target Sparsity: 0.01\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.01\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 347      (total params * sparsity)\n",
      "original mask: 7827 params\n",
      "effective mask: 2839 params\n",
      "effective_sparsity: 0.0027432861680623736\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.50007963180542\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "front\n",
      "right\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original\n",
      "features_8 effective last layer\n",
      "average orig acts:\n",
      "feature features_8:0: 10.785665512084961\n",
      "Target Sparsity: 0.9999\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9999\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34627      (total params * sparsity)\n",
      "gradients from this feature are sparse,the minimum acceptable rank at this sparsity has a score of zero! we will return a mask thats smaller than you asked, by masking all parameters with a score of zero.\n",
      "original mask: 495254 params\n",
      "effective mask: 495254 params\n",
      "effective_sparsity: 1.0\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.785665512084961\n",
      "Target Sparsity: 0.9855536231884058\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9855536231884058\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34130      (total params * sparsity)\n",
      "original mask: 490370 params\n",
      "effective mask: 490361 params\n",
      "effective_sparsity: 0.9855327750505343\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.780518531799316\n",
      "Target Sparsity: 0.9712072463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9712072463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33633      (total params * sparsity)\n",
      "original mask: 485897 params\n",
      "effective mask: 485861 params\n",
      "effective_sparsity: 0.9710944267975744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.772506713867188\n",
      "Target Sparsity: 0.9568608695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9568608695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33137      (total params * sparsity)\n",
      "original mask: 481417 params\n",
      "effective mask: 481318 params\n",
      "effective_sparsity: 0.9565694484550967\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.866493225097656\n",
      "Target Sparsity: 0.9425144927536232\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9425144927536232\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32640      (total params * sparsity)\n",
      "original mask: 476896 params\n",
      "effective mask: 476887 params\n",
      "effective_sparsity: 0.9425064972567139\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.756233215332031\n",
      "Target Sparsity: 0.928168115942029\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.928168115942029\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32143      (total params * sparsity)\n",
      "original mask: 472327 params\n",
      "effective mask: 472165 params\n",
      "effective_sparsity: 0.9276638752526711\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.77548885345459\n",
      "Target Sparsity: 0.9138217391304349\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9138217391304349\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31646      (total params * sparsity)\n",
      "original mask: 467582 params\n",
      "effective mask: 467150 params\n",
      "effective_sparsity: 0.9124458561940514\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.75626277923584\n",
      "Target Sparsity: 0.8994753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8994753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31149      (total params * sparsity)\n",
      "original mask: 462805 params\n",
      "effective mask: 462427 params\n",
      "effective_sparsity: 0.8982673982096449\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.816488265991211\n",
      "Target Sparsity: 0.8851289855072464\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8851289855072464\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30653      (total params * sparsity)\n",
      "original mask: 457829 params\n",
      "effective mask: 457505 params\n",
      "effective_sparsity: 0.8841178169217442\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.831539154052734\n",
      "Target Sparsity: 0.8707826086956522\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8707826086956522\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30156      (total params * sparsity)\n",
      "original mask: 452812 params\n",
      "effective mask: 452272 params\n",
      "effective_sparsity: 0.86907305804216\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.146224975585938\n",
      "Target Sparsity: 0.8564362318840579\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8564362318840579\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29659      (total params * sparsity)\n",
      "original mask: 447459 params\n",
      "effective mask: 446928 params\n",
      "effective_sparsity: 0.8547502165752238\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.296257972717285\n",
      "Target Sparsity: 0.8420898550724638\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8420898550724638\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29162      (total params * sparsity)\n",
      "original mask: 442074 params\n",
      "effective mask: 441309 params\n",
      "effective_sparsity: 0.8396477043026278\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.911376953125\n",
      "Target Sparsity: 0.8277434782608696\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8277434782608696\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28665      (total params * sparsity)\n",
      "original mask: 436625 params\n",
      "effective mask: 435905 params\n",
      "effective_sparsity: 0.8254403696217153\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.796930313110352\n",
      "Target Sparsity: 0.8133971014492754\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8133971014492754\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28168      (total params * sparsity)\n",
      "original mask: 431272 params\n",
      "effective mask: 430696 params\n",
      "effective_sparsity: 0.8115506786023678\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.79159164428711\n",
      "Target Sparsity: 0.7990507246376812\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7990507246376812\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27672      (total params * sparsity)\n",
      "original mask: 425784 params\n",
      "effective mask: 425352 params\n",
      "effective_sparsity: 0.7976898642795264\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.740482330322266\n",
      "Target Sparsity: 0.784704347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.784704347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27175      (total params * sparsity)\n",
      "original mask: 420079 params\n",
      "effective mask: 419719 params\n",
      "effective_sparsity: 0.7835691596881317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.711846351623535\n",
      "Target Sparsity: 0.7703579710144928\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7703579710144928\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26678      (total params * sparsity)\n",
      "original mask: 414198 params\n",
      "effective mask: 413964 params\n",
      "effective_sparsity: 0.7696217152757725\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.705656051635742\n",
      "Target Sparsity: 0.7560115942028985\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7560115942028985\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26181      (total params * sparsity)\n",
      "original mask: 408269 params\n",
      "effective mask: 408071 params\n",
      "effective_sparsity: 0.755385503898354\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.647984504699707\n",
      "Target Sparsity: 0.7416652173913043\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7416652173913043\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25684      (total params * sparsity)\n",
      "original mask: 402484 params\n",
      "effective mask: 402331 params\n",
      "effective_sparsity: 0.7411781692174415\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.735783576965332\n",
      "Target Sparsity: 0.7273188405797102\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7273188405797102\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25188      (total params * sparsity)\n",
      "original mask: 396532 params\n",
      "effective mask: 395992 params\n",
      "effective_sparsity: 0.7256136298007508\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.548413276672363\n",
      "Target Sparsity: 0.712972463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.712972463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24691      (total params * sparsity)\n",
      "original mask: 390603 params\n",
      "effective mask: 390153 params\n",
      "effective_sparsity: 0.7115506786023679\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.276607513427734\n",
      "Target Sparsity: 0.6986260869565217\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6986260869565217\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24194      (total params * sparsity)\n",
      "original mask: 384482 params\n",
      "effective mask: 384068 params\n",
      "effective_sparsity: 0.6973144672249495\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.56903076171875\n",
      "Target Sparsity: 0.6842797101449276\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6842797101449276\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23697      (total params * sparsity)\n",
      "original mask: 378249 params\n",
      "effective mask: 377880 params\n",
      "effective_sparsity: 0.683107132544037\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.664519309997559\n",
      "Target Sparsity: 0.6699333333333334\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6699333333333334\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23200      (total params * sparsity)\n",
      "original mask: 372080 params\n",
      "effective mask: 371585 params\n",
      "effective_sparsity: 0.668351140629512\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.841489791870117\n",
      "Target Sparsity: 0.6555869565217392\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6555869565217392\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22703      (total params * sparsity)\n",
      "original mask: 365703 params\n",
      "effective mask: 365253 params\n",
      "effective_sparsity: 0.6541438059485994\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.949023246765137\n",
      "Target Sparsity: 0.6412405797101449\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6412405797101449\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22207      (total params * sparsity)\n",
      "original mask: 359415 params\n",
      "effective mask: 359046 params\n",
      "effective_sparsity: 0.6400808547502166\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.246320724487305\n",
      "Target Sparsity: 0.6268942028985507\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6268942028985507\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21710      (total params * sparsity)\n",
      "original mask: 353150 params\n",
      "effective mask: 352846 params\n",
      "effective_sparsity: 0.6259890268553278\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.50806713104248\n",
      "Target Sparsity: 0.6125478260869566\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6125478260869566\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21213      (total params * sparsity)\n",
      "original mask: 346469 params\n",
      "effective mask: 346129 params\n",
      "effective_sparsity: 0.6115218019058619\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.792723655700684\n",
      "Target Sparsity: 0.5982014492753623\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5982014492753623\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20716      (total params * sparsity)\n",
      "original mask: 340108 params\n",
      "effective mask: 339723 params\n",
      "effective_sparsity: 0.5970257002598903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.634810447692871\n",
      "Target Sparsity: 0.5838550724637681\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5838550724637681\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20219      (total params * sparsity)\n",
      "original mask: 333507 params\n",
      "effective mask: 333149 params\n",
      "effective_sparsity: 0.582760612185966\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.917614936828613\n",
      "Target Sparsity: 0.569508695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.569508695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19723      (total params * sparsity)\n",
      "original mask: 326931 params\n",
      "effective mask: 326625 params\n",
      "effective_sparsity: 0.5685532775050535\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.895918846130371\n",
      "Target Sparsity: 0.5551623188405798\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5551623188405798\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19226      (total params * sparsity)\n",
      "original mask: 320346 params\n",
      "effective mask: 320058 params\n",
      "effective_sparsity: 0.5542593127346231\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.589489936828613\n",
      "Target Sparsity: 0.5408159420289855\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5408159420289855\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18729      (total params * sparsity)\n",
      "original mask: 313649 params\n",
      "effective mask: 313406 params\n",
      "effective_sparsity: 0.5400519780537106\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.605649948120117\n",
      "Target Sparsity: 0.5264695652173913\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5264695652173913\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18232      (total params * sparsity)\n",
      "original mask: 307032 params\n",
      "effective mask: 306807 params\n",
      "effective_sparsity: 0.5257580132832804\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.560084342956543\n",
      "Target Sparsity: 0.5121231884057971\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5121231884057971\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17735      (total params * sparsity)\n",
      "original mask: 300607 params\n",
      "effective mask: 300391 params\n",
      "effective_sparsity: 0.5114351718163442\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.315268516540527\n",
      "Target Sparsity: 0.49777681159420295\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.49777681159420295\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17239      (total params * sparsity)\n",
      "original mask: 293679 params\n",
      "effective mask: 293427 params\n",
      "effective_sparsity: 0.49699682356338437\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.347806930541992\n",
      "Target Sparsity: 0.4834304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4834304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16742      (total params * sparsity)\n",
      "original mask: 286726 params\n",
      "effective mask: 286429 params\n",
      "effective_sparsity: 0.48250072191741267\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.041899681091309\n",
      "Target Sparsity: 0.4690840579710145\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4690840579710145\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16245      (total params * sparsity)\n",
      "original mask: 279661 params\n",
      "effective mask: 279382 params\n",
      "effective_sparsity: 0.4682067571469824\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.797768592834473\n",
      "Target Sparsity: 0.45473768115942037\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.45473768115942037\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15748      (total params * sparsity)\n",
      "original mask: 272484 params\n",
      "effective mask: 272178 params\n",
      "effective_sparsity: 0.45376840889402253\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.595585823059082\n",
      "Target Sparsity: 0.44039130434782614\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.44039130434782614\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15251      (total params * sparsity)\n",
      "original mask: 265259 params\n",
      "effective mask: 264791 params\n",
      "effective_sparsity: 0.4388969101934739\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.539934158325195\n",
      "Target Sparsity: 0.4260449275362319\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4260449275362319\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14754      (total params * sparsity)\n",
      "original mask: 257858 params\n",
      "effective mask: 257275 params\n",
      "effective_sparsity: 0.42422754836846666\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.860089302062988\n",
      "Target Sparsity: 0.4116985507246377\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4116985507246377\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14258      (total params * sparsity)\n",
      "original mask: 250818 params\n",
      "effective mask: 250199 params\n",
      "effective_sparsity: 0.4097892001155068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.583395957946777\n",
      "Target Sparsity: 0.39735217391304345\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.39735217391304345\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13761      (total params * sparsity)\n",
      "original mask: 243257 params\n",
      "effective mask: 242683 params\n",
      "effective_sparsity: 0.3955818654345943\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.210627555847168\n",
      "Target Sparsity: 0.38300579710144933\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.38300579710144933\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13264      (total params * sparsity)\n",
      "original mask: 235840 params\n",
      "effective mask: 235356 params\n",
      "effective_sparsity: 0.38151891423621137\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.038207054138184\n",
      "Target Sparsity: 0.3686594202898551\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3686594202898551\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12767      (total params * sparsity)\n",
      "original mask: 228215 params\n",
      "effective mask: 227794 params\n",
      "effective_sparsity: 0.3673693329483107\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.018261909484863\n",
      "Target Sparsity: 0.35431304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.35431304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12270      (total params * sparsity)\n",
      "original mask: 220366 params\n",
      "effective mask: 219927 params\n",
      "effective_sparsity: 0.35295986139185676\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.580302238464355\n",
      "Target Sparsity: 0.33996666666666675\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.33996666666666675\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11774      (total params * sparsity)\n",
      "original mask: 212542 params\n",
      "effective mask: 212128 params\n",
      "effective_sparsity: 0.3386658966214265\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.9711332321167\n",
      "Target Sparsity: 0.3256202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3256202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11277      (total params * sparsity)\n",
      "original mask: 204613 params\n",
      "effective mask: 204217 params\n",
      "effective_sparsity: 0.3243719318509962\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.933265686035156\n",
      "Target Sparsity: 0.3112739130434783\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3112739130434783\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10780      (total params * sparsity)\n",
      "original mask: 196604 params\n",
      "effective mask: 196253 params\n",
      "effective_sparsity: 0.31016459717008377\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.412734985351562\n",
      "Target Sparsity: 0.29692753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.29692753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10283      (total params * sparsity)\n",
      "original mask: 188659 params\n",
      "effective mask: 188353 params\n",
      "effective_sparsity: 0.29595726248917126\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.05755615234375\n",
      "Target Sparsity: 0.28258115942028983\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.28258115942028983\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9786      (total params * sparsity)\n",
      "original mask: 180714 params\n",
      "effective mask: 180453 params\n",
      "effective_sparsity: 0.28174992780825875\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.102376937866211\n",
      "Target Sparsity: 0.2682347826086957\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2682347826086957\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9289      (total params * sparsity)\n",
      "original mask: 172609 params\n",
      "effective mask: 172321 params\n",
      "effective_sparsity: 0.2673115795552989\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.80164623260498\n",
      "Target Sparsity: 0.2538884057971015\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2538884057971015\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8793      (total params * sparsity)\n",
      "original mask: 164721 params\n",
      "effective mask: 164451 params\n",
      "effective_sparsity: 0.25304649148137454\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.81423282623291\n",
      "Target Sparsity: 0.23954202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.23954202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8296      (total params * sparsity)\n",
      "original mask: 156504 params\n",
      "effective mask: 156216 params\n",
      "effective_sparsity: 0.2386370199249206\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.198097229003906\n",
      "Target Sparsity: 0.22519565217391313\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.22519565217391313\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7799      (total params * sparsity)\n",
      "original mask: 147951 params\n",
      "effective mask: 147303 params\n",
      "effective_sparsity: 0.2231302339012417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.43397045135498\n",
      "Target Sparsity: 0.2108492753623189\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2108492753623189\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7302      (total params * sparsity)\n",
      "original mask: 139350 params\n",
      "effective mask: 138540 params\n",
      "effective_sparsity: 0.20825873520069305\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 7.773024082183838\n",
      "Target Sparsity: 0.19650289855072467\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.19650289855072467\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6805      (total params * sparsity)\n",
      "original mask: 130957 params\n",
      "effective mask: 130111 params\n",
      "effective_sparsity: 0.19379151025122726\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.965847015380859\n",
      "Target Sparsity: 0.18215652173913044\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.18215652173913044\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6309      (total params * sparsity)\n",
      "original mask: 122333 params\n",
      "effective mask: 121469 params\n",
      "effective_sparsity: 0.17941091539127924\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 7.678413391113281\n",
      "Target Sparsity: 0.1678101449275362\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1678101449275362\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5812      (total params * sparsity)\n",
      "original mask: 113620 params\n",
      "effective mask: 112674 params\n",
      "effective_sparsity: 0.1650014438348253\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.73649263381958\n",
      "Target Sparsity: 0.1534637681159421\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1534637681159421\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5315      (total params * sparsity)\n",
      "original mask: 105083 params\n",
      "effective mask: 103911 params\n",
      "effective_sparsity: 0.15012994513427663\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.532543659210205\n",
      "Target Sparsity: 0.13911739130434786\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.13911739130434786\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4818      (total params * sparsity)\n",
      "original mask: 96018 params\n",
      "effective mask: 94799 params\n",
      "effective_sparsity: 0.1355760900952931\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.692145347595215\n",
      "Target Sparsity: 0.12477101449275363\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.12477101449275363\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4321      (total params * sparsity)\n",
      "original mask: 87769 params\n",
      "effective mask: 86181 params\n",
      "effective_sparsity: 0.12004042737510828\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 3.7929775714874268\n",
      "Target Sparsity: 0.11042463768115951\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.11042463768115951\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3825      (total params * sparsity)\n",
      "original mask: 78953 params\n",
      "effective mask: 76653 params\n",
      "effective_sparsity: 0.10502454519203003\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 3.910109281539917\n",
      "Target Sparsity: 0.09607826086956528\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.09607826086956528\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3328      (total params * sparsity)\n",
      "original mask: 69168 params\n",
      "effective mask: 66761 params\n",
      "effective_sparsity: 0.09012416979497545\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.3502397537231445\n",
      "Target Sparsity: 0.08173188405797105\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.08173188405797105\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2831      (total params * sparsity)\n",
      "original mask: 60007 params\n",
      "effective mask: 57016 params\n",
      "effective_sparsity: 0.07369332948310713\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.900201797485352\n",
      "Target Sparsity: 0.06738550724637682\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.06738550724637682\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2334      (total params * sparsity)\n",
      "original mask: 50222 params\n",
      "effective mask: 46281 params\n",
      "effective_sparsity: 0.057782269708345366\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.684245586395264\n",
      "Target Sparsity: 0.05303913043478259\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.05303913043478259\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1837      (total params * sparsity)\n",
      "original mask: 39893 params\n",
      "effective mask: 35803 params\n",
      "effective_sparsity: 0.043055154490326306\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.839052200317383\n",
      "Target Sparsity: 0.03869275362318847\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.03869275362318847\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1340      (total params * sparsity)\n",
      "original mask: 29212 params\n",
      "effective mask: 24528 params\n",
      "effective_sparsity: 0.027259601501588217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.630640029907227\n",
      "Target Sparsity: 0.02434637681159424\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.02434637681159424\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 844      (total params * sparsity)\n",
      "original mask: 19036 params\n",
      "effective mask: 14617 params\n",
      "effective_sparsity: 0.014813745307536819\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.691299915313721\n",
      "Target Sparsity: 0.01\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.01\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 347      (total params * sparsity)\n",
      "original mask: 7827 params\n",
      "effective mask: 2839 params\n",
      "effective_sparsity: 0.0027432861680623736\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.673127174377441\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "left\n",
      "front\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original\n",
      "features_8 effective last layer\n",
      "average orig acts:\n",
      "feature features_8:0: 21.704315185546875\n",
      "Target Sparsity: 0.9999\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9999\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34627      (total params * sparsity)\n",
      "gradients from this feature are sparse,the minimum acceptable rank at this sparsity has a score of zero! we will return a mask thats smaller than you asked, by masking all parameters with a score of zero.\n",
      "original mask: 495254 params\n",
      "effective mask: 495254 params\n",
      "effective_sparsity: 1.0\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.704315185546875\n",
      "Target Sparsity: 0.9855536231884058\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9855536231884058\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34130      (total params * sparsity)\n",
      "original mask: 490690 params\n",
      "effective mask: 490681 params\n",
      "effective_sparsity: 0.9855327750505343\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.704341888427734\n",
      "Target Sparsity: 0.9712072463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9712072463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33633      (total params * sparsity)\n",
      "original mask: 485929 params\n",
      "effective mask: 485884 params\n",
      "effective_sparsity: 0.9710655501010684\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.72843360900879\n",
      "Target Sparsity: 0.9568608695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9568608695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33137      (total params * sparsity)\n",
      "original mask: 481321 params\n",
      "effective mask: 481303 params\n",
      "effective_sparsity: 0.9568293387236501\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.72062873840332\n",
      "Target Sparsity: 0.9425144927536232\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9425144927536232\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32640      (total params * sparsity)\n",
      "original mask: 476592 params\n",
      "effective mask: 476583 params\n",
      "effective_sparsity: 0.9425064972567139\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.714345932006836\n",
      "Target Sparsity: 0.928168115942029\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.928168115942029\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32143      (total params * sparsity)\n",
      "original mask: 471895 params\n",
      "effective mask: 471886 params\n",
      "effective_sparsity: 0.9281547790932717\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.713266372680664\n",
      "Target Sparsity: 0.9138217391304349\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9138217391304349\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31646      (total params * sparsity)\n",
      "original mask: 466974 params\n",
      "effective mask: 466965 params\n",
      "effective_sparsity: 0.9138030609298297\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.726205825805664\n",
      "Target Sparsity: 0.8994753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8994753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31149      (total params * sparsity)\n",
      "original mask: 461813 params\n",
      "effective mask: 461804 params\n",
      "effective_sparsity: 0.8994513427663875\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.696170806884766\n",
      "Target Sparsity: 0.8851289855072464\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8851289855072464\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30653      (total params * sparsity)\n",
      "original mask: 456741 params\n",
      "effective mask: 456723 params\n",
      "effective_sparsity: 0.8850996246029454\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.725099563598633\n",
      "Target Sparsity: 0.8707826086956522\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8707826086956522\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30156      (total params * sparsity)\n",
      "original mask: 451484 params\n",
      "effective mask: 451466 params\n",
      "effective_sparsity: 0.8707479064395033\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.71413803100586\n",
      "Target Sparsity: 0.8564362318840579\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8564362318840579\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29659      (total params * sparsity)\n",
      "original mask: 446163 params\n",
      "effective mask: 446154 params\n",
      "effective_sparsity: 0.8564250649725671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.729005813598633\n",
      "Target Sparsity: 0.8420898550724638\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8420898550724638\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29162      (total params * sparsity)\n",
      "original mask: 440810 params\n",
      "effective mask: 440720 params\n",
      "effective_sparsity: 0.8418134565405717\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.744491577148438\n",
      "Target Sparsity: 0.8277434782608696\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8277434782608696\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28665      (total params * sparsity)\n",
      "original mask: 435201 params\n",
      "effective mask: 435120 params\n",
      "effective_sparsity: 0.8274906150736355\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.797260284423828\n",
      "Target Sparsity: 0.8133971014492754\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8133971014492754\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28168      (total params * sparsity)\n",
      "original mask: 429560 params\n",
      "effective mask: 429470 params\n",
      "effective_sparsity: 0.8131100202136875\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.72945213317871\n",
      "Target Sparsity: 0.7990507246376812\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7990507246376812\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27672      (total params * sparsity)\n",
      "original mask: 423848 params\n",
      "effective mask: 423722 params\n",
      "effective_sparsity: 0.7986716719607277\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.694339752197266\n",
      "Target Sparsity: 0.784704347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.784704347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27175      (total params * sparsity)\n",
      "original mask: 417919 params\n",
      "effective mask: 417820 params\n",
      "effective_sparsity: 0.7844065838868034\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.677404403686523\n",
      "Target Sparsity: 0.7703579710144928\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7703579710144928\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26678      (total params * sparsity)\n",
      "original mask: 411686 params\n",
      "effective mask: 411605 params\n",
      "effective_sparsity: 0.7701126191163731\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.691869735717773\n",
      "Target Sparsity: 0.7560115942028985\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7560115942028985\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26181      (total params * sparsity)\n",
      "original mask: 405661 params\n",
      "effective mask: 405589 params\n",
      "effective_sparsity: 0.7557897776494369\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.595460891723633\n",
      "Target Sparsity: 0.7416652173913043\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7416652173913043\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25684      (total params * sparsity)\n",
      "original mask: 399700 params\n",
      "effective mask: 399637 params\n",
      "effective_sparsity: 0.7414669361825007\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.518287658691406\n",
      "Target Sparsity: 0.7273188405797102\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7273188405797102\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25188      (total params * sparsity)\n",
      "original mask: 393652 params\n",
      "effective mask: 393589 params\n",
      "effective_sparsity: 0.7271440947155645\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.973608016967773\n",
      "Target Sparsity: 0.712972463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.712972463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24691      (total params * sparsity)\n",
      "original mask: 387691 params\n",
      "effective mask: 387565 params\n",
      "effective_sparsity: 0.712590239676581\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.76698112487793\n",
      "Target Sparsity: 0.6986260869565217\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6986260869565217\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24194      (total params * sparsity)\n",
      "original mask: 381426 params\n",
      "effective mask: 381309 params\n",
      "effective_sparsity: 0.6982673982096448\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.81867790222168\n",
      "Target Sparsity: 0.6842797101449276\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6842797101449276\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23697      (total params * sparsity)\n",
      "original mask: 375225 params\n",
      "effective mask: 375126 params\n",
      "effective_sparsity: 0.6839734334392146\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.79762840270996\n",
      "Target Sparsity: 0.6699333333333334\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6699333333333334\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23200      (total params * sparsity)\n",
      "original mask: 368880 params\n",
      "effective mask: 368808 params\n",
      "effective_sparsity: 0.6697083453652902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.386306762695312\n",
      "Target Sparsity: 0.6555869565217392\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6555869565217392\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22703      (total params * sparsity)\n",
      "original mask: 362631 params\n",
      "effective mask: 362514 params\n",
      "effective_sparsity: 0.6552122437193185\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.315248489379883\n",
      "Target Sparsity: 0.6412405797101449\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6412405797101449\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22207      (total params * sparsity)\n",
      "original mask: 356343 params\n",
      "effective mask: 356235 params\n",
      "effective_sparsity: 0.6409182789488882\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.01759910583496\n",
      "Target Sparsity: 0.6268942028985507\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6268942028985507\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21710      (total params * sparsity)\n",
      "original mask: 349838 params\n",
      "effective mask: 349730 params\n",
      "effective_sparsity: 0.6265665607854461\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.294675827026367\n",
      "Target Sparsity: 0.6125478260869566\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6125478260869566\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21213      (total params * sparsity)\n",
      "original mask: 343333 params\n",
      "effective mask: 343146 params\n",
      "effective_sparsity: 0.6120127057464626\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.854413986206055\n",
      "Target Sparsity: 0.5982014492753623\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5982014492753623\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20716      (total params * sparsity)\n",
      "original mask: 336828 params\n",
      "effective mask: 336666 params\n",
      "effective_sparsity: 0.5976898642795264\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.577970504760742\n",
      "Target Sparsity: 0.5838550724637681\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5838550724637681\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20219      (total params * sparsity)\n",
      "original mask: 330147 params\n",
      "effective mask: 330003 params\n",
      "effective_sparsity: 0.5833958995090962\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.630273818969727\n",
      "Target Sparsity: 0.569508695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.569508695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19723      (total params * sparsity)\n",
      "original mask: 323475 params\n",
      "effective mask: 323358 params\n",
      "effective_sparsity: 0.5691596881316777\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.61406898498535\n",
      "Target Sparsity: 0.5551623188405798\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5551623188405798\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19226      (total params * sparsity)\n",
      "original mask: 316794 params\n",
      "effective mask: 316695 params\n",
      "effective_sparsity: 0.5548657233612475\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.793243408203125\n",
      "Target Sparsity: 0.5408159420289855\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5408159420289855\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18729      (total params * sparsity)\n",
      "original mask: 310049 params\n",
      "effective mask: 309950 params\n",
      "effective_sparsity: 0.5405140051978053\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.93950653076172\n",
      "Target Sparsity: 0.5264695652173913\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5264695652173913\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18232      (total params * sparsity)\n",
      "original mask: 303320 params\n",
      "effective mask: 303203 params\n",
      "effective_sparsity: 0.5261045336413515\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.92858123779297\n",
      "Target Sparsity: 0.5121231884057971\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5121231884057971\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17735      (total params * sparsity)\n",
      "original mask: 296287 params\n",
      "effective mask: 296188 params\n",
      "effective_sparsity: 0.5118105688709211\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 23.107614517211914\n",
      "Target Sparsity: 0.49777681159420295\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.49777681159420295\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17239      (total params * sparsity)\n",
      "original mask: 289391 params\n",
      "effective mask: 289310 params\n",
      "effective_sparsity: 0.49754548079699684\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 23.009355545043945\n",
      "Target Sparsity: 0.4834304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4834304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16742      (total params * sparsity)\n",
      "original mask: 282374 params\n",
      "effective mask: 282167 params\n",
      "effective_sparsity: 0.48278948888247186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 23.12966537475586\n",
      "Target Sparsity: 0.4690840579710145\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4690840579710145\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16245      (total params * sparsity)\n",
      "original mask: 275069 params\n",
      "effective mask: 274853 params\n",
      "effective_sparsity: 0.46840889402252384\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.730716705322266\n",
      "Target Sparsity: 0.45473768115942037\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.45473768115942037\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15748      (total params * sparsity)\n",
      "original mask: 267908 params\n",
      "effective mask: 267638 params\n",
      "effective_sparsity: 0.4538839156800462\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.331886291503906\n",
      "Target Sparsity: 0.44039130434782614\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.44039130434782614\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15251      (total params * sparsity)\n",
      "original mask: 260811 params\n",
      "effective mask: 260622 params\n",
      "effective_sparsity: 0.4397920877851574\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.56227684020996\n",
      "Target Sparsity: 0.4260449275362319\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4260449275362319\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14754      (total params * sparsity)\n",
      "original mask: 253442 params\n",
      "effective mask: 253185 params\n",
      "effective_sparsity: 0.4253248628356916\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.178726196289062\n",
      "Target Sparsity: 0.4116985507246377\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4116985507246377\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14258      (total params * sparsity)\n",
      "original mask: 246226 params\n",
      "effective mask: 245960 params\n",
      "effective_sparsity: 0.4109731446722495\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.776437759399414\n",
      "Target Sparsity: 0.39735217391304345\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.39735217391304345\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13761      (total params * sparsity)\n",
      "original mask: 238873 params\n",
      "effective mask: 238614 params\n",
      "effective_sparsity: 0.39659254981230146\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.41822052001953\n",
      "Target Sparsity: 0.38300579710144933\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.38300579710144933\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13264      (total params * sparsity)\n",
      "original mask: 231424 params\n",
      "effective mask: 231066 params\n",
      "effective_sparsity: 0.38192318798729424\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.812110900878906\n",
      "Target Sparsity: 0.3686594202898551\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3686594202898551\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12767      (total params * sparsity)\n",
      "original mask: 223991 params\n",
      "effective mask: 223615 params\n",
      "effective_sparsity: 0.3675137164308403\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.590923309326172\n",
      "Target Sparsity: 0.35431304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.35431304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12270      (total params * sparsity)\n",
      "original mask: 216014 params\n",
      "effective mask: 215638 params\n",
      "effective_sparsity: 0.3531619982673982\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.505207061767578\n",
      "Target Sparsity: 0.33996666666666675\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.33996666666666675\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11774      (total params * sparsity)\n",
      "original mask: 208382 params\n",
      "effective mask: 207952 params\n",
      "effective_sparsity: 0.3386658966214265\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.76026153564453\n",
      "Target Sparsity: 0.3256202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3256202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11277      (total params * sparsity)\n",
      "original mask: 200677 params\n",
      "effective mask: 200317 params\n",
      "effective_sparsity: 0.3244874386370199\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.02849006652832\n",
      "Target Sparsity: 0.3112739130434783\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3112739130434783\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10780      (total params * sparsity)\n",
      "original mask: 192828 params\n",
      "effective mask: 192513 params\n",
      "effective_sparsity: 0.31028010395610744\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.022106170654297\n",
      "Target Sparsity: 0.29692753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.29692753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10283      (total params * sparsity)\n",
      "original mask: 185155 params\n",
      "effective mask: 184849 params\n",
      "effective_sparsity: 0.29595726248917126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.54813575744629\n",
      "Target Sparsity: 0.28258115942028983\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.28258115942028983\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9786      (total params * sparsity)\n",
      "original mask: 177242 params\n",
      "effective mask: 176945 params\n",
      "effective_sparsity: 0.28163442102223507\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.191381454467773\n",
      "Target Sparsity: 0.2682347826086957\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2682347826086957\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9289      (total params * sparsity)\n",
      "original mask: 169361 params\n",
      "effective mask: 169055 params\n",
      "effective_sparsity: 0.26725382616228704\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.965240478515625\n",
      "Target Sparsity: 0.2538884057971015\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2538884057971015\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8793      (total params * sparsity)\n",
      "original mask: 161393 params\n",
      "effective mask: 161033 params\n",
      "effective_sparsity: 0.25275772451631534\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.680274963378906\n",
      "Target Sparsity: 0.23954202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.23954202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8296      (total params * sparsity)\n",
      "original mask: 153240 params\n",
      "effective mask: 152866 params\n",
      "effective_sparsity: 0.23846375974588507\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.625001907348633\n",
      "Target Sparsity: 0.22519565217391313\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.22519565217391313\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7799      (total params * sparsity)\n",
      "original mask: 144751 params\n",
      "effective mask: 144350 params\n",
      "effective_sparsity: 0.2240254114929252\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 17.93507194519043\n",
      "Target Sparsity: 0.2108492753623189\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2108492753623189\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7302      (total params * sparsity)\n",
      "original mask: 136630 params\n",
      "effective mask: 136256 params\n",
      "effective_sparsity: 0.20976032341900086\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 18.001901626586914\n",
      "Target Sparsity: 0.19650289855072467\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.19650289855072467\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6805      (total params * sparsity)\n",
      "original mask: 127933 params\n",
      "effective mask: 127274 params\n",
      "effective_sparsity: 0.19480219462893444\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 17.18612289428711\n",
      "Target Sparsity: 0.18215652173913044\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.18215652173913044\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6309      (total params * sparsity)\n",
      "original mask: 119437 params\n",
      "effective mask: 118837 params\n",
      "effective_sparsity: 0.18056598325151602\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 15.817360877990723\n",
      "Target Sparsity: 0.1678101449275362\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1678101449275362\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5812      (total params * sparsity)\n",
      "original mask: 111460 params\n",
      "effective mask: 110606 params\n",
      "effective_sparsity: 0.16534796419289632\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 16.225282669067383\n",
      "Target Sparsity: 0.1534637681159421\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1534637681159421\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5315      (total params * sparsity)\n",
      "original mask: 103115 params\n",
      "effective mask: 102151 params\n",
      "effective_sparsity: 0.15059197227837134\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 15.039095878601074\n",
      "Target Sparsity: 0.13911739130434786\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.13911739130434786\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4818      (total params * sparsity)\n",
      "original mask: 94242 params\n",
      "effective mask: 92992 params\n",
      "effective_sparsity: 0.13537395321975165\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 14.262979507446289\n",
      "Target Sparsity: 0.12477101449275363\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.12477101449275363\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4321      (total params * sparsity)\n",
      "original mask: 85897 params\n",
      "effective mask: 84573 params\n",
      "effective_sparsity: 0.12073346809125036\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 14.12586498260498\n",
      "Target Sparsity: 0.11042463768115951\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.11042463768115951\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3825      (total params * sparsity)\n",
      "original mask: 76857 params\n",
      "effective mask: 74094 params\n",
      "effective_sparsity: 0.10436038117239388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.612836837768555\n",
      "Target Sparsity: 0.09607826086956528\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.09607826086956528\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3328      (total params * sparsity)\n",
      "original mask: 67536 params\n",
      "effective mask: 64929 params\n",
      "effective_sparsity: 0.0903551833670228\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 13.261537551879883\n",
      "Target Sparsity: 0.08173188405797105\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.08173188405797105\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2831      (total params * sparsity)\n",
      "original mask: 57991 params\n",
      "effective mask: 55057 params\n",
      "effective_sparsity: 0.0751082876118972\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.186439514160156\n",
      "Target Sparsity: 0.06738550724637682\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.06738550724637682\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2334      (total params * sparsity)\n",
      "original mask: 48430 params\n",
      "effective mask: 44750 params\n",
      "effective_sparsity: 0.05815766676292232\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.562577247619629\n",
      "Target Sparsity: 0.05303913043478259\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.05303913043478259\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1837      (total params * sparsity)\n",
      "original mask: 38469 params\n",
      "effective mask: 33931 params\n",
      "effective_sparsity: 0.04166907305804216\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.759771347045898\n",
      "Target Sparsity: 0.03869275362318847\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.03869275362318847\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1340      (total params * sparsity)\n",
      "original mask: 28812 params\n",
      "effective mask: 24004 params\n",
      "effective_sparsity: 0.027837135431706614\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.268158912658691\n",
      "Target Sparsity: 0.02434637681159424\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.02434637681159424\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 844      (total params * sparsity)\n",
      "original mask: 18668 params\n",
      "effective mask: 13684 params\n",
      "effective_sparsity: 0.01351429396477043\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 1.6634609699249268\n",
      "Target Sparsity: 0.01\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.01\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 347      (total params * sparsity)\n",
      "original mask: 7763 params\n",
      "effective mask: 2806 params\n",
      "effective_sparsity: 0.002945423043603812\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 2.3457236289978027\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "left\n",
      "left\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original\n",
      "features_8 effective last layer\n",
      "average orig acts:\n",
      "feature features_8:0: 11.71319580078125\n",
      "Target Sparsity: 0.9999\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9999\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34627      (total params * sparsity)\n",
      "gradients from this feature are sparse,the minimum acceptable rank at this sparsity has a score of zero! we will return a mask thats smaller than you asked, by masking all parameters with a score of zero.\n",
      "original mask: 495254 params\n",
      "effective mask: 495254 params\n",
      "effective_sparsity: 1.0\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.71319580078125\n",
      "Target Sparsity: 0.9855536231884058\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9855536231884058\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34130      (total params * sparsity)\n",
      "original mask: 490690 params\n",
      "effective mask: 490681 params\n",
      "effective_sparsity: 0.9855327750505343\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.71281909942627\n",
      "Target Sparsity: 0.9712072463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9712072463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33633      (total params * sparsity)\n",
      "original mask: 485929 params\n",
      "effective mask: 485884 params\n",
      "effective_sparsity: 0.9710655501010684\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.72616195678711\n",
      "Target Sparsity: 0.9568608695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9568608695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33137      (total params * sparsity)\n",
      "original mask: 481321 params\n",
      "effective mask: 481303 params\n",
      "effective_sparsity: 0.9568293387236501\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.712822914123535\n",
      "Target Sparsity: 0.9425144927536232\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9425144927536232\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32640      (total params * sparsity)\n",
      "original mask: 476592 params\n",
      "effective mask: 476583 params\n",
      "effective_sparsity: 0.9425064972567139\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.708921432495117\n",
      "Target Sparsity: 0.928168115942029\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.928168115942029\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32143      (total params * sparsity)\n",
      "original mask: 471895 params\n",
      "effective mask: 471886 params\n",
      "effective_sparsity: 0.9281547790932717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.709393501281738\n",
      "Target Sparsity: 0.9138217391304349\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9138217391304349\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31646      (total params * sparsity)\n",
      "original mask: 466974 params\n",
      "effective mask: 466965 params\n",
      "effective_sparsity: 0.9138030609298297\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.699165344238281\n",
      "Target Sparsity: 0.8994753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8994753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31149      (total params * sparsity)\n",
      "original mask: 461813 params\n",
      "effective mask: 461804 params\n",
      "effective_sparsity: 0.8994513427663875\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.680981636047363\n",
      "Target Sparsity: 0.8851289855072464\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8851289855072464\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30653      (total params * sparsity)\n",
      "original mask: 456741 params\n",
      "effective mask: 456723 params\n",
      "effective_sparsity: 0.8850996246029454\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.68532943725586\n",
      "Target Sparsity: 0.8707826086956522\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8707826086956522\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30156      (total params * sparsity)\n",
      "original mask: 451484 params\n",
      "effective mask: 451466 params\n",
      "effective_sparsity: 0.8707479064395033\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.679161071777344\n",
      "Target Sparsity: 0.8564362318840579\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8564362318840579\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29659      (total params * sparsity)\n",
      "original mask: 446163 params\n",
      "effective mask: 446154 params\n",
      "effective_sparsity: 0.8564250649725671\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.676689147949219\n",
      "Target Sparsity: 0.8420898550724638\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8420898550724638\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29162      (total params * sparsity)\n",
      "original mask: 440810 params\n",
      "effective mask: 440720 params\n",
      "effective_sparsity: 0.8418134565405717\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.663198471069336\n",
      "Target Sparsity: 0.8277434782608696\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8277434782608696\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28665      (total params * sparsity)\n",
      "original mask: 435201 params\n",
      "effective mask: 435120 params\n",
      "effective_sparsity: 0.8274906150736355\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.67660903930664\n",
      "Target Sparsity: 0.8133971014492754\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8133971014492754\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28168      (total params * sparsity)\n",
      "original mask: 429560 params\n",
      "effective mask: 429470 params\n",
      "effective_sparsity: 0.8131100202136875\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.64028549194336\n",
      "Target Sparsity: 0.7990507246376812\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7990507246376812\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27672      (total params * sparsity)\n",
      "original mask: 423848 params\n",
      "effective mask: 423722 params\n",
      "effective_sparsity: 0.7986716719607277\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.636168479919434\n",
      "Target Sparsity: 0.784704347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.784704347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27175      (total params * sparsity)\n",
      "original mask: 417919 params\n",
      "effective mask: 417820 params\n",
      "effective_sparsity: 0.7844065838868034\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.623513221740723\n",
      "Target Sparsity: 0.7703579710144928\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7703579710144928\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26678      (total params * sparsity)\n",
      "original mask: 411686 params\n",
      "effective mask: 411605 params\n",
      "effective_sparsity: 0.7701126191163731\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.650153160095215\n",
      "Target Sparsity: 0.7560115942028985\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7560115942028985\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26181      (total params * sparsity)\n",
      "original mask: 405661 params\n",
      "effective mask: 405589 params\n",
      "effective_sparsity: 0.7557897776494369\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.58446216583252\n",
      "Target Sparsity: 0.7416652173913043\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7416652173913043\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25684      (total params * sparsity)\n",
      "original mask: 399700 params\n",
      "effective mask: 399637 params\n",
      "effective_sparsity: 0.7414669361825007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.492409706115723\n",
      "Target Sparsity: 0.7273188405797102\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7273188405797102\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25188      (total params * sparsity)\n",
      "original mask: 393652 params\n",
      "effective mask: 393589 params\n",
      "effective_sparsity: 0.7271440947155645\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.839056968688965\n",
      "Target Sparsity: 0.712972463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.712972463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24691      (total params * sparsity)\n",
      "original mask: 387691 params\n",
      "effective mask: 387565 params\n",
      "effective_sparsity: 0.712590239676581\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.767650604248047\n",
      "Target Sparsity: 0.6986260869565217\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6986260869565217\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24194      (total params * sparsity)\n",
      "original mask: 381426 params\n",
      "effective mask: 381309 params\n",
      "effective_sparsity: 0.6982673982096448\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.193499565124512\n",
      "Target Sparsity: 0.6842797101449276\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6842797101449276\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23697      (total params * sparsity)\n",
      "original mask: 375225 params\n",
      "effective mask: 375126 params\n",
      "effective_sparsity: 0.6839734334392146\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.07380485534668\n",
      "Target Sparsity: 0.6699333333333334\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6699333333333334\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23200      (total params * sparsity)\n",
      "original mask: 368880 params\n",
      "effective mask: 368808 params\n",
      "effective_sparsity: 0.6697083453652902\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.121790885925293\n",
      "Target Sparsity: 0.6555869565217392\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6555869565217392\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22703      (total params * sparsity)\n",
      "original mask: 362631 params\n",
      "effective mask: 362514 params\n",
      "effective_sparsity: 0.6552122437193185\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.971857070922852\n",
      "Target Sparsity: 0.6412405797101449\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6412405797101449\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22207      (total params * sparsity)\n",
      "original mask: 356343 params\n",
      "effective mask: 356235 params\n",
      "effective_sparsity: 0.6409182789488882\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.523337364196777\n",
      "Target Sparsity: 0.6268942028985507\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6268942028985507\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21710      (total params * sparsity)\n",
      "original mask: 349838 params\n",
      "effective mask: 349730 params\n",
      "effective_sparsity: 0.6265665607854461\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.803152084350586\n",
      "Target Sparsity: 0.6125478260869566\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6125478260869566\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21213      (total params * sparsity)\n",
      "original mask: 343333 params\n",
      "effective mask: 343146 params\n",
      "effective_sparsity: 0.6120127057464626\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.28757381439209\n",
      "Target Sparsity: 0.5982014492753623\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5982014492753623\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20716      (total params * sparsity)\n",
      "original mask: 336828 params\n",
      "effective mask: 336666 params\n",
      "effective_sparsity: 0.5976898642795264\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.046359062194824\n",
      "Target Sparsity: 0.5838550724637681\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5838550724637681\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20219      (total params * sparsity)\n",
      "original mask: 330147 params\n",
      "effective mask: 330003 params\n",
      "effective_sparsity: 0.5833958995090962\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.006275177001953\n",
      "Target Sparsity: 0.569508695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.569508695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19723      (total params * sparsity)\n",
      "original mask: 323475 params\n",
      "effective mask: 323358 params\n",
      "effective_sparsity: 0.5691596881316777\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.617569923400879\n",
      "Target Sparsity: 0.5551623188405798\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5551623188405798\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19226      (total params * sparsity)\n",
      "original mask: 316794 params\n",
      "effective mask: 316695 params\n",
      "effective_sparsity: 0.5548657233612475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.615277290344238\n",
      "Target Sparsity: 0.5408159420289855\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5408159420289855\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18729      (total params * sparsity)\n",
      "original mask: 310049 params\n",
      "effective mask: 309950 params\n",
      "effective_sparsity: 0.5405140051978053\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.543325424194336\n",
      "Target Sparsity: 0.5264695652173913\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5264695652173913\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18232      (total params * sparsity)\n",
      "original mask: 303320 params\n",
      "effective mask: 303203 params\n",
      "effective_sparsity: 0.5261045336413515\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.65296459197998\n",
      "Target Sparsity: 0.5121231884057971\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5121231884057971\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17735      (total params * sparsity)\n",
      "original mask: 296287 params\n",
      "effective mask: 296188 params\n",
      "effective_sparsity: 0.5118105688709211\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.754498481750488\n",
      "Target Sparsity: 0.49777681159420295\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.49777681159420295\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17239      (total params * sparsity)\n",
      "original mask: 289391 params\n",
      "effective mask: 289310 params\n",
      "effective_sparsity: 0.49754548079699684\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.73531723022461\n",
      "Target Sparsity: 0.4834304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4834304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16742      (total params * sparsity)\n",
      "original mask: 282374 params\n",
      "effective mask: 282167 params\n",
      "effective_sparsity: 0.48278948888247186\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.867552757263184\n",
      "Target Sparsity: 0.4690840579710145\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4690840579710145\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16245      (total params * sparsity)\n",
      "original mask: 275069 params\n",
      "effective mask: 274853 params\n",
      "effective_sparsity: 0.46840889402252384\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.497965812683105\n",
      "Target Sparsity: 0.45473768115942037\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.45473768115942037\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15748      (total params * sparsity)\n",
      "original mask: 267908 params\n",
      "effective mask: 267638 params\n",
      "effective_sparsity: 0.4538839156800462\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.958118438720703\n",
      "Target Sparsity: 0.44039130434782614\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.44039130434782614\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15251      (total params * sparsity)\n",
      "original mask: 260811 params\n",
      "effective mask: 260622 params\n",
      "effective_sparsity: 0.4397920877851574\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.097434997558594\n",
      "Target Sparsity: 0.4260449275362319\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4260449275362319\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14754      (total params * sparsity)\n",
      "original mask: 253442 params\n",
      "effective mask: 253185 params\n",
      "effective_sparsity: 0.4253248628356916\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.662932395935059\n",
      "Target Sparsity: 0.4116985507246377\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4116985507246377\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14258      (total params * sparsity)\n",
      "original mask: 246226 params\n",
      "effective mask: 245960 params\n",
      "effective_sparsity: 0.4109731446722495\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.378591537475586\n",
      "Target Sparsity: 0.39735217391304345\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.39735217391304345\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13761      (total params * sparsity)\n",
      "original mask: 238873 params\n",
      "effective mask: 238614 params\n",
      "effective_sparsity: 0.39659254981230146\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.205904960632324\n",
      "Target Sparsity: 0.38300579710144933\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.38300579710144933\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13264      (total params * sparsity)\n",
      "original mask: 231424 params\n",
      "effective mask: 231066 params\n",
      "effective_sparsity: 0.38192318798729424\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.289472579956055\n",
      "Target Sparsity: 0.3686594202898551\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3686594202898551\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12767      (total params * sparsity)\n",
      "original mask: 223991 params\n",
      "effective mask: 223615 params\n",
      "effective_sparsity: 0.3675137164308403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.34853744506836\n",
      "Target Sparsity: 0.35431304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.35431304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12270      (total params * sparsity)\n",
      "original mask: 216014 params\n",
      "effective mask: 215638 params\n",
      "effective_sparsity: 0.3531619982673982\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.26024341583252\n",
      "Target Sparsity: 0.33996666666666675\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.33996666666666675\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11774      (total params * sparsity)\n",
      "original mask: 208382 params\n",
      "effective mask: 207952 params\n",
      "effective_sparsity: 0.3386658966214265\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.25818920135498\n",
      "Target Sparsity: 0.3256202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3256202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11277      (total params * sparsity)\n",
      "original mask: 200677 params\n",
      "effective mask: 200317 params\n",
      "effective_sparsity: 0.3244874386370199\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.64028263092041\n",
      "Target Sparsity: 0.3112739130434783\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3112739130434783\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10780      (total params * sparsity)\n",
      "original mask: 192828 params\n",
      "effective mask: 192513 params\n",
      "effective_sparsity: 0.31028010395610744\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.091262817382812\n",
      "Target Sparsity: 0.29692753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.29692753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10283      (total params * sparsity)\n",
      "original mask: 185155 params\n",
      "effective mask: 184849 params\n",
      "effective_sparsity: 0.29595726248917126\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.090747833251953\n",
      "Target Sparsity: 0.28258115942028983\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.28258115942028983\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9786      (total params * sparsity)\n",
      "original mask: 177242 params\n",
      "effective mask: 176945 params\n",
      "effective_sparsity: 0.28163442102223507\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.553446769714355\n",
      "Target Sparsity: 0.2682347826086957\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2682347826086957\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9289      (total params * sparsity)\n",
      "original mask: 169361 params\n",
      "effective mask: 169055 params\n",
      "effective_sparsity: 0.26725382616228704\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.660059928894043\n",
      "Target Sparsity: 0.2538884057971015\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2538884057971015\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8793      (total params * sparsity)\n",
      "original mask: 161393 params\n",
      "effective mask: 161033 params\n",
      "effective_sparsity: 0.25275772451631534\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.726590156555176\n",
      "Target Sparsity: 0.23954202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.23954202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8296      (total params * sparsity)\n",
      "original mask: 153240 params\n",
      "effective mask: 152866 params\n",
      "effective_sparsity: 0.23846375974588507\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.221545219421387\n",
      "Target Sparsity: 0.22519565217391313\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.22519565217391313\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7799      (total params * sparsity)\n",
      "original mask: 144751 params\n",
      "effective mask: 144350 params\n",
      "effective_sparsity: 0.2240254114929252\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.524581909179688\n",
      "Target Sparsity: 0.2108492753623189\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2108492753623189\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7302      (total params * sparsity)\n",
      "original mask: 136630 params\n",
      "effective mask: 136256 params\n",
      "effective_sparsity: 0.20976032341900086\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.78650951385498\n",
      "Target Sparsity: 0.19650289855072467\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.19650289855072467\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6805      (total params * sparsity)\n",
      "original mask: 127933 params\n",
      "effective mask: 127274 params\n",
      "effective_sparsity: 0.19480219462893444\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.966907501220703\n",
      "Target Sparsity: 0.18215652173913044\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.18215652173913044\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6309      (total params * sparsity)\n",
      "original mask: 119437 params\n",
      "effective mask: 118837 params\n",
      "effective_sparsity: 0.18056598325151602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.637322425842285\n",
      "Target Sparsity: 0.1678101449275362\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1678101449275362\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5812      (total params * sparsity)\n",
      "original mask: 111460 params\n",
      "effective mask: 110606 params\n",
      "effective_sparsity: 0.16534796419289632\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.424567222595215\n",
      "Target Sparsity: 0.1534637681159421\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1534637681159421\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5315      (total params * sparsity)\n",
      "original mask: 103115 params\n",
      "effective mask: 102151 params\n",
      "effective_sparsity: 0.15059197227837134\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.607258796691895\n",
      "Target Sparsity: 0.13911739130434786\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.13911739130434786\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4818      (total params * sparsity)\n",
      "original mask: 94242 params\n",
      "effective mask: 92992 params\n",
      "effective_sparsity: 0.13537395321975165\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.7113618850708\n",
      "Target Sparsity: 0.12477101449275363\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.12477101449275363\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4321      (total params * sparsity)\n",
      "original mask: 85897 params\n",
      "effective mask: 84573 params\n",
      "effective_sparsity: 0.12073346809125036\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.871740341186523\n",
      "Target Sparsity: 0.11042463768115951\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.11042463768115951\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3825      (total params * sparsity)\n",
      "original mask: 76857 params\n",
      "effective mask: 74094 params\n",
      "effective_sparsity: 0.10436038117239388\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.855904579162598\n",
      "Target Sparsity: 0.09607826086956528\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.09607826086956528\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3328      (total params * sparsity)\n",
      "original mask: 67536 params\n",
      "effective mask: 64929 params\n",
      "effective_sparsity: 0.0903551833670228\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 7.642269134521484\n",
      "Target Sparsity: 0.08173188405797105\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.08173188405797105\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2831      (total params * sparsity)\n",
      "original mask: 57991 params\n",
      "effective mask: 55057 params\n",
      "effective_sparsity: 0.0751082876118972\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.503472805023193\n",
      "Target Sparsity: 0.06738550724637682\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.06738550724637682\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2334      (total params * sparsity)\n",
      "original mask: 48430 params\n",
      "effective mask: 44750 params\n",
      "effective_sparsity: 0.05815766676292232\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.1083149909973145\n",
      "Target Sparsity: 0.05303913043478259\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.05303913043478259\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1837      (total params * sparsity)\n",
      "original mask: 38469 params\n",
      "effective mask: 33931 params\n",
      "effective_sparsity: 0.04166907305804216\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 1.7273818254470825\n",
      "Target Sparsity: 0.03869275362318847\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.03869275362318847\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1340      (total params * sparsity)\n",
      "original mask: 28812 params\n",
      "effective mask: 24004 params\n",
      "effective_sparsity: 0.027837135431706614\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 2.134406566619873\n",
      "Target Sparsity: 0.02434637681159424\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.02434637681159424\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 844      (total params * sparsity)\n",
      "original mask: 18668 params\n",
      "effective mask: 13684 params\n",
      "effective_sparsity: 0.01351429396477043\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 1.6239070892333984\n",
      "Target Sparsity: 0.01\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.01\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 347      (total params * sparsity)\n",
      "original mask: 7763 params\n",
      "effective mask: 2806 params\n",
      "effective_sparsity: 0.002945423043603812\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 2.9233176708221436\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "left\n",
      "right\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original\n",
      "features_8 effective last layer\n",
      "average orig acts:\n",
      "feature features_8:0: 10.785665512084961\n",
      "Target Sparsity: 0.9999\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9999\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34627      (total params * sparsity)\n",
      "gradients from this feature are sparse,the minimum acceptable rank at this sparsity has a score of zero! we will return a mask thats smaller than you asked, by masking all parameters with a score of zero.\n",
      "original mask: 495254 params\n",
      "effective mask: 495254 params\n",
      "effective_sparsity: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.785665512084961\n",
      "Target Sparsity: 0.9855536231884058\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9855536231884058\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34130      (total params * sparsity)\n",
      "original mask: 490690 params\n",
      "effective mask: 490681 params\n",
      "effective_sparsity: 0.9855327750505343\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.778186798095703\n",
      "Target Sparsity: 0.9712072463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9712072463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33633      (total params * sparsity)\n",
      "original mask: 485929 params\n",
      "effective mask: 485884 params\n",
      "effective_sparsity: 0.9710655501010684\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.80659008026123\n",
      "Target Sparsity: 0.9568608695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9568608695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33137      (total params * sparsity)\n",
      "original mask: 481321 params\n",
      "effective mask: 481303 params\n",
      "effective_sparsity: 0.9568293387236501\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.81299877166748\n",
      "Target Sparsity: 0.9425144927536232\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9425144927536232\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32640      (total params * sparsity)\n",
      "original mask: 476592 params\n",
      "effective mask: 476583 params\n",
      "effective_sparsity: 0.9425064972567139\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.798501968383789\n",
      "Target Sparsity: 0.928168115942029\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.928168115942029\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32143      (total params * sparsity)\n",
      "original mask: 471895 params\n",
      "effective mask: 471886 params\n",
      "effective_sparsity: 0.9281547790932717\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.80055046081543\n",
      "Target Sparsity: 0.9138217391304349\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9138217391304349\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31646      (total params * sparsity)\n",
      "original mask: 466974 params\n",
      "effective mask: 466965 params\n",
      "effective_sparsity: 0.9138030609298297\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.800735473632812\n",
      "Target Sparsity: 0.8994753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8994753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31149      (total params * sparsity)\n",
      "original mask: 461813 params\n",
      "effective mask: 461804 params\n",
      "effective_sparsity: 0.8994513427663875\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.790143013000488\n",
      "Target Sparsity: 0.8851289855072464\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8851289855072464\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30653      (total params * sparsity)\n",
      "original mask: 456741 params\n",
      "effective mask: 456723 params\n",
      "effective_sparsity: 0.8850996246029454\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.786582946777344\n",
      "Target Sparsity: 0.8707826086956522\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8707826086956522\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30156      (total params * sparsity)\n",
      "original mask: 451484 params\n",
      "effective mask: 451466 params\n",
      "effective_sparsity: 0.8707479064395033\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.783082962036133\n",
      "Target Sparsity: 0.8564362318840579\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8564362318840579\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29659      (total params * sparsity)\n",
      "original mask: 446163 params\n",
      "effective mask: 446154 params\n",
      "effective_sparsity: 0.8564250649725671\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.788128852844238\n",
      "Target Sparsity: 0.8420898550724638\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8420898550724638\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29162      (total params * sparsity)\n",
      "original mask: 440810 params\n",
      "effective mask: 440720 params\n",
      "effective_sparsity: 0.8418134565405717\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.75908088684082\n",
      "Target Sparsity: 0.8277434782608696\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8277434782608696\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28665      (total params * sparsity)\n",
      "original mask: 435201 params\n",
      "effective mask: 435120 params\n",
      "effective_sparsity: 0.8274906150736355\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.899531364440918\n",
      "Target Sparsity: 0.8133971014492754\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8133971014492754\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28168      (total params * sparsity)\n",
      "original mask: 429560 params\n",
      "effective mask: 429470 params\n",
      "effective_sparsity: 0.8131100202136875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.749341011047363\n",
      "Target Sparsity: 0.7990507246376812\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7990507246376812\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27672      (total params * sparsity)\n",
      "original mask: 423848 params\n",
      "effective mask: 423722 params\n",
      "effective_sparsity: 0.7986716719607277\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.77823543548584\n",
      "Target Sparsity: 0.784704347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.784704347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27175      (total params * sparsity)\n",
      "original mask: 417919 params\n",
      "effective mask: 417820 params\n",
      "effective_sparsity: 0.7844065838868034\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.76555061340332\n",
      "Target Sparsity: 0.7703579710144928\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7703579710144928\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26678      (total params * sparsity)\n",
      "original mask: 411686 params\n",
      "effective mask: 411605 params\n",
      "effective_sparsity: 0.7701126191163731\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.754925727844238\n",
      "Target Sparsity: 0.7560115942028985\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7560115942028985\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26181      (total params * sparsity)\n",
      "original mask: 405661 params\n",
      "effective mask: 405589 params\n",
      "effective_sparsity: 0.7557897776494369\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.689423561096191\n",
      "Target Sparsity: 0.7416652173913043\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7416652173913043\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25684      (total params * sparsity)\n",
      "original mask: 399700 params\n",
      "effective mask: 399637 params\n",
      "effective_sparsity: 0.7414669361825007\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.655762672424316\n",
      "Target Sparsity: 0.7273188405797102\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7273188405797102\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25188      (total params * sparsity)\n",
      "original mask: 393652 params\n",
      "effective mask: 393589 params\n",
      "effective_sparsity: 0.7271440947155645\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.104129791259766\n",
      "Target Sparsity: 0.712972463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.712972463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24691      (total params * sparsity)\n",
      "original mask: 387691 params\n",
      "effective mask: 387565 params\n",
      "effective_sparsity: 0.712590239676581\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.978818893432617\n",
      "Target Sparsity: 0.6986260869565217\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6986260869565217\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24194      (total params * sparsity)\n",
      "original mask: 381426 params\n",
      "effective mask: 381309 params\n",
      "effective_sparsity: 0.6982673982096448\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.421529769897461\n",
      "Target Sparsity: 0.6842797101449276\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6842797101449276\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23697      (total params * sparsity)\n",
      "original mask: 375225 params\n",
      "effective mask: 375126 params\n",
      "effective_sparsity: 0.6839734334392146\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.372519493103027\n",
      "Target Sparsity: 0.6699333333333334\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6699333333333334\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23200      (total params * sparsity)\n",
      "original mask: 368880 params\n",
      "effective mask: 368808 params\n",
      "effective_sparsity: 0.6697083453652902\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.558128356933594\n",
      "Target Sparsity: 0.6555869565217392\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6555869565217392\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22703      (total params * sparsity)\n",
      "original mask: 362631 params\n",
      "effective mask: 362514 params\n",
      "effective_sparsity: 0.6552122437193185\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.44020938873291\n",
      "Target Sparsity: 0.6412405797101449\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6412405797101449\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22207      (total params * sparsity)\n",
      "original mask: 356343 params\n",
      "effective mask: 356235 params\n",
      "effective_sparsity: 0.6409182789488882\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.944053649902344\n",
      "Target Sparsity: 0.6268942028985507\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6268942028985507\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21710      (total params * sparsity)\n",
      "original mask: 349838 params\n",
      "effective mask: 349730 params\n",
      "effective_sparsity: 0.6265665607854461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.1778564453125\n",
      "Target Sparsity: 0.6125478260869566\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6125478260869566\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21213      (total params * sparsity)\n",
      "original mask: 343333 params\n",
      "effective mask: 343146 params\n",
      "effective_sparsity: 0.6120127057464626\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.646410942077637\n",
      "Target Sparsity: 0.5982014492753623\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5982014492753623\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20716      (total params * sparsity)\n",
      "original mask: 336828 params\n",
      "effective mask: 336666 params\n",
      "effective_sparsity: 0.5976898642795264\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.352694511413574\n",
      "Target Sparsity: 0.5838550724637681\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5838550724637681\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20219      (total params * sparsity)\n",
      "original mask: 330147 params\n",
      "effective mask: 330003 params\n",
      "effective_sparsity: 0.5833958995090962\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.30551528930664\n",
      "Target Sparsity: 0.569508695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.569508695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19723      (total params * sparsity)\n",
      "original mask: 323475 params\n",
      "effective mask: 323358 params\n",
      "effective_sparsity: 0.5691596881316777\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.674878120422363\n",
      "Target Sparsity: 0.5551623188405798\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5551623188405798\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19226      (total params * sparsity)\n",
      "original mask: 316794 params\n",
      "effective mask: 316695 params\n",
      "effective_sparsity: 0.5548657233612475\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.873832702636719\n",
      "Target Sparsity: 0.5408159420289855\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5408159420289855\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18729      (total params * sparsity)\n",
      "original mask: 310049 params\n",
      "effective mask: 309950 params\n",
      "effective_sparsity: 0.5405140051978053\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.010746955871582\n",
      "Target Sparsity: 0.5264695652173913\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5264695652173913\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18232      (total params * sparsity)\n",
      "original mask: 303320 params\n",
      "effective mask: 303203 params\n",
      "effective_sparsity: 0.5261045336413515\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.62739372253418\n",
      "Target Sparsity: 0.5121231884057971\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5121231884057971\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17735      (total params * sparsity)\n",
      "original mask: 296287 params\n",
      "effective mask: 296188 params\n",
      "effective_sparsity: 0.5118105688709211\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.826981544494629\n",
      "Target Sparsity: 0.49777681159420295\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.49777681159420295\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17239      (total params * sparsity)\n",
      "original mask: 289391 params\n",
      "effective mask: 289310 params\n",
      "effective_sparsity: 0.49754548079699684\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.832338333129883\n",
      "Target Sparsity: 0.4834304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4834304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16742      (total params * sparsity)\n",
      "original mask: 282374 params\n",
      "effective mask: 282167 params\n",
      "effective_sparsity: 0.48278948888247186\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.780617713928223\n",
      "Target Sparsity: 0.4690840579710145\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4690840579710145\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16245      (total params * sparsity)\n",
      "original mask: 275069 params\n",
      "effective mask: 274853 params\n",
      "effective_sparsity: 0.46840889402252384\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.388334274291992\n",
      "Target Sparsity: 0.45473768115942037\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.45473768115942037\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15748      (total params * sparsity)\n",
      "original mask: 267908 params\n",
      "effective mask: 267638 params\n",
      "effective_sparsity: 0.4538839156800462\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.882316589355469\n",
      "Target Sparsity: 0.44039130434782614\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.44039130434782614\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15251      (total params * sparsity)\n",
      "original mask: 260811 params\n",
      "effective mask: 260622 params\n",
      "effective_sparsity: 0.4397920877851574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.050515174865723\n",
      "Target Sparsity: 0.4260449275362319\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4260449275362319\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14754      (total params * sparsity)\n",
      "original mask: 253442 params\n",
      "effective mask: 253185 params\n",
      "effective_sparsity: 0.4253248628356916\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.840109825134277\n",
      "Target Sparsity: 0.4116985507246377\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4116985507246377\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14258      (total params * sparsity)\n",
      "original mask: 246226 params\n",
      "effective mask: 245960 params\n",
      "effective_sparsity: 0.4109731446722495\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.649571418762207\n",
      "Target Sparsity: 0.39735217391304345\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.39735217391304345\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13761      (total params * sparsity)\n",
      "original mask: 238873 params\n",
      "effective mask: 238614 params\n",
      "effective_sparsity: 0.39659254981230146\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.444014549255371\n",
      "Target Sparsity: 0.38300579710144933\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.38300579710144933\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13264      (total params * sparsity)\n",
      "original mask: 231424 params\n",
      "effective mask: 231066 params\n",
      "effective_sparsity: 0.38192318798729424\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.840609550476074\n",
      "Target Sparsity: 0.3686594202898551\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3686594202898551\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12767      (total params * sparsity)\n",
      "original mask: 223991 params\n",
      "effective mask: 223615 params\n",
      "effective_sparsity: 0.3675137164308403\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.72225284576416\n",
      "Target Sparsity: 0.35431304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.35431304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12270      (total params * sparsity)\n",
      "original mask: 216014 params\n",
      "effective mask: 215638 params\n",
      "effective_sparsity: 0.3531619982673982\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.58022689819336\n",
      "Target Sparsity: 0.33996666666666675\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.33996666666666675\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11774      (total params * sparsity)\n",
      "original mask: 208382 params\n",
      "effective mask: 207952 params\n",
      "effective_sparsity: 0.3386658966214265\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.82252311706543\n",
      "Target Sparsity: 0.3256202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3256202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11277      (total params * sparsity)\n",
      "original mask: 200677 params\n",
      "effective mask: 200317 params\n",
      "effective_sparsity: 0.3244874386370199\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.995662689208984\n",
      "Target Sparsity: 0.3112739130434783\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3112739130434783\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10780      (total params * sparsity)\n",
      "original mask: 192828 params\n",
      "effective mask: 192513 params\n",
      "effective_sparsity: 0.31028010395610744\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.354510307312012\n",
      "Target Sparsity: 0.29692753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.29692753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10283      (total params * sparsity)\n",
      "original mask: 185155 params\n",
      "effective mask: 184849 params\n",
      "effective_sparsity: 0.29595726248917126\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.729795455932617\n",
      "Target Sparsity: 0.28258115942028983\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.28258115942028983\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9786      (total params * sparsity)\n",
      "original mask: 177242 params\n",
      "effective mask: 176945 params\n",
      "effective_sparsity: 0.28163442102223507\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.130520820617676\n",
      "Target Sparsity: 0.2682347826086957\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2682347826086957\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9289      (total params * sparsity)\n",
      "original mask: 169361 params\n",
      "effective mask: 169055 params\n",
      "effective_sparsity: 0.26725382616228704\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.373379707336426\n",
      "Target Sparsity: 0.2538884057971015\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2538884057971015\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8793      (total params * sparsity)\n",
      "original mask: 161393 params\n",
      "effective mask: 161033 params\n",
      "effective_sparsity: 0.25275772451631534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.580357551574707\n",
      "Target Sparsity: 0.23954202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.23954202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8296      (total params * sparsity)\n",
      "original mask: 153240 params\n",
      "effective mask: 152866 params\n",
      "effective_sparsity: 0.23846375974588507\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.695272445678711\n",
      "Target Sparsity: 0.22519565217391313\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.22519565217391313\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7799      (total params * sparsity)\n",
      "original mask: 144751 params\n",
      "effective mask: 144350 params\n",
      "effective_sparsity: 0.2240254114929252\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.731351852416992\n",
      "Target Sparsity: 0.2108492753623189\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2108492753623189\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7302      (total params * sparsity)\n",
      "original mask: 136630 params\n",
      "effective mask: 136256 params\n",
      "effective_sparsity: 0.20976032341900086\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.473747253417969\n",
      "Target Sparsity: 0.19650289855072467\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.19650289855072467\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6805      (total params * sparsity)\n",
      "original mask: 127933 params\n",
      "effective mask: 127274 params\n",
      "effective_sparsity: 0.19480219462893444\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.330854415893555\n",
      "Target Sparsity: 0.18215652173913044\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.18215652173913044\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6309      (total params * sparsity)\n",
      "original mask: 119437 params\n",
      "effective mask: 118837 params\n",
      "effective_sparsity: 0.18056598325151602\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 7.39415979385376\n",
      "Target Sparsity: 0.1678101449275362\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1678101449275362\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5812      (total params * sparsity)\n",
      "original mask: 111460 params\n",
      "effective mask: 110606 params\n",
      "effective_sparsity: 0.16534796419289632\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 7.354434013366699\n",
      "Target Sparsity: 0.1534637681159421\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1534637681159421\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5315      (total params * sparsity)\n",
      "original mask: 103115 params\n",
      "effective mask: 102151 params\n",
      "effective_sparsity: 0.15059197227837134\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.683959007263184\n",
      "Target Sparsity: 0.13911739130434786\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.13911739130434786\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4818      (total params * sparsity)\n",
      "original mask: 94242 params\n",
      "effective mask: 92992 params\n",
      "effective_sparsity: 0.13537395321975165\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.534945011138916\n",
      "Target Sparsity: 0.12477101449275363\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.12477101449275363\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4321      (total params * sparsity)\n",
      "original mask: 85897 params\n",
      "effective mask: 84573 params\n",
      "effective_sparsity: 0.12073346809125036\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 7.147400379180908\n",
      "Target Sparsity: 0.11042463768115951\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.11042463768115951\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3825      (total params * sparsity)\n",
      "original mask: 76857 params\n",
      "effective mask: 74094 params\n",
      "effective_sparsity: 0.10436038117239388\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.683994293212891\n",
      "Target Sparsity: 0.09607826086956528\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.09607826086956528\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3328      (total params * sparsity)\n",
      "original mask: 67536 params\n",
      "effective mask: 64929 params\n",
      "effective_sparsity: 0.0903551833670228\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.286044120788574\n",
      "Target Sparsity: 0.08173188405797105\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.08173188405797105\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2831      (total params * sparsity)\n",
      "original mask: 57991 params\n",
      "effective mask: 55057 params\n",
      "effective_sparsity: 0.0751082876118972\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.802215099334717\n",
      "Target Sparsity: 0.06738550724637682\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.06738550724637682\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2334      (total params * sparsity)\n",
      "original mask: 48430 params\n",
      "effective mask: 44750 params\n",
      "effective_sparsity: 0.05815766676292232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.9563469886779785\n",
      "Target Sparsity: 0.05303913043478259\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.05303913043478259\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1837      (total params * sparsity)\n",
      "original mask: 38469 params\n",
      "effective mask: 33931 params\n",
      "effective_sparsity: 0.04166907305804216\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 1.2310785055160522\n",
      "Target Sparsity: 0.03869275362318847\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.03869275362318847\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1340      (total params * sparsity)\n",
      "original mask: 28812 params\n",
      "effective mask: 24004 params\n",
      "effective_sparsity: 0.027837135431706614\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 1.2103548049926758\n",
      "Target Sparsity: 0.02434637681159424\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.02434637681159424\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 844      (total params * sparsity)\n",
      "original mask: 18668 params\n",
      "effective mask: 13684 params\n",
      "effective_sparsity: 0.01351429396477043\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 0.1545182168483734\n",
      "Target Sparsity: 0.01\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.01\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 347      (total params * sparsity)\n",
      "original mask: 7763 params\n",
      "effective mask: 2806 params\n",
      "effective_sparsity: 0.002945423043603812\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 1.23373281955719\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "right\n",
      "front\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original\n",
      "features_8 effective last layer\n",
      "average orig acts:\n",
      "feature features_8:0: 21.704315185546875\n",
      "Target Sparsity: 0.9999\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9999\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34627      (total params * sparsity)\n",
      "gradients from this feature are sparse,the minimum acceptable rank at this sparsity has a score of zero! we will return a mask thats smaller than you asked, by masking all parameters with a score of zero.\n",
      "original mask: 495254 params\n",
      "effective mask: 495254 params\n",
      "effective_sparsity: 1.0\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.704315185546875\n",
      "Target Sparsity: 0.9855536231884058\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9855536231884058\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34130      (total params * sparsity)\n",
      "original mask: 490690 params\n",
      "effective mask: 490681 params\n",
      "effective_sparsity: 0.9855327750505343\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.70803451538086\n",
      "Target Sparsity: 0.9712072463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9712072463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33633      (total params * sparsity)\n",
      "original mask: 485929 params\n",
      "effective mask: 485929 params\n",
      "effective_sparsity: 0.9712099335835981\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.713363647460938\n",
      "Target Sparsity: 0.9568608695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9568608695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33137      (total params * sparsity)\n",
      "original mask: 481353 params\n",
      "effective mask: 481344 params\n",
      "effective_sparsity: 0.9568582154201559\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.718442916870117\n",
      "Target Sparsity: 0.9425144927536232\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9425144927536232\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32640      (total params * sparsity)\n",
      "original mask: 476672 params\n",
      "effective mask: 476654 params\n",
      "effective_sparsity: 0.9424776205602079\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.713516235351562\n",
      "Target Sparsity: 0.928168115942029\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.928168115942029\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32143      (total params * sparsity)\n",
      "original mask: 471991 params\n",
      "effective mask: 471964 params\n",
      "effective_sparsity: 0.9280970257002599\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.729934692382812\n",
      "Target Sparsity: 0.9138217391304349\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9138217391304349\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31646      (total params * sparsity)\n",
      "original mask: 467198 params\n",
      "effective mask: 466559 params\n",
      "effective_sparsity: 0.9117816921744153\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.737001419067383\n",
      "Target Sparsity: 0.8994753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8994753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31149      (total params * sparsity)\n",
      "original mask: 462149 params\n",
      "effective mask: 461627 params\n",
      "effective_sparsity: 0.8978053710655501\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.76456069946289\n",
      "Target Sparsity: 0.8851289855072464\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8851289855072464\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30653      (total params * sparsity)\n",
      "original mask: 457093 params\n",
      "effective mask: 456724 params\n",
      "effective_sparsity: 0.8839734334392145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.79268455505371\n",
      "Target Sparsity: 0.8707826086956522\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8707826086956522\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30156      (total params * sparsity)\n",
      "original mask: 451708 params\n",
      "effective mask: 451447 params\n",
      "effective_sparsity: 0.8699682356338435\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.82746696472168\n",
      "Target Sparsity: 0.8564362318840579\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8564362318840579\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29659      (total params * sparsity)\n",
      "original mask: 446387 params\n",
      "effective mask: 446063 params\n",
      "effective_sparsity: 0.85541438059486\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.87847328186035\n",
      "Target Sparsity: 0.8420898550724638\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8420898550724638\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29162      (total params * sparsity)\n",
      "original mask: 441002 params\n",
      "effective mask: 440732 params\n",
      "effective_sparsity: 0.8412359226104533\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.917022705078125\n",
      "Target Sparsity: 0.8277434782608696\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8277434782608696\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28665      (total params * sparsity)\n",
      "original mask: 435185 params\n",
      "effective mask: 434987 params\n",
      "effective_sparsity: 0.8271152180190586\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.052946090698242\n",
      "Target Sparsity: 0.8133971014492754\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8133971014492754\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28168      (total params * sparsity)\n",
      "original mask: 429560 params\n",
      "effective mask: 429398 params\n",
      "effective_sparsity: 0.8128790066416401\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.15566062927246\n",
      "Target Sparsity: 0.7990507246376812\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7990507246376812\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27672      (total params * sparsity)\n",
      "original mask: 423752 params\n",
      "effective mask: 423608 params\n",
      "effective_sparsity: 0.7986139185677159\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.13282585144043\n",
      "Target Sparsity: 0.784704347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.784704347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27175      (total params * sparsity)\n",
      "original mask: 417791 params\n",
      "effective mask: 417548 params\n",
      "effective_sparsity: 0.7839445567427087\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.125211715698242\n",
      "Target Sparsity: 0.7703579710144928\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7703579710144928\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26678      (total params * sparsity)\n",
      "original mask: 411654 params\n",
      "effective mask: 411456 params\n",
      "effective_sparsity: 0.7697372220617962\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.051233291625977\n",
      "Target Sparsity: 0.7560115942028985\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7560115942028985\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26181      (total params * sparsity)\n",
      "original mask: 405645 params\n",
      "effective mask: 405447 params\n",
      "effective_sparsity: 0.755385503898354\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.99641990661621\n",
      "Target Sparsity: 0.7416652173913043\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7416652173913043\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25684      (total params * sparsity)\n",
      "original mask: 399668 params\n",
      "effective mask: 399497 params\n",
      "effective_sparsity: 0.7411204158244297\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.956928253173828\n",
      "Target Sparsity: 0.7273188405797102\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7273188405797102\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25188      (total params * sparsity)\n",
      "original mask: 393716 params\n",
      "effective mask: 393599 params\n",
      "effective_sparsity: 0.726970834536529\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.893190383911133\n",
      "Target Sparsity: 0.712972463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.712972463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24691      (total params * sparsity)\n",
      "original mask: 387611 params\n",
      "effective mask: 387521 params\n",
      "effective_sparsity: 0.7127057464626047\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.878332138061523\n",
      "Target Sparsity: 0.6986260869565217\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6986260869565217\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24194      (total params * sparsity)\n",
      "original mask: 381026 params\n",
      "effective mask: 380936 params\n",
      "effective_sparsity: 0.6983540282991626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.968637466430664\n",
      "Target Sparsity: 0.6842797101449276\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6842797101449276\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23697      (total params * sparsity)\n",
      "original mask: 374937 params\n",
      "effective mask: 374847 params\n",
      "effective_sparsity: 0.6840023101357204\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.73546028137207\n",
      "Target Sparsity: 0.6699333333333334\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6699333333333334\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23200      (total params * sparsity)\n",
      "original mask: 368528 params\n",
      "effective mask: 368384 params\n",
      "effective_sparsity: 0.6694773317932429\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.73223114013672\n",
      "Target Sparsity: 0.6555869565217392\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6555869565217392\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22703      (total params * sparsity)\n",
      "original mask: 362167 params\n",
      "effective mask: 362086 params\n",
      "effective_sparsity: 0.6553277505053422\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.31807518005371\n",
      "Target Sparsity: 0.6412405797101449\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6412405797101449\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22207      (total params * sparsity)\n",
      "original mask: 356055 params\n",
      "effective mask: 355974 params\n",
      "effective_sparsity: 0.641004909038406\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.621469497680664\n",
      "Target Sparsity: 0.6268942028985507\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6268942028985507\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21710      (total params * sparsity)\n",
      "original mask: 349438 params\n",
      "effective mask: 349384 params\n",
      "effective_sparsity: 0.6267398209644817\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.093154907226562\n",
      "Target Sparsity: 0.6125478260869566\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6125478260869566\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21213      (total params * sparsity)\n",
      "original mask: 342965 params\n",
      "effective mask: 342902 params\n",
      "effective_sparsity: 0.6123592261045336\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.57042121887207\n",
      "Target Sparsity: 0.5982014492753623\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5982014492753623\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20716      (total params * sparsity)\n",
      "original mask: 336556 params\n",
      "effective mask: 336475 params\n",
      "effective_sparsity: 0.5979497545480797\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.851736068725586\n",
      "Target Sparsity: 0.5838550724637681\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5838550724637681\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20219      (total params * sparsity)\n",
      "original mask: 329715 params\n",
      "effective mask: 329643 params\n",
      "effective_sparsity: 0.5836269130811436\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 20.90190315246582\n",
      "Target Sparsity: 0.569508695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.569508695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19723      (total params * sparsity)\n",
      "original mask: 323411 params\n",
      "effective mask: 323303 params\n",
      "effective_sparsity: 0.5691885648281837\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.95222282409668\n",
      "Target Sparsity: 0.5551623188405798\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5551623188405798\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19226      (total params * sparsity)\n",
      "original mask: 316730 params\n",
      "effective mask: 316586 params\n",
      "effective_sparsity: 0.5547213398787179\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.49755096435547\n",
      "Target Sparsity: 0.5408159420289855\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5408159420289855\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18729      (total params * sparsity)\n",
      "original mask: 310097 params\n",
      "effective mask: 309926 params\n",
      "effective_sparsity: 0.540282991625758\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.500211715698242\n",
      "Target Sparsity: 0.5264695652173913\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5264695652173913\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18232      (total params * sparsity)\n",
      "original mask: 303208 params\n",
      "effective mask: 303073 params\n",
      "effective_sparsity: 0.5260467802483396\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.39090347290039\n",
      "Target Sparsity: 0.5121231884057971\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5121231884057971\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17735      (total params * sparsity)\n",
      "original mask: 296079 params\n",
      "effective mask: 295944 params\n",
      "effective_sparsity: 0.5116950620848975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.397701263427734\n",
      "Target Sparsity: 0.49777681159420295\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.49777681159420295\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17239      (total params * sparsity)\n",
      "original mask: 289151 params\n",
      "effective mask: 289007 params\n",
      "effective_sparsity: 0.4973433439214554\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.40829849243164\n",
      "Target Sparsity: 0.4834304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4834304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16742      (total params * sparsity)\n",
      "original mask: 281990 params\n",
      "effective mask: 281837 params\n",
      "effective_sparsity: 0.4829627490615074\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.743799209594727\n",
      "Target Sparsity: 0.4690840579710145\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4690840579710145\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16245      (total params * sparsity)\n",
      "original mask: 274845 params\n",
      "effective mask: 274611 params\n",
      "effective_sparsity: 0.468351140629512\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.579309463500977\n",
      "Target Sparsity: 0.45473768115942037\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.45473768115942037\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15748      (total params * sparsity)\n",
      "original mask: 267476 params\n",
      "effective mask: 267206 params\n",
      "effective_sparsity: 0.4538839156800462\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.449249267578125\n",
      "Target Sparsity: 0.44039130434782614\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.44039130434782614\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15251      (total params * sparsity)\n",
      "original mask: 260219 params\n",
      "effective mask: 259940 params\n",
      "effective_sparsity: 0.4395033208200982\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.451168060302734\n",
      "Target Sparsity: 0.4260449275362319\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4260449275362319\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14754      (total params * sparsity)\n",
      "original mask: 253058 params\n",
      "effective mask: 252716 params\n",
      "effective_sparsity: 0.42494946578111464\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.69215965270996\n",
      "Target Sparsity: 0.4116985507246377\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4116985507246377\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14258      (total params * sparsity)\n",
      "original mask: 246018 params\n",
      "effective mask: 245676 params\n",
      "effective_sparsity: 0.41062662431417846\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.687177658081055\n",
      "Target Sparsity: 0.39735217391304345\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.39735217391304345\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13761      (total params * sparsity)\n",
      "original mask: 238585 params\n",
      "effective mask: 238279 params\n",
      "effective_sparsity: 0.39639041293676003\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.51820945739746\n",
      "Target Sparsity: 0.38300579710144933\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.38300579710144933\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13264      (total params * sparsity)\n",
      "original mask: 231088 params\n",
      "effective mask: 230773 params\n",
      "effective_sparsity: 0.382009818076812\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.9349365234375\n",
      "Target Sparsity: 0.3686594202898551\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3686594202898551\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12767      (total params * sparsity)\n",
      "original mask: 223399 params\n",
      "effective mask: 222949 params\n",
      "effective_sparsity: 0.3672249494657811\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 23.01043128967285\n",
      "Target Sparsity: 0.35431304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.35431304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12270      (total params * sparsity)\n",
      "original mask: 215966 params\n",
      "effective mask: 215570 params\n",
      "effective_sparsity: 0.3530464914813745\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 22.457664489746094\n",
      "Target Sparsity: 0.33996666666666675\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.33996666666666675\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11774      (total params * sparsity)\n",
      "original mask: 208094 params\n",
      "effective mask: 207689 params\n",
      "effective_sparsity: 0.3386947733179324\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.84366226196289\n",
      "Target Sparsity: 0.3256202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3256202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11277      (total params * sparsity)\n",
      "original mask: 200309 params\n",
      "effective mask: 199890 params\n",
      "effective_sparsity: 0.32440080854750214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.14108657836914\n",
      "Target Sparsity: 0.3112739130434783\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3112739130434783\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10780      (total params * sparsity)\n",
      "original mask: 192620 params\n",
      "effective mask: 192228 params\n",
      "effective_sparsity: 0.31013572047357785\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.402069091796875\n",
      "Target Sparsity: 0.29692753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.29692753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10283      (total params * sparsity)\n",
      "original mask: 184851 params\n",
      "effective mask: 184466 params\n",
      "effective_sparsity: 0.2957551256136298\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.73179817199707\n",
      "Target Sparsity: 0.28258115942028983\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.28258115942028983\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9786      (total params * sparsity)\n",
      "original mask: 177018 params\n",
      "effective mask: 176613 params\n",
      "effective_sparsity: 0.28128790066416404\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.13270378112793\n",
      "Target Sparsity: 0.2682347826086957\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2682347826086957\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9289      (total params * sparsity)\n",
      "original mask: 169265 params\n",
      "effective mask: 168835 params\n",
      "effective_sparsity: 0.266907305804216\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 21.15274429321289\n",
      "Target Sparsity: 0.2538884057971015\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2538884057971015\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8793      (total params * sparsity)\n",
      "original mask: 161441 params\n",
      "effective mask: 161011 params\n",
      "effective_sparsity: 0.2525844643372798\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 19.986061096191406\n",
      "Target Sparsity: 0.23954202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.23954202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8296      (total params * sparsity)\n",
      "original mask: 153128 params\n",
      "effective mask: 152644 params\n",
      "effective_sparsity: 0.2380594859948022\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 18.917808532714844\n",
      "Target Sparsity: 0.22519565217391313\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.22519565217391313\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7799      (total params * sparsity)\n",
      "original mask: 144671 params\n",
      "effective mask: 144230 params\n",
      "effective_sparsity: 0.22379439792087785\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 18.878843307495117\n",
      "Target Sparsity: 0.2108492753623189\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2108492753623189\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7302      (total params * sparsity)\n",
      "original mask: 136582 params\n",
      "effective mask: 135839 params\n",
      "effective_sparsity: 0.20903840600635287\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 18.176511764526367\n",
      "Target Sparsity: 0.19650289855072467\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.19650289855072467\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6805      (total params * sparsity)\n",
      "original mask: 128141 params\n",
      "effective mask: 127142 params\n",
      "effective_sparsity: 0.19376263355472134\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 17.79431915283203\n",
      "Target Sparsity: 0.18215652173913044\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.18215652173913044\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6309      (total params * sparsity)\n",
      "original mask: 119485 params\n",
      "effective mask: 118599 params\n",
      "effective_sparsity: 0.17969968235633843\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 16.186767578125\n",
      "Target Sparsity: 0.1678101449275362\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1678101449275362\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5812      (total params * sparsity)\n",
      "original mask: 111140 params\n",
      "effective mask: 110115 params\n",
      "effective_sparsity: 0.16479930695928385\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 13.899045944213867\n",
      "Target Sparsity: 0.1534637681159421\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1534637681159421\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5315      (total params * sparsity)\n",
      "original mask: 102587 params\n",
      "effective mask: 101454 params\n",
      "effective_sparsity: 0.1501010684377707\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 14.56729507446289\n",
      "Target Sparsity: 0.13911739130434786\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.13911739130434786\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4818      (total params * sparsity)\n",
      "original mask: 94210 params\n",
      "effective mask: 93030 params\n",
      "effective_sparsity: 0.13554721339878717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.547409057617188\n",
      "Target Sparsity: 0.12477101449275363\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.12477101449275363\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4321      (total params * sparsity)\n",
      "original mask: 85849 params\n",
      "effective mask: 84606 params\n",
      "effective_sparsity: 0.12099335835980364\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.349102973937988\n",
      "Target Sparsity: 0.11042463768115951\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.11042463768115951\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3825      (total params * sparsity)\n",
      "original mask: 76921 params\n",
      "effective mask: 74376 params\n",
      "effective_sparsity: 0.10511117528154779\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.176380157470703\n",
      "Target Sparsity: 0.09607826086956528\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.09607826086956528\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3328      (total params * sparsity)\n",
      "original mask: 67616 params\n",
      "effective mask: 64669 params\n",
      "effective_sparsity: 0.0893156222928097\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.455185890197754\n",
      "Target Sparsity: 0.08173188405797105\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.08173188405797105\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2831      (total params * sparsity)\n",
      "original mask: 58423 params\n",
      "effective mask: 55592 params\n",
      "effective_sparsity: 0.07507941091539128\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.152660369873047\n",
      "Target Sparsity: 0.06738550724637682\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.06738550724637682\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2334      (total params * sparsity)\n",
      "original mask: 48398 params\n",
      "effective mask: 44541 params\n",
      "effective_sparsity: 0.05835980363846376\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.595148086547852\n",
      "Target Sparsity: 0.05303913043478259\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.05303913043478259\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1837      (total params * sparsity)\n",
      "original mask: 38421 params\n",
      "effective mask: 33857 params\n",
      "effective_sparsity: 0.04184233323707768\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.089037895202637\n",
      "Target Sparsity: 0.03869275362318847\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.03869275362318847\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1340      (total params * sparsity)\n",
      "original mask: 29084 params\n",
      "effective mask: 24552 params\n",
      "effective_sparsity: 0.027490615073635576\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.932311534881592\n",
      "Target Sparsity: 0.02434637681159424\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.02434637681159424\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 844      (total params * sparsity)\n",
      "original mask: 18268 params\n",
      "effective mask: 13454 params\n",
      "effective_sparsity: 0.014265088073924343\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 2.941560745239258\n",
      "Target Sparsity: 0.01\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.01\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 347      (total params * sparsity)\n",
      "original mask: 7619 params\n",
      "effective mask: 3013 params\n",
      "effective_sparsity: 0.002685532775050534\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 0.8753472566604614\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "right\n",
      "left\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original\n",
      "features_8 effective last layer\n",
      "average orig acts:\n",
      "feature features_8:0: 11.71319580078125\n",
      "Target Sparsity: 0.9999\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9999\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34627      (total params * sparsity)\n",
      "gradients from this feature are sparse,the minimum acceptable rank at this sparsity has a score of zero! we will return a mask thats smaller than you asked, by masking all parameters with a score of zero.\n",
      "original mask: 495254 params\n",
      "effective mask: 495254 params\n",
      "effective_sparsity: 1.0\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.71319580078125\n",
      "Target Sparsity: 0.9855536231884058\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9855536231884058\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34130      (total params * sparsity)\n",
      "original mask: 490690 params\n",
      "effective mask: 490681 params\n",
      "effective_sparsity: 0.9855327750505343\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.713529586791992\n",
      "Target Sparsity: 0.9712072463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9712072463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33633      (total params * sparsity)\n",
      "original mask: 485929 params\n",
      "effective mask: 485929 params\n",
      "effective_sparsity: 0.9712099335835981\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.711270332336426\n",
      "Target Sparsity: 0.9568608695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9568608695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33137      (total params * sparsity)\n",
      "original mask: 481353 params\n",
      "effective mask: 481344 params\n",
      "effective_sparsity: 0.9568582154201559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.725257873535156\n",
      "Target Sparsity: 0.9425144927536232\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9425144927536232\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32640      (total params * sparsity)\n",
      "original mask: 476672 params\n",
      "effective mask: 476654 params\n",
      "effective_sparsity: 0.9424776205602079\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.71635627746582\n",
      "Target Sparsity: 0.928168115942029\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.928168115942029\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32143      (total params * sparsity)\n",
      "original mask: 471991 params\n",
      "effective mask: 471964 params\n",
      "effective_sparsity: 0.9280970257002599\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.738451957702637\n",
      "Target Sparsity: 0.9138217391304349\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9138217391304349\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31646      (total params * sparsity)\n",
      "original mask: 467198 params\n",
      "effective mask: 466559 params\n",
      "effective_sparsity: 0.9117816921744153\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.74073314666748\n",
      "Target Sparsity: 0.8994753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8994753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31149      (total params * sparsity)\n",
      "original mask: 462149 params\n",
      "effective mask: 461627 params\n",
      "effective_sparsity: 0.8978053710655501\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.751522064208984\n",
      "Target Sparsity: 0.8851289855072464\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8851289855072464\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30653      (total params * sparsity)\n",
      "original mask: 457093 params\n",
      "effective mask: 456724 params\n",
      "effective_sparsity: 0.8839734334392145\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.801798820495605\n",
      "Target Sparsity: 0.8707826086956522\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8707826086956522\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30156      (total params * sparsity)\n",
      "original mask: 451708 params\n",
      "effective mask: 451447 params\n",
      "effective_sparsity: 0.8699682356338435\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.835655212402344\n",
      "Target Sparsity: 0.8564362318840579\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8564362318840579\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29659      (total params * sparsity)\n",
      "original mask: 446387 params\n",
      "effective mask: 446063 params\n",
      "effective_sparsity: 0.85541438059486\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.901954650878906\n",
      "Target Sparsity: 0.8420898550724638\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8420898550724638\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29162      (total params * sparsity)\n",
      "original mask: 441002 params\n",
      "effective mask: 440732 params\n",
      "effective_sparsity: 0.8412359226104533\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.972164154052734\n",
      "Target Sparsity: 0.8277434782608696\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8277434782608696\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28665      (total params * sparsity)\n",
      "original mask: 435185 params\n",
      "effective mask: 434987 params\n",
      "effective_sparsity: 0.8271152180190586\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.170416831970215\n",
      "Target Sparsity: 0.8133971014492754\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8133971014492754\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28168      (total params * sparsity)\n",
      "original mask: 429560 params\n",
      "effective mask: 429398 params\n",
      "effective_sparsity: 0.8128790066416401\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.251969337463379\n",
      "Target Sparsity: 0.7990507246376812\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7990507246376812\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27672      (total params * sparsity)\n",
      "original mask: 423752 params\n",
      "effective mask: 423608 params\n",
      "effective_sparsity: 0.7986139185677159\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.236799240112305\n",
      "Target Sparsity: 0.784704347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.784704347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27175      (total params * sparsity)\n",
      "original mask: 417791 params\n",
      "effective mask: 417548 params\n",
      "effective_sparsity: 0.7839445567427087\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.269322395324707\n",
      "Target Sparsity: 0.7703579710144928\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7703579710144928\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26678      (total params * sparsity)\n",
      "original mask: 411654 params\n",
      "effective mask: 411456 params\n",
      "effective_sparsity: 0.7697372220617962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.16871452331543\n",
      "Target Sparsity: 0.7560115942028985\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7560115942028985\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26181      (total params * sparsity)\n",
      "original mask: 405645 params\n",
      "effective mask: 405447 params\n",
      "effective_sparsity: 0.755385503898354\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.087080955505371\n",
      "Target Sparsity: 0.7416652173913043\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7416652173913043\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25684      (total params * sparsity)\n",
      "original mask: 399668 params\n",
      "effective mask: 399497 params\n",
      "effective_sparsity: 0.7411204158244297\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.00400161743164\n",
      "Target Sparsity: 0.7273188405797102\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7273188405797102\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25188      (total params * sparsity)\n",
      "original mask: 393716 params\n",
      "effective mask: 393599 params\n",
      "effective_sparsity: 0.726970834536529\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.949511528015137\n",
      "Target Sparsity: 0.712972463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.712972463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24691      (total params * sparsity)\n",
      "original mask: 387611 params\n",
      "effective mask: 387521 params\n",
      "effective_sparsity: 0.7127057464626047\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.90593147277832\n",
      "Target Sparsity: 0.6986260869565217\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6986260869565217\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24194      (total params * sparsity)\n",
      "original mask: 381026 params\n",
      "effective mask: 380936 params\n",
      "effective_sparsity: 0.6983540282991626\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.067347526550293\n",
      "Target Sparsity: 0.6842797101449276\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6842797101449276\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23697      (total params * sparsity)\n",
      "original mask: 374937 params\n",
      "effective mask: 374847 params\n",
      "effective_sparsity: 0.6840023101357204\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.891783714294434\n",
      "Target Sparsity: 0.6699333333333334\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6699333333333334\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23200      (total params * sparsity)\n",
      "original mask: 368528 params\n",
      "effective mask: 368384 params\n",
      "effective_sparsity: 0.6694773317932429\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.262052536010742\n",
      "Target Sparsity: 0.6555869565217392\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6555869565217392\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22703      (total params * sparsity)\n",
      "original mask: 362167 params\n",
      "effective mask: 362086 params\n",
      "effective_sparsity: 0.6553277505053422\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.003212928771973\n",
      "Target Sparsity: 0.6412405797101449\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6412405797101449\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22207      (total params * sparsity)\n",
      "original mask: 356055 params\n",
      "effective mask: 355974 params\n",
      "effective_sparsity: 0.641004909038406\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.517256736755371\n",
      "Target Sparsity: 0.6268942028985507\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6268942028985507\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21710      (total params * sparsity)\n",
      "original mask: 349438 params\n",
      "effective mask: 349384 params\n",
      "effective_sparsity: 0.6267398209644817\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.041136741638184\n",
      "Target Sparsity: 0.6125478260869566\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6125478260869566\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21213      (total params * sparsity)\n",
      "original mask: 342965 params\n",
      "effective mask: 342902 params\n",
      "effective_sparsity: 0.6123592261045336\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.138045310974121\n",
      "Target Sparsity: 0.5982014492753623\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5982014492753623\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20716      (total params * sparsity)\n",
      "original mask: 336556 params\n",
      "effective mask: 336475 params\n",
      "effective_sparsity: 0.5979497545480797\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.23802375793457\n",
      "Target Sparsity: 0.5838550724637681\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5838550724637681\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20219      (total params * sparsity)\n",
      "original mask: 329715 params\n",
      "effective mask: 329643 params\n",
      "effective_sparsity: 0.5836269130811436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.16673755645752\n",
      "Target Sparsity: 0.569508695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.569508695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19723      (total params * sparsity)\n",
      "original mask: 323411 params\n",
      "effective mask: 323303 params\n",
      "effective_sparsity: 0.5691885648281837\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.06464958190918\n",
      "Target Sparsity: 0.5551623188405798\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5551623188405798\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19226      (total params * sparsity)\n",
      "original mask: 316730 params\n",
      "effective mask: 316586 params\n",
      "effective_sparsity: 0.5547213398787179\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.410054206848145\n",
      "Target Sparsity: 0.5408159420289855\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5408159420289855\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18729      (total params * sparsity)\n",
      "original mask: 310097 params\n",
      "effective mask: 309926 params\n",
      "effective_sparsity: 0.540282991625758\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.403825759887695\n",
      "Target Sparsity: 0.5264695652173913\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5264695652173913\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18232      (total params * sparsity)\n",
      "original mask: 303208 params\n",
      "effective mask: 303073 params\n",
      "effective_sparsity: 0.5260467802483396\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.196950912475586\n",
      "Target Sparsity: 0.5121231884057971\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5121231884057971\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17735      (total params * sparsity)\n",
      "original mask: 296079 params\n",
      "effective mask: 295944 params\n",
      "effective_sparsity: 0.5116950620848975\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.22427749633789\n",
      "Target Sparsity: 0.49777681159420295\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.49777681159420295\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17239      (total params * sparsity)\n",
      "original mask: 289151 params\n",
      "effective mask: 289007 params\n",
      "effective_sparsity: 0.4973433439214554\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.157938003540039\n",
      "Target Sparsity: 0.4834304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4834304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16742      (total params * sparsity)\n",
      "original mask: 281990 params\n",
      "effective mask: 281837 params\n",
      "effective_sparsity: 0.4829627490615074\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.212690353393555\n",
      "Target Sparsity: 0.4690840579710145\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4690840579710145\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16245      (total params * sparsity)\n",
      "original mask: 274845 params\n",
      "effective mask: 274611 params\n",
      "effective_sparsity: 0.468351140629512\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 12.110540390014648\n",
      "Target Sparsity: 0.45473768115942037\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.45473768115942037\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15748      (total params * sparsity)\n",
      "original mask: 267476 params\n",
      "effective mask: 267206 params\n",
      "effective_sparsity: 0.4538839156800462\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.833878517150879\n",
      "Target Sparsity: 0.44039130434782614\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.44039130434782614\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15251      (total params * sparsity)\n",
      "original mask: 260219 params\n",
      "effective mask: 259940 params\n",
      "effective_sparsity: 0.4395033208200982\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.73537826538086\n",
      "Target Sparsity: 0.4260449275362319\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4260449275362319\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14754      (total params * sparsity)\n",
      "original mask: 253058 params\n",
      "effective mask: 252716 params\n",
      "effective_sparsity: 0.42494946578111464\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.936075210571289\n",
      "Target Sparsity: 0.4116985507246377\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4116985507246377\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14258      (total params * sparsity)\n",
      "original mask: 246018 params\n",
      "effective mask: 245676 params\n",
      "effective_sparsity: 0.41062662431417846\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.77259635925293\n",
      "Target Sparsity: 0.39735217391304345\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.39735217391304345\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13761      (total params * sparsity)\n",
      "original mask: 238585 params\n",
      "effective mask: 238279 params\n",
      "effective_sparsity: 0.39639041293676003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.205546379089355\n",
      "Target Sparsity: 0.38300579710144933\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.38300579710144933\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13264      (total params * sparsity)\n",
      "original mask: 231088 params\n",
      "effective mask: 230773 params\n",
      "effective_sparsity: 0.382009818076812\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.595641136169434\n",
      "Target Sparsity: 0.3686594202898551\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3686594202898551\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12767      (total params * sparsity)\n",
      "original mask: 223399 params\n",
      "effective mask: 222949 params\n",
      "effective_sparsity: 0.3672249494657811\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.493386268615723\n",
      "Target Sparsity: 0.35431304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.35431304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12270      (total params * sparsity)\n",
      "original mask: 215966 params\n",
      "effective mask: 215570 params\n",
      "effective_sparsity: 0.3530464914813745\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.09237289428711\n",
      "Target Sparsity: 0.33996666666666675\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.33996666666666675\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11774      (total params * sparsity)\n",
      "original mask: 208094 params\n",
      "effective mask: 207689 params\n",
      "effective_sparsity: 0.3386947733179324\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.49948501586914\n",
      "Target Sparsity: 0.3256202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3256202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11277      (total params * sparsity)\n",
      "original mask: 200309 params\n",
      "effective mask: 199890 params\n",
      "effective_sparsity: 0.32440080854750214\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.914382934570312\n",
      "Target Sparsity: 0.3112739130434783\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3112739130434783\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10780      (total params * sparsity)\n",
      "original mask: 192620 params\n",
      "effective mask: 192228 params\n",
      "effective_sparsity: 0.31013572047357785\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.96617603302002\n",
      "Target Sparsity: 0.29692753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.29692753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10283      (total params * sparsity)\n",
      "original mask: 184851 params\n",
      "effective mask: 184466 params\n",
      "effective_sparsity: 0.2957551256136298\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.26201343536377\n",
      "Target Sparsity: 0.28258115942028983\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.28258115942028983\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9786      (total params * sparsity)\n",
      "original mask: 177018 params\n",
      "effective mask: 176613 params\n",
      "effective_sparsity: 0.28128790066416404\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.961714744567871\n",
      "Target Sparsity: 0.2682347826086957\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2682347826086957\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9289      (total params * sparsity)\n",
      "original mask: 169265 params\n",
      "effective mask: 168835 params\n",
      "effective_sparsity: 0.266907305804216\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.53211498260498\n",
      "Target Sparsity: 0.2538884057971015\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2538884057971015\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8793      (total params * sparsity)\n",
      "original mask: 161441 params\n",
      "effective mask: 161011 params\n",
      "effective_sparsity: 0.2525844643372798\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.76717758178711\n",
      "Target Sparsity: 0.23954202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.23954202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8296      (total params * sparsity)\n",
      "original mask: 153128 params\n",
      "effective mask: 152644 params\n",
      "effective_sparsity: 0.2380594859948022\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.917582511901855\n",
      "Target Sparsity: 0.22519565217391313\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.22519565217391313\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7799      (total params * sparsity)\n",
      "original mask: 144671 params\n",
      "effective mask: 144230 params\n",
      "effective_sparsity: 0.22379439792087785\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.801872253417969\n",
      "Target Sparsity: 0.2108492753623189\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2108492753623189\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7302      (total params * sparsity)\n",
      "original mask: 136582 params\n",
      "effective mask: 135839 params\n",
      "effective_sparsity: 0.20903840600635287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.186594009399414\n",
      "Target Sparsity: 0.19650289855072467\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.19650289855072467\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6805      (total params * sparsity)\n",
      "original mask: 128141 params\n",
      "effective mask: 127142 params\n",
      "effective_sparsity: 0.19376263355472134\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.1082181930542\n",
      "Target Sparsity: 0.18215652173913044\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.18215652173913044\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6309      (total params * sparsity)\n",
      "original mask: 119485 params\n",
      "effective mask: 118599 params\n",
      "effective_sparsity: 0.17969968235633843\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.156471252441406\n",
      "Target Sparsity: 0.1678101449275362\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1678101449275362\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5812      (total params * sparsity)\n",
      "original mask: 111140 params\n",
      "effective mask: 110115 params\n",
      "effective_sparsity: 0.16479930695928385\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.261236190795898\n",
      "Target Sparsity: 0.1534637681159421\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1534637681159421\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5315      (total params * sparsity)\n",
      "original mask: 102587 params\n",
      "effective mask: 101454 params\n",
      "effective_sparsity: 0.1501010684377707\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.9107441902160645\n",
      "Target Sparsity: 0.13911739130434786\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.13911739130434786\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4818      (total params * sparsity)\n",
      "original mask: 94210 params\n",
      "effective mask: 93030 params\n",
      "effective_sparsity: 0.13554721339878717\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.5403547286987305\n",
      "Target Sparsity: 0.12477101449275363\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.12477101449275363\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4321      (total params * sparsity)\n",
      "original mask: 85849 params\n",
      "effective mask: 84606 params\n",
      "effective_sparsity: 0.12099335835980364\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.466476917266846\n",
      "Target Sparsity: 0.11042463768115951\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.11042463768115951\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3825      (total params * sparsity)\n",
      "original mask: 76921 params\n",
      "effective mask: 74376 params\n",
      "effective_sparsity: 0.10511117528154779\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.350627899169922\n",
      "Target Sparsity: 0.09607826086956528\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.09607826086956528\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3328      (total params * sparsity)\n",
      "original mask: 67616 params\n",
      "effective mask: 64669 params\n",
      "effective_sparsity: 0.0893156222928097\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 3.8772475719451904\n",
      "Target Sparsity: 0.08173188405797105\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.08173188405797105\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2831      (total params * sparsity)\n",
      "original mask: 58423 params\n",
      "effective mask: 55592 params\n",
      "effective_sparsity: 0.07507941091539128\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.182490348815918\n",
      "Target Sparsity: 0.06738550724637682\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.06738550724637682\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2334      (total params * sparsity)\n",
      "original mask: 48398 params\n",
      "effective mask: 44541 params\n",
      "effective_sparsity: 0.05835980363846376\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.050108909606934\n",
      "Target Sparsity: 0.05303913043478259\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.05303913043478259\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1837      (total params * sparsity)\n",
      "original mask: 38421 params\n",
      "effective mask: 33857 params\n",
      "effective_sparsity: 0.04184233323707768\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.979050636291504\n",
      "Target Sparsity: 0.03869275362318847\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.03869275362318847\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1340      (total params * sparsity)\n",
      "original mask: 29084 params\n",
      "effective mask: 24552 params\n",
      "effective_sparsity: 0.027490615073635576\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 3.6195669174194336\n",
      "Target Sparsity: 0.02434637681159424\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.02434637681159424\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 844      (total params * sparsity)\n",
      "original mask: 18268 params\n",
      "effective mask: 13454 params\n",
      "effective_sparsity: 0.014265088073924343\n",
      "features_8 effective last layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average circuit acts:\n",
      "feature features_8:0: 0.7133192420005798\n",
      "Target Sparsity: 0.01\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.01\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 347      (total params * sparsity)\n",
      "original mask: 7619 params\n",
      "effective mask: 3013 params\n",
      "effective_sparsity: 0.002685532775050534\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 0.9373914003372192\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "right\n",
      "right\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original\n",
      "features_8 effective last layer\n",
      "average orig acts:\n",
      "feature features_8:0: 10.785665512084961\n",
      "Target Sparsity: 0.9999\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9999\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34627      (total params * sparsity)\n",
      "gradients from this feature are sparse,the minimum acceptable rank at this sparsity has a score of zero! we will return a mask thats smaller than you asked, by masking all parameters with a score of zero.\n",
      "original mask: 495254 params\n",
      "effective mask: 495254 params\n",
      "effective_sparsity: 1.0\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.785665512084961\n",
      "Target Sparsity: 0.9855536231884058\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9855536231884058\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 34130      (total params * sparsity)\n",
      "original mask: 490690 params\n",
      "effective mask: 490681 params\n",
      "effective_sparsity: 0.9855327750505343\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.785645484924316\n",
      "Target Sparsity: 0.9712072463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9712072463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33633      (total params * sparsity)\n",
      "original mask: 485929 params\n",
      "effective mask: 485929 params\n",
      "effective_sparsity: 0.9712099335835981\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.786874771118164\n",
      "Target Sparsity: 0.9568608695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9568608695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 33137      (total params * sparsity)\n",
      "original mask: 481353 params\n",
      "effective mask: 481344 params\n",
      "effective_sparsity: 0.9568582154201559\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.788392066955566\n",
      "Target Sparsity: 0.9425144927536232\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9425144927536232\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32640      (total params * sparsity)\n",
      "original mask: 476672 params\n",
      "effective mask: 476654 params\n",
      "effective_sparsity: 0.9424776205602079\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.77756118774414\n",
      "Target Sparsity: 0.928168115942029\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.928168115942029\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 32143      (total params * sparsity)\n",
      "original mask: 471991 params\n",
      "effective mask: 471964 params\n",
      "effective_sparsity: 0.9280970257002599\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.786969184875488\n",
      "Target Sparsity: 0.9138217391304349\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.9138217391304349\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31646      (total params * sparsity)\n",
      "original mask: 467198 params\n",
      "effective mask: 466559 params\n",
      "effective_sparsity: 0.9117816921744153\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.790038108825684\n",
      "Target Sparsity: 0.8994753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8994753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 31149      (total params * sparsity)\n",
      "original mask: 462149 params\n",
      "effective mask: 461627 params\n",
      "effective_sparsity: 0.8978053710655501\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.805858612060547\n",
      "Target Sparsity: 0.8851289855072464\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8851289855072464\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30653      (total params * sparsity)\n",
      "original mask: 457093 params\n",
      "effective mask: 456724 params\n",
      "effective_sparsity: 0.8839734334392145\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.836125373840332\n",
      "Target Sparsity: 0.8707826086956522\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8707826086956522\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 30156      (total params * sparsity)\n",
      "original mask: 451708 params\n",
      "effective mask: 451447 params\n",
      "effective_sparsity: 0.8699682356338435\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.861949920654297\n",
      "Target Sparsity: 0.8564362318840579\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8564362318840579\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29659      (total params * sparsity)\n",
      "original mask: 446387 params\n",
      "effective mask: 446063 params\n",
      "effective_sparsity: 0.85541438059486\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.902737617492676\n",
      "Target Sparsity: 0.8420898550724638\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8420898550724638\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 29162      (total params * sparsity)\n",
      "original mask: 441002 params\n",
      "effective mask: 440732 params\n",
      "effective_sparsity: 0.8412359226104533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.957487106323242\n",
      "Target Sparsity: 0.8277434782608696\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8277434782608696\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28665      (total params * sparsity)\n",
      "original mask: 435185 params\n",
      "effective mask: 434987 params\n",
      "effective_sparsity: 0.8271152180190586\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.100018501281738\n",
      "Target Sparsity: 0.8133971014492754\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.8133971014492754\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 28168      (total params * sparsity)\n",
      "original mask: 429560 params\n",
      "effective mask: 429398 params\n",
      "effective_sparsity: 0.8128790066416401\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.167884826660156\n",
      "Target Sparsity: 0.7990507246376812\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7990507246376812\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27672      (total params * sparsity)\n",
      "original mask: 423752 params\n",
      "effective mask: 423608 params\n",
      "effective_sparsity: 0.7986139185677159\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.11967658996582\n",
      "Target Sparsity: 0.784704347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.784704347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 27175      (total params * sparsity)\n",
      "original mask: 417791 params\n",
      "effective mask: 417548 params\n",
      "effective_sparsity: 0.7839445567427087\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.085368156433105\n",
      "Target Sparsity: 0.7703579710144928\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7703579710144928\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26678      (total params * sparsity)\n",
      "original mask: 411654 params\n",
      "effective mask: 411456 params\n",
      "effective_sparsity: 0.7697372220617962\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.012995719909668\n",
      "Target Sparsity: 0.7560115942028985\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7560115942028985\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 26181      (total params * sparsity)\n",
      "original mask: 405645 params\n",
      "effective mask: 405447 params\n",
      "effective_sparsity: 0.755385503898354\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.970130920410156\n",
      "Target Sparsity: 0.7416652173913043\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7416652173913043\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25684      (total params * sparsity)\n",
      "original mask: 399668 params\n",
      "effective mask: 399497 params\n",
      "effective_sparsity: 0.7411204158244297\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.947504043579102\n",
      "Target Sparsity: 0.7273188405797102\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.7273188405797102\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 25188      (total params * sparsity)\n",
      "original mask: 393716 params\n",
      "effective mask: 393599 params\n",
      "effective_sparsity: 0.726970834536529\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.886606216430664\n",
      "Target Sparsity: 0.712972463768116\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.712972463768116\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24691      (total params * sparsity)\n",
      "original mask: 387611 params\n",
      "effective mask: 387521 params\n",
      "effective_sparsity: 0.7127057464626047\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.900378227233887\n",
      "Target Sparsity: 0.6986260869565217\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6986260869565217\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 24194      (total params * sparsity)\n",
      "original mask: 381026 params\n",
      "effective mask: 380936 params\n",
      "effective_sparsity: 0.6983540282991626\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.995170593261719\n",
      "Target Sparsity: 0.6842797101449276\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6842797101449276\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23697      (total params * sparsity)\n",
      "original mask: 374937 params\n",
      "effective mask: 374847 params\n",
      "effective_sparsity: 0.6840023101357204\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.848337173461914\n",
      "Target Sparsity: 0.6699333333333334\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6699333333333334\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 23200      (total params * sparsity)\n",
      "original mask: 368528 params\n",
      "effective mask: 368384 params\n",
      "effective_sparsity: 0.6694773317932429\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.181544303894043\n",
      "Target Sparsity: 0.6555869565217392\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6555869565217392\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22703      (total params * sparsity)\n",
      "original mask: 362167 params\n",
      "effective mask: 362086 params\n",
      "effective_sparsity: 0.6553277505053422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.06725025177002\n",
      "Target Sparsity: 0.6412405797101449\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6412405797101449\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 22207      (total params * sparsity)\n",
      "original mask: 356055 params\n",
      "effective mask: 355974 params\n",
      "effective_sparsity: 0.641004909038406\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.600881576538086\n",
      "Target Sparsity: 0.6268942028985507\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6268942028985507\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21710      (total params * sparsity)\n",
      "original mask: 349438 params\n",
      "effective mask: 349384 params\n",
      "effective_sparsity: 0.6267398209644817\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.137796401977539\n",
      "Target Sparsity: 0.6125478260869566\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.6125478260869566\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 21213      (total params * sparsity)\n",
      "original mask: 342965 params\n",
      "effective mask: 342902 params\n",
      "effective_sparsity: 0.6123592261045336\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.203624725341797\n",
      "Target Sparsity: 0.5982014492753623\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5982014492753623\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20716      (total params * sparsity)\n",
      "original mask: 336556 params\n",
      "effective mask: 336475 params\n",
      "effective_sparsity: 0.5979497545480797\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.494932174682617\n",
      "Target Sparsity: 0.5838550724637681\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5838550724637681\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 20219      (total params * sparsity)\n",
      "original mask: 329715 params\n",
      "effective mask: 329643 params\n",
      "effective_sparsity: 0.5836269130811436\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.573942184448242\n",
      "Target Sparsity: 0.569508695652174\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.569508695652174\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19723      (total params * sparsity)\n",
      "original mask: 323411 params\n",
      "effective mask: 323303 params\n",
      "effective_sparsity: 0.5691885648281837\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.284767150878906\n",
      "Target Sparsity: 0.5551623188405798\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5551623188405798\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 19226      (total params * sparsity)\n",
      "original mask: 316730 params\n",
      "effective mask: 316586 params\n",
      "effective_sparsity: 0.5547213398787179\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.728761672973633\n",
      "Target Sparsity: 0.5408159420289855\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5408159420289855\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18729      (total params * sparsity)\n",
      "original mask: 310097 params\n",
      "effective mask: 309926 params\n",
      "effective_sparsity: 0.540282991625758\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.71475601196289\n",
      "Target Sparsity: 0.5264695652173913\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5264695652173913\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 18232      (total params * sparsity)\n",
      "original mask: 303208 params\n",
      "effective mask: 303073 params\n",
      "effective_sparsity: 0.5260467802483396\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.529375076293945\n",
      "Target Sparsity: 0.5121231884057971\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.5121231884057971\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17735      (total params * sparsity)\n",
      "original mask: 296079 params\n",
      "effective mask: 295944 params\n",
      "effective_sparsity: 0.5116950620848975\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.608635902404785\n",
      "Target Sparsity: 0.49777681159420295\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.49777681159420295\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 17239      (total params * sparsity)\n",
      "original mask: 289151 params\n",
      "effective mask: 289007 params\n",
      "effective_sparsity: 0.4973433439214554\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.588507652282715\n",
      "Target Sparsity: 0.4834304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4834304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16742      (total params * sparsity)\n",
      "original mask: 281990 params\n",
      "effective mask: 281837 params\n",
      "effective_sparsity: 0.4829627490615074\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.684477806091309\n",
      "Target Sparsity: 0.4690840579710145\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4690840579710145\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 16245      (total params * sparsity)\n",
      "original mask: 274845 params\n",
      "effective mask: 274611 params\n",
      "effective_sparsity: 0.468351140629512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.474114418029785\n",
      "Target Sparsity: 0.45473768115942037\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.45473768115942037\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15748      (total params * sparsity)\n",
      "original mask: 267476 params\n",
      "effective mask: 267206 params\n",
      "effective_sparsity: 0.4538839156800462\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.114091873168945\n",
      "Target Sparsity: 0.44039130434782614\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.44039130434782614\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 15251      (total params * sparsity)\n",
      "original mask: 260219 params\n",
      "effective mask: 259940 params\n",
      "effective_sparsity: 0.4395033208200982\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.101767539978027\n",
      "Target Sparsity: 0.4260449275362319\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4260449275362319\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14754      (total params * sparsity)\n",
      "original mask: 253058 params\n",
      "effective mask: 252716 params\n",
      "effective_sparsity: 0.42494946578111464\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.533772468566895\n",
      "Target Sparsity: 0.4116985507246377\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.4116985507246377\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 14258      (total params * sparsity)\n",
      "original mask: 246018 params\n",
      "effective mask: 245676 params\n",
      "effective_sparsity: 0.41062662431417846\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.309690475463867\n",
      "Target Sparsity: 0.39735217391304345\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.39735217391304345\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13761      (total params * sparsity)\n",
      "original mask: 238585 params\n",
      "effective mask: 238279 params\n",
      "effective_sparsity: 0.39639041293676003\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.966275215148926\n",
      "Target Sparsity: 0.38300579710144933\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.38300579710144933\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 13264      (total params * sparsity)\n",
      "original mask: 231088 params\n",
      "effective mask: 230773 params\n",
      "effective_sparsity: 0.382009818076812\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.241847038269043\n",
      "Target Sparsity: 0.3686594202898551\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3686594202898551\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12767      (total params * sparsity)\n",
      "original mask: 223399 params\n",
      "effective mask: 222949 params\n",
      "effective_sparsity: 0.3672249494657811\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 11.201532363891602\n",
      "Target Sparsity: 0.35431304347826087\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.35431304347826087\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 12270      (total params * sparsity)\n",
      "original mask: 215966 params\n",
      "effective mask: 215570 params\n",
      "effective_sparsity: 0.3530464914813745\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.715521812438965\n",
      "Target Sparsity: 0.33996666666666675\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.33996666666666675\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11774      (total params * sparsity)\n",
      "original mask: 208094 params\n",
      "effective mask: 207689 params\n",
      "effective_sparsity: 0.3386947733179324\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.395785331726074\n",
      "Target Sparsity: 0.3256202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3256202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 11277      (total params * sparsity)\n",
      "original mask: 200309 params\n",
      "effective mask: 199890 params\n",
      "effective_sparsity: 0.32440080854750214\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.987419128417969\n",
      "Target Sparsity: 0.3112739130434783\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.3112739130434783\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10780      (total params * sparsity)\n",
      "original mask: 192620 params\n",
      "effective mask: 192228 params\n",
      "effective_sparsity: 0.31013572047357785\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.05519962310791\n",
      "Target Sparsity: 0.29692753623188406\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.29692753623188406\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 10283      (total params * sparsity)\n",
      "original mask: 184851 params\n",
      "effective mask: 184466 params\n",
      "effective_sparsity: 0.2957551256136298\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.46715259552002\n",
      "Target Sparsity: 0.28258115942028983\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.28258115942028983\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9786      (total params * sparsity)\n",
      "original mask: 177018 params\n",
      "effective mask: 176613 params\n",
      "effective_sparsity: 0.28128790066416404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.060312271118164\n",
      "Target Sparsity: 0.2682347826086957\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2682347826086957\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 9289      (total params * sparsity)\n",
      "original mask: 169265 params\n",
      "effective mask: 168835 params\n",
      "effective_sparsity: 0.266907305804216\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 10.38931655883789\n",
      "Target Sparsity: 0.2538884057971015\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2538884057971015\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8793      (total params * sparsity)\n",
      "original mask: 161441 params\n",
      "effective mask: 161011 params\n",
      "effective_sparsity: 0.2525844643372798\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.476128578186035\n",
      "Target Sparsity: 0.23954202898550725\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.23954202898550725\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8296      (total params * sparsity)\n",
      "original mask: 153128 params\n",
      "effective mask: 152644 params\n",
      "effective_sparsity: 0.2380594859948022\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.98625659942627\n",
      "Target Sparsity: 0.22519565217391313\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.22519565217391313\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7799      (total params * sparsity)\n",
      "original mask: 144671 params\n",
      "effective mask: 144230 params\n",
      "effective_sparsity: 0.22379439792087785\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.350921630859375\n",
      "Target Sparsity: 0.2108492753623189\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.2108492753623189\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 7302      (total params * sparsity)\n",
      "original mask: 136582 params\n",
      "effective mask: 135839 params\n",
      "effective_sparsity: 0.20903840600635287\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 9.037779808044434\n",
      "Target Sparsity: 0.19650289855072467\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.19650289855072467\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6805      (total params * sparsity)\n",
      "original mask: 128141 params\n",
      "effective mask: 127142 params\n",
      "effective_sparsity: 0.19376263355472134\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 8.868549346923828\n",
      "Target Sparsity: 0.18215652173913044\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.18215652173913044\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 6309      (total params * sparsity)\n",
      "original mask: 119485 params\n",
      "effective mask: 118599 params\n",
      "effective_sparsity: 0.17969968235633843\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 7.740830898284912\n",
      "Target Sparsity: 0.1678101449275362\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1678101449275362\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5812      (total params * sparsity)\n",
      "original mask: 111140 params\n",
      "effective mask: 110115 params\n",
      "effective_sparsity: 0.16479930695928385\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.758028507232666\n",
      "Target Sparsity: 0.1534637681159421\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.1534637681159421\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 5315      (total params * sparsity)\n",
      "original mask: 102587 params\n",
      "effective mask: 101454 params\n",
      "effective_sparsity: 0.1501010684377707\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.917745113372803\n",
      "Target Sparsity: 0.13911739130434786\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.13911739130434786\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4818      (total params * sparsity)\n",
      "original mask: 94210 params\n",
      "effective mask: 93030 params\n",
      "effective_sparsity: 0.13554721339878717\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.914658069610596\n",
      "Target Sparsity: 0.12477101449275363\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.12477101449275363\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 4321      (total params * sparsity)\n",
      "original mask: 85849 params\n",
      "effective mask: 84606 params\n",
      "effective_sparsity: 0.12099335835980364\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 5.373974323272705\n",
      "Target Sparsity: 0.11042463768115951\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.11042463768115951\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3825      (total params * sparsity)\n",
      "original mask: 76921 params\n",
      "effective mask: 74376 params\n",
      "effective_sparsity: 0.10511117528154779\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.706872463226318\n",
      "Target Sparsity: 0.09607826086956528\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.09607826086956528\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 3328      (total params * sparsity)\n",
      "original mask: 67616 params\n",
      "effective mask: 64669 params\n",
      "effective_sparsity: 0.0893156222928097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.323014259338379\n",
      "Target Sparsity: 0.08173188405797105\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.08173188405797105\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2831      (total params * sparsity)\n",
      "original mask: 58423 params\n",
      "effective mask: 55592 params\n",
      "effective_sparsity: 0.07507941091539128\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.359879493713379\n",
      "Target Sparsity: 0.06738550724637682\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.06738550724637682\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 2334      (total params * sparsity)\n",
      "original mask: 48398 params\n",
      "effective mask: 44541 params\n",
      "effective_sparsity: 0.05835980363846376\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 6.871334075927734\n",
      "Target Sparsity: 0.05303913043478259\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.05303913043478259\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1837      (total params * sparsity)\n",
      "original mask: 38421 params\n",
      "effective mask: 33857 params\n",
      "effective_sparsity: 0.04184233323707768\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 4.4109296798706055\n",
      "Target Sparsity: 0.03869275362318847\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.03869275362318847\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 1340      (total params * sparsity)\n",
      "original mask: 29084 params\n",
      "effective mask: 24552 params\n",
      "effective_sparsity: 0.027490615073635576\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 3.2291080951690674\n",
      "Target Sparsity: 0.02434637681159424\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.02434637681159424\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 844      (total params * sparsity)\n",
      "original mask: 18268 params\n",
      "effective mask: 13454 params\n",
      "effective_sparsity: 0.014265088073924343\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 1.517086148262024\n",
      "Target Sparsity: 0.01\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.01\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 347      (total params * sparsity)\n",
      "original mask: 7619 params\n",
      "effective mask: 3013 params\n",
      "effective_sparsity: 0.002685532775050534\n",
      "features_8 effective last layer\n",
      "average circuit acts:\n",
      "feature features_8:0: 0.6289452314376831\n"
     ]
    }
   ],
   "source": [
    "from circuit_pruner.extraction import get_preservation_at_sparsities\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "structure='kernels'\n",
    "\n",
    "sparsities = np.linspace(.9999, .01, num=70)\n",
    "\n",
    "model_sparsities = []\n",
    "for sparsity in sparsities:\n",
    "    model_sparsities.append(sparsity*general_circuit_sparsity_factor) \n",
    "\n",
    "\n",
    "scores = {'front_circuit':{},\n",
    "          'left_circuit':{},\n",
    "          'right_circuit':{},\n",
    "          'profile_circuit':{},\n",
    "         }\n",
    "\n",
    "for rank_aspect in aspects:\n",
    "    for data_aspect in aspects:\n",
    "        print('\\n\\n\\n')\n",
    "        print(rank_aspect)\n",
    "        print(data_aspect)\n",
    "        print('\\n\\n\\n')\n",
    "        scores[rank_aspect+'_circuit'][data_aspect+'_data'] = get_preservation_at_sparsities(\n",
    "            \n",
    "                                                                general_circuit,\n",
    "                                                                ranks[rank_aspect],\n",
    "                                                                circuit_feature_targets,\n",
    "                                                                dataloaders[data_aspect],\n",
    "                                                                sparsities,device,metric='all',\n",
    "                                                                rank_field = target_position,\n",
    "                                                                structure=structure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4188ed57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['spearman', 'pearson', 'avg_diff', 'avg_abs_diff', 'std_normed_diff', 'mean_normed_diff', 'std_normed_abs_diff'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['front_circuit']['front_data'][layer+':0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1948584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#pickle.dump(scores,open('face_front_profile_scores','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76fb742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "scores = pickle.load(open('face_front_profile_scores','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27d7f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sparsities = np.linspace(.9999, .01, num=70)\n",
    "\n",
    "model_sparsities = []\n",
    "for sparsity in sparsities:\n",
    "    model_sparsities.append(sparsity*general_circuit_sparsity_factor) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf1c0819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#4C78A8",
          "width": 12
         },
         "name": "front_circuit : front_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          1.7382586520398036e-05,
          1.3952414519735612e-05,
          0.003590772859752178,
          -6.241133814910427e-05,
          0.00029292277758941054,
          0.0002940017729997635,
          0.0014650659868493676,
          0.0015135830035433173,
          0.012249858118593693,
          0.01962275058031082,
          0.0024858496617525816,
          0.0023447966668754816,
          0.0029333310667425394,
          0.003482875879853964,
          0.0013241772539913654,
          -0.0032043384853750467,
          -0.008814465254545212,
          -0.004760937765240669,
          -0.011306611821055412,
          -0.022814471274614334,
          -0.0007347544305957854,
          0.0008744319202378392,
          -0.05922714248299599,
          -0.05293833464384079,
          -0.04132775589823723,
          -0.027838345617055893,
          -0.016284329816699028,
          -0.02555745095014572,
          0.06233064830303192,
          0.05773207172751427,
          0.045901112258434296,
          0.04111229255795479,
          0.042728595435619354,
          0.029567552730441093,
          0.02390158735215664,
          0.004080836195498705,
          -0.010823821648955345,
          -0.0182026457041502,
          -0.01533504854887724,
          -0.04601885750889778,
          -0.0593382753431797,
          -0.0790891945362091,
          -0.09080187976360321,
          -0.08797898143529892,
          -0.11485762149095535,
          -0.0785399079322815,
          -0.08005953580141068,
          -0.048308905214071274,
          -0.03391754627227783,
          -0.01231662929058075,
          -0.022311383858323097,
          0.02537335641682148,
          -0.02341223508119583,
          -0.11858195811510086,
          -0.1548890918493271,
          -0.21237654983997345,
          -0.20309826731681824,
          -0.2605537176132202,
          -0.3019435703754425,
          -0.42584261298179626,
          -0.5050730109214783,
          -0.5804826617240906,
          -0.5447521805763245,
          -0.5082824230194092,
          -0.5608110427856445,
          -0.3371371328830719,
          -0.5418956279754639,
          -0.6379358172416687,
          -0.7070026993751526
         ]
        },
        {
         "line": {
          "color": "#4C78A8",
          "dash": "dash",
          "width": 12
         },
         "name": "front_circuit : left_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          -0.0011161925503984094,
          -0.0015589171089231968,
          0.007133193779736757,
          -0.001196734025143087,
          0.0011595601681619883,
          0.00299309054389596,
          0.01500080805271864,
          0.014129800722002983,
          0.026297742500901222,
          0.02297896519303322,
          0.001162663334980607,
          0.003078927518799901,
          0.0003731928300112486,
          0.00272726290859282,
          -0.004642189480364323,
          -0.006749721243977547,
          -0.016575289890170097,
          -0.008229461498558521,
          -0.015799304470419884,
          -0.0320611335337162,
          0.0009316981304436922,
          0.010871784761548042,
          -0.07064809650182724,
          -0.058935850858688354,
          -0.02973121963441372,
          -0.02957853302359581,
          -0.010161051526665688,
          -0.03207213431596756,
          0.09748845547437668,
          0.08218326419591904,
          0.0691845715045929,
          0.06494417041540146,
          0.05468206852674484,
          0.028639551252126694,
          0.029739167541265488,
          0.0018418856197968125,
          -0.015391020104289055,
          -0.04400591924786568,
          -0.05857454985380173,
          -0.114056296646595,
          -0.13497328758239746,
          -0.17799974977970123,
          -0.21537548303604126,
          -0.22479909658432007,
          -0.26020699739456177,
          -0.22501297295093536,
          -0.23348066210746765,
          -0.18031270802021027,
          -0.144323468208313,
          -0.12816143035888672,
          -0.16548343002796173,
          -0.10322947800159454,
          -0.1578381210565567,
          -0.268416166305542,
          -0.2789369225502014,
          -0.37754571437835693,
          -0.37348079681396484,
          -0.4180731773376465,
          -0.485443651676178,
          -0.5752413272857666,
          -0.6185914278030396,
          -0.6363544464111328,
          -0.5809557437896729,
          -0.5083438158035278,
          -0.500476062297821,
          -0.25848114490509033,
          -0.43064144253730774,
          -0.5046852231025696,
          -0.530437171459198
         ]
        },
        {
         "line": {
          "color": "#4C78A8",
          "dash": "dot",
          "width": 12
         },
         "name": "front_circuit : right_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          -0.000477004999993369,
          -0.0012201049830764532,
          0.007494035642594099,
          -0.0027288049459457397,
          -0.0009433611994609237,
          -0.0027262894436717033,
          0.0028577407356351614,
          0.004253392107784748,
          0.03342963010072708,
          0.04733992740511894,
          0.01165549922734499,
          0.0010445384541526437,
          0.0005493889329954982,
          -0.004188972990959883,
          -0.006844231393188238,
          -0.007417984772473574,
          -0.012765186838805676,
          -0.004624729976058006,
          -0.02199692651629448,
          -0.04719765856862068,
          -0.020085226744413376,
          -0.011231852695345879,
          -0.08753973245620728,
          -0.07756978273391724,
          -0.05000559985637665,
          -0.025737712159752846,
          0.0006543870549649,
          -0.013986589387059212,
          0.10494954138994217,
          0.10293802618980408,
          0.0745270699262619,
          0.07602532207965851,
          0.07180071622133255,
          0.04910240322351456,
          0.05211948603391647,
          0.023756926879286766,
          0.0011223251931369305,
          -0.017623171210289,
          -0.022782975807785988,
          -0.08581534028053284,
          -0.11146910488605499,
          -0.14603060483932495,
          -0.16201665997505188,
          -0.16386593878269196,
          -0.20447155833244324,
          -0.16823546588420868,
          -0.17174623906612396,
          -0.12729206681251526,
          -0.06750688701868057,
          -0.06335151940584183,
          -0.09123387187719345,
          0.0026488257572054863,
          -0.05447673052549362,
          -0.21803885698318481,
          -0.2793188691139221,
          -0.35415685176849365,
          -0.2880908250808716,
          -0.37542155385017395,
          -0.3943309187889099,
          -0.5649646520614624,
          -0.6483315229415894,
          -0.6374714970588684,
          -0.5966646075248718,
          -0.5456744432449341,
          -0.47298139333724976,
          -0.08776575326919556,
          -0.4779514670372009,
          -0.565043032169342,
          -0.566727876663208
         ]
        },
        {
         "line": {
          "color": "#F58518",
          "dash": "dash",
          "width": 12
         },
         "name": "left_circuit : front_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          1.3210833458288107e-06,
          0.0011112254578620195,
          0.0007516914629377425,
          0.00046209149877540767,
          0.0004123686521779746,
          0.0010086700785905123,
          -0.0003751262847799808,
          0.0009576626471243799,
          0.00045248327660374343,
          0.0011376467300578952,
          0.0018510556546971202,
          0.004282341804355383,
          0.001158238621428609,
          -0.0004593975027091801,
          -0.001239935983903706,
          -0.0005733522120863199,
          -0.0050153909251093864,
          -0.00857112929224968,
          0.012407315894961357,
          0.0028871914837509394,
          -0.04080475494265556,
          -0.04177450016140938,
          -0.1067994013428688,
          -0.11007335036993027,
          -0.07771340757608414,
          -0.06494742631912231,
          -0.03915814682841301,
          -0.051894914358854294,
          -0.04948516562581062,
          -0.0041580661199986935,
          0.004097288008779287,
          0.010836068540811539,
          0.05640672892332077,
          0.06465528905391693,
          0.060128141194581985,
          0.06567133963108063,
          0.04729016497731209,
          0.028914516791701317,
          0.03952953591942787,
          0.021857982501387596,
          0.003322986885905266,
          -0.013181525282561779,
          0.004966574255377054,
          -0.005224325694143772,
          -0.009173557162284851,
          0.002577595179900527,
          0.014935924671590328,
          -0.03143204748630524,
          -0.0071957907639443874,
          0.022440973669290543,
          -0.03405188024044037,
          -0.0011076685041189194,
          -0.09580174833536148,
          -0.17366330325603485,
          -0.17058412730693817,
          -0.20817023515701294,
          -0.2712342143058777,
          -0.25243982672691345,
          -0.3070918619632721,
          -0.3428504467010498,
          -0.3491678833961487,
          -0.4188788831233978,
          -0.3889906108379364,
          -0.48459845781326294,
          -0.4672682285308838,
          -0.7346255779266357,
          -0.8033497333526611,
          -0.9233580231666565,
          -0.8919235467910767
         ]
        },
        {
         "line": {
          "color": "#F58518",
          "width": 12
         },
         "name": "left_circuit : left_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          -3.215639299014583e-05,
          0.001107049873098731,
          -3.167440809193067e-05,
          -0.00036470743361860514,
          -0.00032452380401082337,
          -0.0011976852547377348,
          -0.0027500521391630173,
          -0.002378954319283366,
          -0.0029056447092443705,
          -0.00311667425557971,
          -0.004268475342541933,
          -0.0031233043409883976,
          -0.006224434822797775,
          -0.006575790233910084,
          -0.007656416390091181,
          -0.005382064264267683,
          -0.010990440845489502,
          -0.018849177286028862,
          0.010745405219495296,
          0.00464927963912487,
          -0.04436840862035751,
          -0.05458718165755272,
          -0.13586421310901642,
          -0.1486646831035614,
          -0.10158266127109528,
          -0.07769361138343811,
          -0.036336857825517654,
          -0.05693028122186661,
          -0.06035247817635536,
          -0.008163964375853539,
          -0.008359471336007118,
          -0.014502241276204586,
          0.08023164421319962,
          0.08890002220869064,
          0.08726243674755096,
          0.09855187684297562,
          0.06699882447719574,
          0.020910115912556648,
          0.03280404582619667,
          -0.004291079472750425,
          -0.028566349297761917,
          -0.04330920800566673,
          -0.03617468103766441,
          -0.031132204458117485,
          -0.03867015242576599,
          -0.03884567320346832,
          -0.006224877201020718,
          -0.0530967079102993,
          -0.05314072594046593,
          -0.013638317584991455,
          -0.08991017937660217,
          0.0011436560889706016,
          -0.12734778225421906,
          -0.1868501901626587,
          -0.16448837518692017,
          -0.14908716082572937,
          -0.17722517251968384,
          -0.19538886845111847,
          -0.2651654779911041,
          -0.25627782940864563,
          -0.24258583784103394,
          -0.41468536853790283,
          -0.3475504219532013,
          -0.5301475524902344,
          -0.4785098731517792,
          -0.8525267839431763,
          -0.8177775144577026,
          -0.8613607287406921,
          -0.7504251599311829
         ]
        },
        {
         "line": {
          "color": "#F58518",
          "dash": "dot",
          "width": 12
         },
         "name": "left_circuit : right_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          -0.0006932219839654863,
          0.001940099522471428,
          0.002534298226237297,
          0.001190227922052145,
          0.0013802149333059788,
          0.0013973339227959514,
          0.0004152457695454359,
          8.52161247166805e-05,
          -0.00023925595451146364,
          0.00022838733275420964,
          -0.002464825054630637,
          0.010557367466390133,
          -0.003367769531905651,
          -0.0006888193311169744,
          -0.0018648862605914474,
          -0.0028499122709035873,
          -0.008923038840293884,
          -0.01204373873770237,
          0.029526755213737488,
          0.017908357083797455,
          -0.03376109525561333,
          -0.03830506652593613,
          -0.11381182819604874,
          -0.12474477291107178,
          -0.07803048193454742,
          -0.05635327100753784,
          -0.012911041267216206,
          -0.04014298692345619,
          -0.0445173978805542,
          -0.01027151569724083,
          0.008174519054591656,
          0.020868590101599693,
          0.07804156094789505,
          0.09654643386602402,
          0.09704309701919556,
          0.09224767237901688,
          0.055876921862363815,
          0.00896116066724062,
          0.02455570548772812,
          0.005047841463238001,
          -0.012617861852049828,
          -0.03167636692523956,
          0.005094312597066164,
          -0.005879185162484646,
          -0.019047316163778305,
          0.003417370142415166,
          0.019470112398266792,
          -0.039974652230739594,
          -0.005180083680897951,
          0.03197355195879936,
          -0.03822532296180725,
          0.07368053495883942,
          -0.10109645873308182,
          -0.19046691060066223,
          -0.2143508791923523,
          -0.22759929299354553,
          -0.3144455850124359,
          -0.3181287348270416,
          -0.38029226660728455,
          -0.3941081762313843,
          -0.33732402324676514,
          -0.47300463914871216,
          -0.4171852767467499,
          -0.5547595620155334,
          -0.447753369808197,
          -0.8858597278594971,
          -0.8877810835838318,
          -0.9856736660003662,
          -0.8856136202812195
         ]
        },
        {
         "line": {
          "color": "#54A24B",
          "dash": "dash",
          "width": 12
         },
         "name": "right_circuit : front_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          0.00017138391558546573,
          0.00041677337139844894,
          0.0006510528037324548,
          0.0004239711561240256,
          0.0011805323883891106,
          0.0015060125151649117,
          0.0027757061179727316,
          0.004071537405252457,
          0.005674028303474188,
          0.00802412535995245,
          0.009800240397453308,
          0.01606273651123047,
          0.020795296877622604,
          0.01974334381520748,
          0.019392400979995728,
          0.01598370634019375,
          0.013458388857543468,
          0.011638614349067211,
          0.008702210150659084,
          0.008017671294510365,
          0.012178227305412292,
          0.0014349666889756918,
          -0.044787611812353134,
          -0.06386919319629669,
          -0.09596466273069382,
          -0.12030595541000366,
          -0.052242882549762726,
          -0.03928159177303314,
          -0.03697005286812782,
          0.011422009207308292,
          0.03654766082763672,
          0.03666992485523224,
          0.03163382038474083,
          0.03194689378142357,
          0.032435040920972824,
          0.04789295047521591,
          0.04031417518854141,
          0.034321874380111694,
          0.03441024571657181,
          0.045513805001974106,
          0.04528412967920303,
          0.03749917075037956,
          0.05669951066374779,
          0.06017761677503586,
          0.03470951318740845,
          0.006420323625206947,
          -0.02595015987753868,
          -0.013925587758421898,
          0.0012662826338782907,
          -0.026336107403039932,
          -0.0254130307585001,
          -0.079166479408741,
          -0.12838493287563324,
          -0.1301802098751068,
          -0.16253919899463654,
          -0.18014830350875854,
          -0.2542143166065216,
          -0.35961827635765076,
          -0.32882949709892273,
          -0.4218933582305908,
          -0.4310300052165985,
          -0.5311356782913208,
          -0.5643637776374817,
          -0.5783022046089172,
          -0.4657675623893738,
          -0.5351598858833313,
          -0.6806021928787231,
          -0.8644711375236511,
          -0.9596694707870483
         ]
        },
        {
         "line": {
          "color": "#54A24B",
          "dash": "dot",
          "width": 12
         },
         "name": "right_circuit : left_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          2.8554377422551624e-05,
          -0.00016418426821473986,
          0.001029788050800562,
          0.00026983380666933954,
          0.002156483242288232,
          0.0023511655163019896,
          0.003272106871008873,
          0.007564453408122063,
          0.010454903356730938,
          0.0161150973290205,
          0.02210930548608303,
          0.03903473541140556,
          0.0459972508251667,
          0.04470214992761612,
          0.04747873544692993,
          0.03888942301273346,
          0.031920041888952255,
          0.0248271431773901,
          0.020175205543637276,
          0.01645454205572605,
          0.030235275626182556,
          0.015246853232383728,
          -0.03851575404405594,
          -0.060613855719566345,
          -0.10210167616605759,
          -0.14274993538856506,
          -0.04910259321331978,
          -0.04056711494922638,
          -0.04665308818221092,
          0.030005045235157013,
          0.059493474662303925,
          0.05896180868148804,
          0.041300151497125626,
          0.04363309592008591,
          0.037969354540109634,
          0.04264392331242561,
          0.03392304107546806,
          0.010303265415132046,
          0.0018938626162707806,
          0.019028112292289734,
          0.005071243736892939,
          -0.04333989694714546,
          -0.010036076419055462,
          -0.018765924498438835,
          -0.05300196632742882,
          -0.10361899435520172,
          -0.15357142686843872,
          -0.1491495668888092,
          -0.1238928809762001,
          -0.14953045547008514,
          -0.10083331167697906,
          -0.16613885760307312,
          -0.23867206275463104,
          -0.24855060875415802,
          -0.21570557355880737,
          -0.22239673137664795,
          -0.30365097522735596,
          -0.4654543995857239,
          -0.4100033640861511,
          -0.5269988179206848,
          -0.5333060622215271,
          -0.6285701990127563,
          -0.6689845323562622,
          -0.6429247856140137,
          -0.4834791123867035,
          -0.5749195218086243,
          -0.690983772277832,
          -0.9391011595726013,
          -0.9199713468551636
         ]
        },
        {
         "line": {
          "color": "#54A24B",
          "width": 12
         },
         "name": "right_circuit : right_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          -1.6758193623900297e-06,
          0.0001121868917834945,
          0.000252897763857618,
          -0.0007512258598580956,
          0.00012097180297132581,
          0.0004055119934491813,
          0.0018722756067290902,
          0.00467853806912899,
          0.007072902750223875,
          0.010854504071176052,
          0.015930647030472755,
          0.029145611450076103,
          0.035437844693660736,
          0.030968183651566505,
          0.027787169441580772,
          0.021077124401926994,
          0.017102887853980064,
          0.015004996210336685,
          0.009358704090118408,
          0.010635781101882458,
          0.0194244422018528,
          0.005810684524476528,
          -0.05601147934794426,
          -0.06660833954811096,
          -0.10984792560338974,
          -0.15278314054012299,
          -0.05396417900919914,
          -0.02695552445948124,
          -0.019630055874586105,
          0.04627459496259689,
          0.08744000643491745,
          0.08614141494035721,
          0.06895368546247482,
          0.0763024166226387,
          0.07443604618310928,
          0.08333414047956467,
          0.0638299211859703,
          0.030450325459241867,
          0.02930777706205845,
          0.06936121731996536,
          0.048585254698991776,
          0.016745416447520256,
          0.04229533672332764,
          0.03855753317475319,
          -0.006503307726234198,
          -0.03614789620041847,
          -0.0740099847316742,
          -0.06772560626268387,
          -0.029531113803386688,
          -0.0672515332698822,
          -0.03674762323498726,
          -0.12141446769237518,
          -0.1668332815170288,
          -0.1330229789018631,
          -0.16205622255802155,
          -0.17774656414985657,
          -0.28230372071266174,
          -0.4661405384540558,
          -0.4513322710990906,
          -0.5443342328071594,
          -0.5017483830451965,
          -0.5635991096496582,
          -0.5991889238357544,
          -0.5957707762718201,
          -0.3629196286201477,
          -0.5910376310348511,
          -0.7006110548973083,
          -0.8593422770500183,
          -0.9416869282722473
         ]
        }
       ],
       "layout": {
        "legend": {
         "x": 0.03,
         "xanchor": "left",
         "y": 0.65,
         "yanchor": "top"
        },
        "paper_bgcolor": "rgba(255,255,255,1)",
        "plot_bgcolor": "rgba(255,255,255,1)",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 720,
        "xaxis": {
         "autorange": "reversed",
         "gridcolor": "rgb(210,210,210)",
         "gridwidth": 4,
         "tickmode": "array",
         "tickvals": [
          0.4,
          0.3,
          0.2,
          0.1
         ],
         "title": {
          "text": "sparsity"
         }
        },
        "yaxis": {
         "gridcolor": "rgb(210,210,210)",
         "gridwidth": 4,
         "title": {
          "text": "$\\Huge{\\Delta\\mathcal{F}}$"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"fc338ba0-5ec4-46a5-a17d-e292eb4a0769\" class=\"plotly-graph-div\" style=\"height:525px; width:720px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fc338ba0-5ec4-46a5-a17d-e292eb4a0769\")) {                    Plotly.newPlot(                        \"fc338ba0-5ec4-46a5-a17d-e292eb4a0769\",                        [{\"line\": {\"color\": \"#4C78A8\", \"width\": 12}, \"name\": \"front_circuit : front_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, 1.7382586520398036e-05, 1.3952414519735612e-05, 0.003590772859752178, -6.241133814910427e-05, 0.00029292277758941054, 0.0002940017729997635, 0.0014650659868493676, 0.0015135830035433173, 0.012249858118593693, 0.01962275058031082, 0.0024858496617525816, 0.0023447966668754816, 0.0029333310667425394, 0.003482875879853964, 0.0013241772539913654, -0.0032043384853750467, -0.008814465254545212, -0.004760937765240669, -0.011306611821055412, -0.022814471274614334, -0.0007347544305957854, 0.0008744319202378392, -0.05922714248299599, -0.05293833464384079, -0.04132775589823723, -0.027838345617055893, -0.016284329816699028, -0.02555745095014572, 0.06233064830303192, 0.05773207172751427, 0.045901112258434296, 0.04111229255795479, 0.042728595435619354, 0.029567552730441093, 0.02390158735215664, 0.004080836195498705, -0.010823821648955345, -0.0182026457041502, -0.01533504854887724, -0.04601885750889778, -0.0593382753431797, -0.0790891945362091, -0.09080187976360321, -0.08797898143529892, -0.11485762149095535, -0.0785399079322815, -0.08005953580141068, -0.048308905214071274, -0.03391754627227783, -0.01231662929058075, -0.022311383858323097, 0.02537335641682148, -0.02341223508119583, -0.11858195811510086, -0.1548890918493271, -0.21237654983997345, -0.20309826731681824, -0.2605537176132202, -0.3019435703754425, -0.42584261298179626, -0.5050730109214783, -0.5804826617240906, -0.5447521805763245, -0.5082824230194092, -0.5608110427856445, -0.3371371328830719, -0.5418956279754639, -0.6379358172416687, -0.7070026993751526]}, {\"line\": {\"color\": \"#4C78A8\", \"dash\": \"dash\", \"width\": 12}, \"name\": \"front_circuit : left_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, -0.0011161925503984094, -0.0015589171089231968, 0.007133193779736757, -0.001196734025143087, 0.0011595601681619883, 0.00299309054389596, 0.01500080805271864, 0.014129800722002983, 0.026297742500901222, 0.02297896519303322, 0.001162663334980607, 0.003078927518799901, 0.0003731928300112486, 0.00272726290859282, -0.004642189480364323, -0.006749721243977547, -0.016575289890170097, -0.008229461498558521, -0.015799304470419884, -0.0320611335337162, 0.0009316981304436922, 0.010871784761548042, -0.07064809650182724, -0.058935850858688354, -0.02973121963441372, -0.02957853302359581, -0.010161051526665688, -0.03207213431596756, 0.09748845547437668, 0.08218326419591904, 0.0691845715045929, 0.06494417041540146, 0.05468206852674484, 0.028639551252126694, 0.029739167541265488, 0.0018418856197968125, -0.015391020104289055, -0.04400591924786568, -0.05857454985380173, -0.114056296646595, -0.13497328758239746, -0.17799974977970123, -0.21537548303604126, -0.22479909658432007, -0.26020699739456177, -0.22501297295093536, -0.23348066210746765, -0.18031270802021027, -0.144323468208313, -0.12816143035888672, -0.16548343002796173, -0.10322947800159454, -0.1578381210565567, -0.268416166305542, -0.2789369225502014, -0.37754571437835693, -0.37348079681396484, -0.4180731773376465, -0.485443651676178, -0.5752413272857666, -0.6185914278030396, -0.6363544464111328, -0.5809557437896729, -0.5083438158035278, -0.500476062297821, -0.25848114490509033, -0.43064144253730774, -0.5046852231025696, -0.530437171459198]}, {\"line\": {\"color\": \"#4C78A8\", \"dash\": \"dot\", \"width\": 12}, \"name\": \"front_circuit : right_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, -0.000477004999993369, -0.0012201049830764532, 0.007494035642594099, -0.0027288049459457397, -0.0009433611994609237, -0.0027262894436717033, 0.0028577407356351614, 0.004253392107784748, 0.03342963010072708, 0.04733992740511894, 0.01165549922734499, 0.0010445384541526437, 0.0005493889329954982, -0.004188972990959883, -0.006844231393188238, -0.007417984772473574, -0.012765186838805676, -0.004624729976058006, -0.02199692651629448, -0.04719765856862068, -0.020085226744413376, -0.011231852695345879, -0.08753973245620728, -0.07756978273391724, -0.05000559985637665, -0.025737712159752846, 0.0006543870549649, -0.013986589387059212, 0.10494954138994217, 0.10293802618980408, 0.0745270699262619, 0.07602532207965851, 0.07180071622133255, 0.04910240322351456, 0.05211948603391647, 0.023756926879286766, 0.0011223251931369305, -0.017623171210289, -0.022782975807785988, -0.08581534028053284, -0.11146910488605499, -0.14603060483932495, -0.16201665997505188, -0.16386593878269196, -0.20447155833244324, -0.16823546588420868, -0.17174623906612396, -0.12729206681251526, -0.06750688701868057, -0.06335151940584183, -0.09123387187719345, 0.0026488257572054863, -0.05447673052549362, -0.21803885698318481, -0.2793188691139221, -0.35415685176849365, -0.2880908250808716, -0.37542155385017395, -0.3943309187889099, -0.5649646520614624, -0.6483315229415894, -0.6374714970588684, -0.5966646075248718, -0.5456744432449341, -0.47298139333724976, -0.08776575326919556, -0.4779514670372009, -0.565043032169342, -0.566727876663208]}, {\"line\": {\"color\": \"#F58518\", \"dash\": \"dash\", \"width\": 12}, \"name\": \"left_circuit : front_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, 1.3210833458288107e-06, 0.0011112254578620195, 0.0007516914629377425, 0.00046209149877540767, 0.0004123686521779746, 0.0010086700785905123, -0.0003751262847799808, 0.0009576626471243799, 0.00045248327660374343, 0.0011376467300578952, 0.0018510556546971202, 0.004282341804355383, 0.001158238621428609, -0.0004593975027091801, -0.001239935983903706, -0.0005733522120863199, -0.0050153909251093864, -0.00857112929224968, 0.012407315894961357, 0.0028871914837509394, -0.04080475494265556, -0.04177450016140938, -0.1067994013428688, -0.11007335036993027, -0.07771340757608414, -0.06494742631912231, -0.03915814682841301, -0.051894914358854294, -0.04948516562581062, -0.0041580661199986935, 0.004097288008779287, 0.010836068540811539, 0.05640672892332077, 0.06465528905391693, 0.060128141194581985, 0.06567133963108063, 0.04729016497731209, 0.028914516791701317, 0.03952953591942787, 0.021857982501387596, 0.003322986885905266, -0.013181525282561779, 0.004966574255377054, -0.005224325694143772, -0.009173557162284851, 0.002577595179900527, 0.014935924671590328, -0.03143204748630524, -0.0071957907639443874, 0.022440973669290543, -0.03405188024044037, -0.0011076685041189194, -0.09580174833536148, -0.17366330325603485, -0.17058412730693817, -0.20817023515701294, -0.2712342143058777, -0.25243982672691345, -0.3070918619632721, -0.3428504467010498, -0.3491678833961487, -0.4188788831233978, -0.3889906108379364, -0.48459845781326294, -0.4672682285308838, -0.7346255779266357, -0.8033497333526611, -0.9233580231666565, -0.8919235467910767]}, {\"line\": {\"color\": \"#F58518\", \"width\": 12}, \"name\": \"left_circuit : left_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, -3.215639299014583e-05, 0.001107049873098731, -3.167440809193067e-05, -0.00036470743361860514, -0.00032452380401082337, -0.0011976852547377348, -0.0027500521391630173, -0.002378954319283366, -0.0029056447092443705, -0.00311667425557971, -0.004268475342541933, -0.0031233043409883976, -0.006224434822797775, -0.006575790233910084, -0.007656416390091181, -0.005382064264267683, -0.010990440845489502, -0.018849177286028862, 0.010745405219495296, 0.00464927963912487, -0.04436840862035751, -0.05458718165755272, -0.13586421310901642, -0.1486646831035614, -0.10158266127109528, -0.07769361138343811, -0.036336857825517654, -0.05693028122186661, -0.06035247817635536, -0.008163964375853539, -0.008359471336007118, -0.014502241276204586, 0.08023164421319962, 0.08890002220869064, 0.08726243674755096, 0.09855187684297562, 0.06699882447719574, 0.020910115912556648, 0.03280404582619667, -0.004291079472750425, -0.028566349297761917, -0.04330920800566673, -0.03617468103766441, -0.031132204458117485, -0.03867015242576599, -0.03884567320346832, -0.006224877201020718, -0.0530967079102993, -0.05314072594046593, -0.013638317584991455, -0.08991017937660217, 0.0011436560889706016, -0.12734778225421906, -0.1868501901626587, -0.16448837518692017, -0.14908716082572937, -0.17722517251968384, -0.19538886845111847, -0.2651654779911041, -0.25627782940864563, -0.24258583784103394, -0.41468536853790283, -0.3475504219532013, -0.5301475524902344, -0.4785098731517792, -0.8525267839431763, -0.8177775144577026, -0.8613607287406921, -0.7504251599311829]}, {\"line\": {\"color\": \"#F58518\", \"dash\": \"dot\", \"width\": 12}, \"name\": \"left_circuit : right_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, -0.0006932219839654863, 0.001940099522471428, 0.002534298226237297, 0.001190227922052145, 0.0013802149333059788, 0.0013973339227959514, 0.0004152457695454359, 8.52161247166805e-05, -0.00023925595451146364, 0.00022838733275420964, -0.002464825054630637, 0.010557367466390133, -0.003367769531905651, -0.0006888193311169744, -0.0018648862605914474, -0.0028499122709035873, -0.008923038840293884, -0.01204373873770237, 0.029526755213737488, 0.017908357083797455, -0.03376109525561333, -0.03830506652593613, -0.11381182819604874, -0.12474477291107178, -0.07803048193454742, -0.05635327100753784, -0.012911041267216206, -0.04014298692345619, -0.0445173978805542, -0.01027151569724083, 0.008174519054591656, 0.020868590101599693, 0.07804156094789505, 0.09654643386602402, 0.09704309701919556, 0.09224767237901688, 0.055876921862363815, 0.00896116066724062, 0.02455570548772812, 0.005047841463238001, -0.012617861852049828, -0.03167636692523956, 0.005094312597066164, -0.005879185162484646, -0.019047316163778305, 0.003417370142415166, 0.019470112398266792, -0.039974652230739594, -0.005180083680897951, 0.03197355195879936, -0.03822532296180725, 0.07368053495883942, -0.10109645873308182, -0.19046691060066223, -0.2143508791923523, -0.22759929299354553, -0.3144455850124359, -0.3181287348270416, -0.38029226660728455, -0.3941081762313843, -0.33732402324676514, -0.47300463914871216, -0.4171852767467499, -0.5547595620155334, -0.447753369808197, -0.8858597278594971, -0.8877810835838318, -0.9856736660003662, -0.8856136202812195]}, {\"line\": {\"color\": \"#54A24B\", \"dash\": \"dash\", \"width\": 12}, \"name\": \"right_circuit : front_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, 0.00017138391558546573, 0.00041677337139844894, 0.0006510528037324548, 0.0004239711561240256, 0.0011805323883891106, 0.0015060125151649117, 0.0027757061179727316, 0.004071537405252457, 0.005674028303474188, 0.00802412535995245, 0.009800240397453308, 0.01606273651123047, 0.020795296877622604, 0.01974334381520748, 0.019392400979995728, 0.01598370634019375, 0.013458388857543468, 0.011638614349067211, 0.008702210150659084, 0.008017671294510365, 0.012178227305412292, 0.0014349666889756918, -0.044787611812353134, -0.06386919319629669, -0.09596466273069382, -0.12030595541000366, -0.052242882549762726, -0.03928159177303314, -0.03697005286812782, 0.011422009207308292, 0.03654766082763672, 0.03666992485523224, 0.03163382038474083, 0.03194689378142357, 0.032435040920972824, 0.04789295047521591, 0.04031417518854141, 0.034321874380111694, 0.03441024571657181, 0.045513805001974106, 0.04528412967920303, 0.03749917075037956, 0.05669951066374779, 0.06017761677503586, 0.03470951318740845, 0.006420323625206947, -0.02595015987753868, -0.013925587758421898, 0.0012662826338782907, -0.026336107403039932, -0.0254130307585001, -0.079166479408741, -0.12838493287563324, -0.1301802098751068, -0.16253919899463654, -0.18014830350875854, -0.2542143166065216, -0.35961827635765076, -0.32882949709892273, -0.4218933582305908, -0.4310300052165985, -0.5311356782913208, -0.5643637776374817, -0.5783022046089172, -0.4657675623893738, -0.5351598858833313, -0.6806021928787231, -0.8644711375236511, -0.9596694707870483]}, {\"line\": {\"color\": \"#54A24B\", \"dash\": \"dot\", \"width\": 12}, \"name\": \"right_circuit : left_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, 2.8554377422551624e-05, -0.00016418426821473986, 0.001029788050800562, 0.00026983380666933954, 0.002156483242288232, 0.0023511655163019896, 0.003272106871008873, 0.007564453408122063, 0.010454903356730938, 0.0161150973290205, 0.02210930548608303, 0.03903473541140556, 0.0459972508251667, 0.04470214992761612, 0.04747873544692993, 0.03888942301273346, 0.031920041888952255, 0.0248271431773901, 0.020175205543637276, 0.01645454205572605, 0.030235275626182556, 0.015246853232383728, -0.03851575404405594, -0.060613855719566345, -0.10210167616605759, -0.14274993538856506, -0.04910259321331978, -0.04056711494922638, -0.04665308818221092, 0.030005045235157013, 0.059493474662303925, 0.05896180868148804, 0.041300151497125626, 0.04363309592008591, 0.037969354540109634, 0.04264392331242561, 0.03392304107546806, 0.010303265415132046, 0.0018938626162707806, 0.019028112292289734, 0.005071243736892939, -0.04333989694714546, -0.010036076419055462, -0.018765924498438835, -0.05300196632742882, -0.10361899435520172, -0.15357142686843872, -0.1491495668888092, -0.1238928809762001, -0.14953045547008514, -0.10083331167697906, -0.16613885760307312, -0.23867206275463104, -0.24855060875415802, -0.21570557355880737, -0.22239673137664795, -0.30365097522735596, -0.4654543995857239, -0.4100033640861511, -0.5269988179206848, -0.5333060622215271, -0.6285701990127563, -0.6689845323562622, -0.6429247856140137, -0.4834791123867035, -0.5749195218086243, -0.690983772277832, -0.9391011595726013, -0.9199713468551636]}, {\"line\": {\"color\": \"#54A24B\", \"width\": 12}, \"name\": \"right_circuit : right_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, -1.6758193623900297e-06, 0.0001121868917834945, 0.000252897763857618, -0.0007512258598580956, 0.00012097180297132581, 0.0004055119934491813, 0.0018722756067290902, 0.00467853806912899, 0.007072902750223875, 0.010854504071176052, 0.015930647030472755, 0.029145611450076103, 0.035437844693660736, 0.030968183651566505, 0.027787169441580772, 0.021077124401926994, 0.017102887853980064, 0.015004996210336685, 0.009358704090118408, 0.010635781101882458, 0.0194244422018528, 0.005810684524476528, -0.05601147934794426, -0.06660833954811096, -0.10984792560338974, -0.15278314054012299, -0.05396417900919914, -0.02695552445948124, -0.019630055874586105, 0.04627459496259689, 0.08744000643491745, 0.08614141494035721, 0.06895368546247482, 0.0763024166226387, 0.07443604618310928, 0.08333414047956467, 0.0638299211859703, 0.030450325459241867, 0.02930777706205845, 0.06936121731996536, 0.048585254698991776, 0.016745416447520256, 0.04229533672332764, 0.03855753317475319, -0.006503307726234198, -0.03614789620041847, -0.0740099847316742, -0.06772560626268387, -0.029531113803386688, -0.0672515332698822, -0.03674762323498726, -0.12141446769237518, -0.1668332815170288, -0.1330229789018631, -0.16205622255802155, -0.17774656414985657, -0.28230372071266174, -0.4661405384540558, -0.4513322710990906, -0.5443342328071594, -0.5017483830451965, -0.5635991096496582, -0.5991889238357544, -0.5957707762718201, -0.3629196286201477, -0.5910376310348511, -0.7006110548973083, -0.8593422770500183, -0.9416869282722473]}],                        {\"legend\": {\"x\": 0.03, \"xanchor\": \"left\", \"y\": 0.65, \"yanchor\": \"top\"}, \"paper_bgcolor\": \"rgba(255,255,255,1)\", \"plot_bgcolor\": \"rgba(255,255,255,1)\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 720, \"xaxis\": {\"autorange\": \"reversed\", \"gridcolor\": \"rgb(210,210,210)\", \"gridwidth\": 4, \"tickmode\": \"array\", \"tickvals\": [0.4, 0.3, 0.2, 0.1], \"title\": {\"text\": \"sparsity\"}}, \"yaxis\": {\"gridcolor\": \"rgb(210,210,210)\", \"gridwidth\": 4, \"title\": {\"text\": \"$\\\\Huge{\\\\Delta\\\\mathcal{F}}$\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('fc338ba0-5ec4-46a5-a17d-e292eb4a0769');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "x_axis = model_sparsities\n",
    "\n",
    "metric = 'mean_normed_diff'\n",
    "\n",
    "color_dict = {\n",
    "               'front_circuit':px.colors.qualitative.T10[0],\n",
    "               'left_circuit':px.colors.qualitative.T10[1],\n",
    "               'right_circuit':px.colors.qualitative.T10[4],\n",
    "             }\n",
    "\n",
    "dash_dict = {\n",
    "               'front_data':None,\n",
    "               'left_data':'dot',\n",
    "               'right_data':'dash',\n",
    "            }\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for circuit in scores:\n",
    "    third_line = False\n",
    "    for data in scores[circuit]:\n",
    "        if data.replace('_data','') == circuit.replace('_circuit',''):\n",
    "            linetype = None\n",
    "        elif third_line:\n",
    "            linetype = 'dot'\n",
    "        else:\n",
    "            linetype= 'dash'\n",
    "            third_line = True\n",
    "            \n",
    "            \n",
    "        # Create and style traces\n",
    "        y = scores[circuit][data]['%s:%s'%(layer,0)][metric]\n",
    "        x = x_axis[0:len(scores[circuit][data]['%s:%s'%(layer,0)][metric])]\n",
    "        fig.add_trace(go.Scatter(x=x, y=y, name=circuit+' : '+data,\n",
    "                         line=dict(color=color_dict[circuit], width=12,dash=linetype)))\n",
    "\n",
    "# Edit the layout\n",
    "fig.update_layout( width = 720,\n",
    "                   plot_bgcolor = 'rgba(255,255,255,1)',\n",
    "                   paper_bgcolor = 'rgba(255,255,255,1)',\n",
    "                   xaxis_title='sparsity',\n",
    "                   yaxis_title=r'$\\Huge{\\Delta\\mathcal{F}}$',\n",
    "                  legend=dict(\n",
    "                                yanchor=\"top\",\n",
    "                                y=0.65,\n",
    "                                xanchor=\"left\",\n",
    "                                x=0.03\n",
    "                              )\n",
    "                 )\n",
    "\n",
    "fig.update_xaxes(autorange=\"reversed\",gridcolor='rgb(210,210,210)',gridwidth=4)\n",
    "fig.update_yaxes(gridcolor='rgb(210,210,210)',gridwidth=4)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = [.4, .3, .2, .1]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ed62fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#4C78A8",
          "width": 12
         },
         "name": "front_circuit : front_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          1.7382586520398036e-05,
          1.3952414519735612e-05,
          0.003590772859752178,
          -6.241133814910427e-05,
          0.00029292277758941054,
          0.0002940017729997635,
          0.0014650659868493676,
          0.0015135830035433173,
          0.012249858118593693,
          0.01962275058031082,
          0.0024858496617525816,
          0.0023447966668754816,
          0.0029333310667425394,
          0.003482875879853964,
          0.0013241772539913654,
          -0.0032043384853750467,
          -0.008814465254545212,
          -0.004760937765240669,
          -0.011306611821055412,
          -0.022814471274614334,
          -0.0007347544305957854,
          0.0008744319202378392,
          -0.05922714248299599,
          -0.05293833464384079,
          -0.04132775589823723,
          -0.027838345617055893,
          -0.016284329816699028,
          -0.02555745095014572,
          0.06233064830303192,
          0.05773207172751427,
          0.045901112258434296,
          0.04111229255795479,
          0.042728595435619354,
          0.029567552730441093,
          0.02390158735215664,
          0.004080836195498705,
          -0.010823821648955345,
          -0.0182026457041502,
          -0.01533504854887724,
          -0.04601885750889778,
          -0.0593382753431797,
          -0.0790891945362091,
          -0.09080187976360321,
          -0.08797898143529892,
          -0.11485762149095535,
          -0.0785399079322815,
          -0.08005953580141068,
          -0.048308905214071274,
          -0.03391754627227783,
          -0.01231662929058075,
          -0.022311383858323097,
          0.02537335641682148,
          -0.02341223508119583,
          -0.11858195811510086,
          -0.1548890918493271,
          -0.21237654983997345,
          -0.20309826731681824,
          -0.2605537176132202,
          -0.3019435703754425,
          -0.42584261298179626,
          -0.5050730109214783,
          -0.5804826617240906,
          -0.5447521805763245,
          -0.5082824230194092,
          -0.5608110427856445,
          -0.3371371328830719,
          -0.5418956279754639,
          -0.6379358172416687,
          -0.7070026993751526
         ]
        },
        {
         "line": {
          "color": "#4C78A8",
          "dash": "dash",
          "width": 12
         },
         "name": "front_circuit : left_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          -0.0011161925503984094,
          -0.0015589171089231968,
          0.007133193779736757,
          -0.001196734025143087,
          0.0011595601681619883,
          0.00299309054389596,
          0.01500080805271864,
          0.014129800722002983,
          0.026297742500901222,
          0.02297896519303322,
          0.001162663334980607,
          0.003078927518799901,
          0.0003731928300112486,
          0.00272726290859282,
          -0.004642189480364323,
          -0.006749721243977547,
          -0.016575289890170097,
          -0.008229461498558521,
          -0.015799304470419884,
          -0.0320611335337162,
          0.0009316981304436922,
          0.010871784761548042,
          -0.07064809650182724,
          -0.058935850858688354,
          -0.02973121963441372,
          -0.02957853302359581,
          -0.010161051526665688,
          -0.03207213431596756,
          0.09748845547437668,
          0.08218326419591904,
          0.0691845715045929,
          0.06494417041540146,
          0.05468206852674484,
          0.028639551252126694,
          0.029739167541265488,
          0.0018418856197968125,
          -0.015391020104289055,
          -0.04400591924786568,
          -0.05857454985380173,
          -0.114056296646595,
          -0.13497328758239746,
          -0.17799974977970123,
          -0.21537548303604126,
          -0.22479909658432007,
          -0.26020699739456177,
          -0.22501297295093536,
          -0.23348066210746765,
          -0.18031270802021027,
          -0.144323468208313,
          -0.12816143035888672,
          -0.16548343002796173,
          -0.10322947800159454,
          -0.1578381210565567,
          -0.268416166305542,
          -0.2789369225502014,
          -0.37754571437835693,
          -0.37348079681396484,
          -0.4180731773376465,
          -0.485443651676178,
          -0.5752413272857666,
          -0.6185914278030396,
          -0.6363544464111328,
          -0.5809557437896729,
          -0.5083438158035278,
          -0.500476062297821,
          -0.25848114490509033,
          -0.43064144253730774,
          -0.5046852231025696,
          -0.530437171459198
         ]
        },
        {
         "line": {
          "color": "#4C78A8",
          "dash": "dot",
          "width": 12
         },
         "name": "front_circuit : right_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          -0.000477004999993369,
          -0.0012201049830764532,
          0.007494035642594099,
          -0.0027288049459457397,
          -0.0009433611994609237,
          -0.0027262894436717033,
          0.0028577407356351614,
          0.004253392107784748,
          0.03342963010072708,
          0.04733992740511894,
          0.01165549922734499,
          0.0010445384541526437,
          0.0005493889329954982,
          -0.004188972990959883,
          -0.006844231393188238,
          -0.007417984772473574,
          -0.012765186838805676,
          -0.004624729976058006,
          -0.02199692651629448,
          -0.04719765856862068,
          -0.020085226744413376,
          -0.011231852695345879,
          -0.08753973245620728,
          -0.07756978273391724,
          -0.05000559985637665,
          -0.025737712159752846,
          0.0006543870549649,
          -0.013986589387059212,
          0.10494954138994217,
          0.10293802618980408,
          0.0745270699262619,
          0.07602532207965851,
          0.07180071622133255,
          0.04910240322351456,
          0.05211948603391647,
          0.023756926879286766,
          0.0011223251931369305,
          -0.017623171210289,
          -0.022782975807785988,
          -0.08581534028053284,
          -0.11146910488605499,
          -0.14603060483932495,
          -0.16201665997505188,
          -0.16386593878269196,
          -0.20447155833244324,
          -0.16823546588420868,
          -0.17174623906612396,
          -0.12729206681251526,
          -0.06750688701868057,
          -0.06335151940584183,
          -0.09123387187719345,
          0.0026488257572054863,
          -0.05447673052549362,
          -0.21803885698318481,
          -0.2793188691139221,
          -0.35415685176849365,
          -0.2880908250808716,
          -0.37542155385017395,
          -0.3943309187889099,
          -0.5649646520614624,
          -0.6483315229415894,
          -0.6374714970588684,
          -0.5966646075248718,
          -0.5456744432449341,
          -0.47298139333724976,
          -0.08776575326919556,
          -0.4779514670372009,
          -0.565043032169342,
          -0.566727876663208
         ]
        },
        {
         "line": {
          "color": "#F58518",
          "dash": "dash",
          "width": 12
         },
         "name": "left_circuit : front_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          1.3210833458288107e-06,
          0.0011112254578620195,
          0.0007516914629377425,
          0.00046209149877540767,
          0.0004123686521779746,
          0.0010086700785905123,
          -0.0003751262847799808,
          0.0009576626471243799,
          0.00045248327660374343,
          0.0011376467300578952,
          0.0018510556546971202,
          0.004282341804355383,
          0.001158238621428609,
          -0.0004593975027091801,
          -0.001239935983903706,
          -0.0005733522120863199,
          -0.0050153909251093864,
          -0.00857112929224968,
          0.012407315894961357,
          0.0028871914837509394,
          -0.04080475494265556,
          -0.04177450016140938,
          -0.1067994013428688,
          -0.11007335036993027,
          -0.07771340757608414,
          -0.06494742631912231,
          -0.03915814682841301,
          -0.051894914358854294,
          -0.04948516562581062,
          -0.0041580661199986935,
          0.004097288008779287,
          0.010836068540811539,
          0.05640672892332077,
          0.06465528905391693,
          0.060128141194581985,
          0.06567133963108063,
          0.04729016497731209,
          0.028914516791701317,
          0.03952953591942787,
          0.021857982501387596,
          0.003322986885905266,
          -0.013181525282561779,
          0.004966574255377054,
          -0.005224325694143772,
          -0.009173557162284851,
          0.002577595179900527,
          0.014935924671590328,
          -0.03143204748630524,
          -0.0071957907639443874,
          0.022440973669290543,
          -0.03405188024044037,
          -0.0011076685041189194,
          -0.09580174833536148,
          -0.17366330325603485,
          -0.17058412730693817,
          -0.20817023515701294,
          -0.2712342143058777,
          -0.25243982672691345,
          -0.3070918619632721,
          -0.3428504467010498,
          -0.3491678833961487,
          -0.4188788831233978,
          -0.3889906108379364,
          -0.48459845781326294,
          -0.4672682285308838,
          -0.7346255779266357,
          -0.8033497333526611,
          -0.9233580231666565,
          -0.8919235467910767
         ]
        },
        {
         "line": {
          "color": "#F58518",
          "width": 12
         },
         "name": "left_circuit : left_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          -3.215639299014583e-05,
          0.001107049873098731,
          -3.167440809193067e-05,
          -0.00036470743361860514,
          -0.00032452380401082337,
          -0.0011976852547377348,
          -0.0027500521391630173,
          -0.002378954319283366,
          -0.0029056447092443705,
          -0.00311667425557971,
          -0.004268475342541933,
          -0.0031233043409883976,
          -0.006224434822797775,
          -0.006575790233910084,
          -0.007656416390091181,
          -0.005382064264267683,
          -0.010990440845489502,
          -0.018849177286028862,
          0.010745405219495296,
          0.00464927963912487,
          -0.04436840862035751,
          -0.05458718165755272,
          -0.13586421310901642,
          -0.1486646831035614,
          -0.10158266127109528,
          -0.07769361138343811,
          -0.036336857825517654,
          -0.05693028122186661,
          -0.06035247817635536,
          -0.008163964375853539,
          -0.008359471336007118,
          -0.014502241276204586,
          0.08023164421319962,
          0.08890002220869064,
          0.08726243674755096,
          0.09855187684297562,
          0.06699882447719574,
          0.020910115912556648,
          0.03280404582619667,
          -0.004291079472750425,
          -0.028566349297761917,
          -0.04330920800566673,
          -0.03617468103766441,
          -0.031132204458117485,
          -0.03867015242576599,
          -0.03884567320346832,
          -0.006224877201020718,
          -0.0530967079102993,
          -0.05314072594046593,
          -0.013638317584991455,
          -0.08991017937660217,
          0.0011436560889706016,
          -0.12734778225421906,
          -0.1868501901626587,
          -0.16448837518692017,
          -0.14908716082572937,
          -0.17722517251968384,
          -0.19538886845111847,
          -0.2651654779911041,
          -0.25627782940864563,
          -0.24258583784103394,
          -0.41468536853790283,
          -0.3475504219532013,
          -0.5301475524902344,
          -0.4785098731517792,
          -0.8525267839431763,
          -0.8177775144577026,
          -0.8613607287406921,
          -0.7504251599311829
         ]
        },
        {
         "line": {
          "color": "#F58518",
          "dash": "dot",
          "width": 12
         },
         "name": "left_circuit : right_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          -0.0006932219839654863,
          0.001940099522471428,
          0.002534298226237297,
          0.001190227922052145,
          0.0013802149333059788,
          0.0013973339227959514,
          0.0004152457695454359,
          8.52161247166805e-05,
          -0.00023925595451146364,
          0.00022838733275420964,
          -0.002464825054630637,
          0.010557367466390133,
          -0.003367769531905651,
          -0.0006888193311169744,
          -0.0018648862605914474,
          -0.0028499122709035873,
          -0.008923038840293884,
          -0.01204373873770237,
          0.029526755213737488,
          0.017908357083797455,
          -0.03376109525561333,
          -0.03830506652593613,
          -0.11381182819604874,
          -0.12474477291107178,
          -0.07803048193454742,
          -0.05635327100753784,
          -0.012911041267216206,
          -0.04014298692345619,
          -0.0445173978805542,
          -0.01027151569724083,
          0.008174519054591656,
          0.020868590101599693,
          0.07804156094789505,
          0.09654643386602402,
          0.09704309701919556,
          0.09224767237901688,
          0.055876921862363815,
          0.00896116066724062,
          0.02455570548772812,
          0.005047841463238001,
          -0.012617861852049828,
          -0.03167636692523956,
          0.005094312597066164,
          -0.005879185162484646,
          -0.019047316163778305,
          0.003417370142415166,
          0.019470112398266792,
          -0.039974652230739594,
          -0.005180083680897951,
          0.03197355195879936,
          -0.03822532296180725,
          0.07368053495883942,
          -0.10109645873308182,
          -0.19046691060066223,
          -0.2143508791923523,
          -0.22759929299354553,
          -0.3144455850124359,
          -0.3181287348270416,
          -0.38029226660728455,
          -0.3941081762313843,
          -0.33732402324676514,
          -0.47300463914871216,
          -0.4171852767467499,
          -0.5547595620155334,
          -0.447753369808197,
          -0.8858597278594971,
          -0.8877810835838318,
          -0.9856736660003662,
          -0.8856136202812195
         ]
        },
        {
         "line": {
          "color": "#54A24B",
          "dash": "dash",
          "width": 12
         },
         "name": "right_circuit : front_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          0.00017138391558546573,
          0.00041677337139844894,
          0.0006510528037324548,
          0.0004239711561240256,
          0.0011805323883891106,
          0.0015060125151649117,
          0.0027757061179727316,
          0.004071537405252457,
          0.005674028303474188,
          0.00802412535995245,
          0.009800240397453308,
          0.01606273651123047,
          0.020795296877622604,
          0.01974334381520748,
          0.019392400979995728,
          0.01598370634019375,
          0.013458388857543468,
          0.011638614349067211,
          0.008702210150659084,
          0.008017671294510365,
          0.012178227305412292,
          0.0014349666889756918,
          -0.044787611812353134,
          -0.06386919319629669,
          -0.09596466273069382,
          -0.12030595541000366,
          -0.052242882549762726,
          -0.03928159177303314,
          -0.03697005286812782,
          0.011422009207308292,
          0.03654766082763672,
          0.03666992485523224,
          0.03163382038474083,
          0.03194689378142357,
          0.032435040920972824,
          0.04789295047521591,
          0.04031417518854141,
          0.034321874380111694,
          0.03441024571657181,
          0.045513805001974106,
          0.04528412967920303,
          0.03749917075037956,
          0.05669951066374779,
          0.06017761677503586,
          0.03470951318740845,
          0.006420323625206947,
          -0.02595015987753868,
          -0.013925587758421898,
          0.0012662826338782907,
          -0.026336107403039932,
          -0.0254130307585001,
          -0.079166479408741,
          -0.12838493287563324,
          -0.1301802098751068,
          -0.16253919899463654,
          -0.18014830350875854,
          -0.2542143166065216,
          -0.35961827635765076,
          -0.32882949709892273,
          -0.4218933582305908,
          -0.4310300052165985,
          -0.5311356782913208,
          -0.5643637776374817,
          -0.5783022046089172,
          -0.4657675623893738,
          -0.5351598858833313,
          -0.6806021928787231,
          -0.8644711375236511,
          -0.9596694707870483
         ]
        },
        {
         "line": {
          "color": "#54A24B",
          "dash": "dot",
          "width": 12
         },
         "name": "right_circuit : left_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          2.8554377422551624e-05,
          -0.00016418426821473986,
          0.001029788050800562,
          0.00026983380666933954,
          0.002156483242288232,
          0.0023511655163019896,
          0.003272106871008873,
          0.007564453408122063,
          0.010454903356730938,
          0.0161150973290205,
          0.02210930548608303,
          0.03903473541140556,
          0.0459972508251667,
          0.04470214992761612,
          0.04747873544692993,
          0.03888942301273346,
          0.031920041888952255,
          0.0248271431773901,
          0.020175205543637276,
          0.01645454205572605,
          0.030235275626182556,
          0.015246853232383728,
          -0.03851575404405594,
          -0.060613855719566345,
          -0.10210167616605759,
          -0.14274993538856506,
          -0.04910259321331978,
          -0.04056711494922638,
          -0.04665308818221092,
          0.030005045235157013,
          0.059493474662303925,
          0.05896180868148804,
          0.041300151497125626,
          0.04363309592008591,
          0.037969354540109634,
          0.04264392331242561,
          0.03392304107546806,
          0.010303265415132046,
          0.0018938626162707806,
          0.019028112292289734,
          0.005071243736892939,
          -0.04333989694714546,
          -0.010036076419055462,
          -0.018765924498438835,
          -0.05300196632742882,
          -0.10361899435520172,
          -0.15357142686843872,
          -0.1491495668888092,
          -0.1238928809762001,
          -0.14953045547008514,
          -0.10083331167697906,
          -0.16613885760307312,
          -0.23867206275463104,
          -0.24855060875415802,
          -0.21570557355880737,
          -0.22239673137664795,
          -0.30365097522735596,
          -0.4654543995857239,
          -0.4100033640861511,
          -0.5269988179206848,
          -0.5333060622215271,
          -0.6285701990127563,
          -0.6689845323562622,
          -0.6429247856140137,
          -0.4834791123867035,
          -0.5749195218086243,
          -0.690983772277832,
          -0.9391011595726013,
          -0.9199713468551636
         ]
        },
        {
         "line": {
          "color": "#54A24B",
          "width": 12
         },
         "name": "right_circuit : right_data",
         "type": "scatter",
         "x": [
          0.39988147865853657,
          0.3941440545433122,
          0.3884066304280878,
          0.3826692063128635,
          0.3769317821976392,
          0.3711943580824148,
          0.3654569339671905,
          0.3597195098519661,
          0.3539820857367417,
          0.3482446616215174,
          0.342507237506293,
          0.3367698133910687,
          0.33103238927584433,
          0.32529496516061995,
          0.31955754104539563,
          0.31382011693017126,
          0.30808269281494693,
          0.30234526869972256,
          0.2966078445844982,
          0.29087042046927386,
          0.2851329963540495,
          0.27939557223882516,
          0.27365814812360084,
          0.26792072400837647,
          0.2621832998931521,
          0.2564458757779277,
          0.25070845166270334,
          0.24497102754747904,
          0.23923360343225467,
          0.23349617931703032,
          0.227758755201806,
          0.22202133108658162,
          0.21628390697135727,
          0.2105464828561329,
          0.20480905874090855,
          0.19907163462568422,
          0.19333421051045985,
          0.18759678639523547,
          0.18185936228001118,
          0.1761219381647868,
          0.17038451404956242,
          0.16464708993433808,
          0.1589096658191137,
          0.15317224170388938,
          0.14743481758866503,
          0.14169739347344065,
          0.13595996935821633,
          0.13022254524299198,
          0.1244851211277676,
          0.11874769701254324,
          0.11301027289731888,
          0.10727284878209456,
          0.1015354246668702,
          0.09579800055164583,
          0.09006057643642151,
          0.08432315232119715,
          0.07858572820597277,
          0.07284830409074841,
          0.06711087997552405,
          0.061373455860299735,
          0.055636031745075365,
          0.049898607629851,
          0.04416118351462668,
          0.03842375939940232,
          0.032686335284177956,
          0.02694891116895359,
          0.021211487053729224,
          0.015474062938504904,
          0.00973663882328054,
          0.003999214708056171
         ],
         "y": [
          0,
          -1.6758193623900297e-06,
          0.0001121868917834945,
          0.000252897763857618,
          -0.0007512258598580956,
          0.00012097180297132581,
          0.0004055119934491813,
          0.0018722756067290902,
          0.00467853806912899,
          0.007072902750223875,
          0.010854504071176052,
          0.015930647030472755,
          0.029145611450076103,
          0.035437844693660736,
          0.030968183651566505,
          0.027787169441580772,
          0.021077124401926994,
          0.017102887853980064,
          0.015004996210336685,
          0.009358704090118408,
          0.010635781101882458,
          0.0194244422018528,
          0.005810684524476528,
          -0.05601147934794426,
          -0.06660833954811096,
          -0.10984792560338974,
          -0.15278314054012299,
          -0.05396417900919914,
          -0.02695552445948124,
          -0.019630055874586105,
          0.04627459496259689,
          0.08744000643491745,
          0.08614141494035721,
          0.06895368546247482,
          0.0763024166226387,
          0.07443604618310928,
          0.08333414047956467,
          0.0638299211859703,
          0.030450325459241867,
          0.02930777706205845,
          0.06936121731996536,
          0.048585254698991776,
          0.016745416447520256,
          0.04229533672332764,
          0.03855753317475319,
          -0.006503307726234198,
          -0.03614789620041847,
          -0.0740099847316742,
          -0.06772560626268387,
          -0.029531113803386688,
          -0.0672515332698822,
          -0.03674762323498726,
          -0.12141446769237518,
          -0.1668332815170288,
          -0.1330229789018631,
          -0.16205622255802155,
          -0.17774656414985657,
          -0.28230372071266174,
          -0.4661405384540558,
          -0.4513322710990906,
          -0.5443342328071594,
          -0.5017483830451965,
          -0.5635991096496582,
          -0.5991889238357544,
          -0.5957707762718201,
          -0.3629196286201477,
          -0.5910376310348511,
          -0.7006110548973083,
          -0.8593422770500183,
          -0.9416869282722473
         ]
        }
       ],
       "layout": {
        "font": {
         "size": 50
        },
        "height": 1200,
        "legend": {
         "bgcolor": "rgba(255,255,255,0.3)",
         "font": {
          "size": 40
         },
         "x": 0.03,
         "xanchor": "left",
         "y": 0.3,
         "yanchor": "top"
        },
        "margin": {
         "b": 100,
         "l": 100,
         "r": 100,
         "t": 100
        },
        "paper_bgcolor": "rgba(255,255,255,1)",
        "plot_bgcolor": "rgba(255,255,255,1)",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1600,
        "xaxis": {
         "autorange": "reversed",
         "gridcolor": "rgb(210,210,210)",
         "gridwidth": 4,
         "tickmode": "array",
         "tickvals": [
          0.4,
          0.3,
          0.2,
          0.1
         ],
         "title": {
          "text": "sparsity"
         }
        },
        "yaxis": {
         "gridcolor": "rgb(210,210,210)",
         "gridwidth": 4,
         "title": {
          "text": "$\\Huge{\\Delta\\mathcal{F}}$"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"c912fcf1-d8b1-4b5c-850e-4ee960e6cd65\" class=\"plotly-graph-div\" style=\"height:1200px; width:1600px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c912fcf1-d8b1-4b5c-850e-4ee960e6cd65\")) {                    Plotly.newPlot(                        \"c912fcf1-d8b1-4b5c-850e-4ee960e6cd65\",                        [{\"line\": {\"color\": \"#4C78A8\", \"width\": 12}, \"name\": \"front_circuit : front_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, 1.7382586520398036e-05, 1.3952414519735612e-05, 0.003590772859752178, -6.241133814910427e-05, 0.00029292277758941054, 0.0002940017729997635, 0.0014650659868493676, 0.0015135830035433173, 0.012249858118593693, 0.01962275058031082, 0.0024858496617525816, 0.0023447966668754816, 0.0029333310667425394, 0.003482875879853964, 0.0013241772539913654, -0.0032043384853750467, -0.008814465254545212, -0.004760937765240669, -0.011306611821055412, -0.022814471274614334, -0.0007347544305957854, 0.0008744319202378392, -0.05922714248299599, -0.05293833464384079, -0.04132775589823723, -0.027838345617055893, -0.016284329816699028, -0.02555745095014572, 0.06233064830303192, 0.05773207172751427, 0.045901112258434296, 0.04111229255795479, 0.042728595435619354, 0.029567552730441093, 0.02390158735215664, 0.004080836195498705, -0.010823821648955345, -0.0182026457041502, -0.01533504854887724, -0.04601885750889778, -0.0593382753431797, -0.0790891945362091, -0.09080187976360321, -0.08797898143529892, -0.11485762149095535, -0.0785399079322815, -0.08005953580141068, -0.048308905214071274, -0.03391754627227783, -0.01231662929058075, -0.022311383858323097, 0.02537335641682148, -0.02341223508119583, -0.11858195811510086, -0.1548890918493271, -0.21237654983997345, -0.20309826731681824, -0.2605537176132202, -0.3019435703754425, -0.42584261298179626, -0.5050730109214783, -0.5804826617240906, -0.5447521805763245, -0.5082824230194092, -0.5608110427856445, -0.3371371328830719, -0.5418956279754639, -0.6379358172416687, -0.7070026993751526]}, {\"line\": {\"color\": \"#4C78A8\", \"dash\": \"dash\", \"width\": 12}, \"name\": \"front_circuit : left_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, -0.0011161925503984094, -0.0015589171089231968, 0.007133193779736757, -0.001196734025143087, 0.0011595601681619883, 0.00299309054389596, 0.01500080805271864, 0.014129800722002983, 0.026297742500901222, 0.02297896519303322, 0.001162663334980607, 0.003078927518799901, 0.0003731928300112486, 0.00272726290859282, -0.004642189480364323, -0.006749721243977547, -0.016575289890170097, -0.008229461498558521, -0.015799304470419884, -0.0320611335337162, 0.0009316981304436922, 0.010871784761548042, -0.07064809650182724, -0.058935850858688354, -0.02973121963441372, -0.02957853302359581, -0.010161051526665688, -0.03207213431596756, 0.09748845547437668, 0.08218326419591904, 0.0691845715045929, 0.06494417041540146, 0.05468206852674484, 0.028639551252126694, 0.029739167541265488, 0.0018418856197968125, -0.015391020104289055, -0.04400591924786568, -0.05857454985380173, -0.114056296646595, -0.13497328758239746, -0.17799974977970123, -0.21537548303604126, -0.22479909658432007, -0.26020699739456177, -0.22501297295093536, -0.23348066210746765, -0.18031270802021027, -0.144323468208313, -0.12816143035888672, -0.16548343002796173, -0.10322947800159454, -0.1578381210565567, -0.268416166305542, -0.2789369225502014, -0.37754571437835693, -0.37348079681396484, -0.4180731773376465, -0.485443651676178, -0.5752413272857666, -0.6185914278030396, -0.6363544464111328, -0.5809557437896729, -0.5083438158035278, -0.500476062297821, -0.25848114490509033, -0.43064144253730774, -0.5046852231025696, -0.530437171459198]}, {\"line\": {\"color\": \"#4C78A8\", \"dash\": \"dot\", \"width\": 12}, \"name\": \"front_circuit : right_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, -0.000477004999993369, -0.0012201049830764532, 0.007494035642594099, -0.0027288049459457397, -0.0009433611994609237, -0.0027262894436717033, 0.0028577407356351614, 0.004253392107784748, 0.03342963010072708, 0.04733992740511894, 0.01165549922734499, 0.0010445384541526437, 0.0005493889329954982, -0.004188972990959883, -0.006844231393188238, -0.007417984772473574, -0.012765186838805676, -0.004624729976058006, -0.02199692651629448, -0.04719765856862068, -0.020085226744413376, -0.011231852695345879, -0.08753973245620728, -0.07756978273391724, -0.05000559985637665, -0.025737712159752846, 0.0006543870549649, -0.013986589387059212, 0.10494954138994217, 0.10293802618980408, 0.0745270699262619, 0.07602532207965851, 0.07180071622133255, 0.04910240322351456, 0.05211948603391647, 0.023756926879286766, 0.0011223251931369305, -0.017623171210289, -0.022782975807785988, -0.08581534028053284, -0.11146910488605499, -0.14603060483932495, -0.16201665997505188, -0.16386593878269196, -0.20447155833244324, -0.16823546588420868, -0.17174623906612396, -0.12729206681251526, -0.06750688701868057, -0.06335151940584183, -0.09123387187719345, 0.0026488257572054863, -0.05447673052549362, -0.21803885698318481, -0.2793188691139221, -0.35415685176849365, -0.2880908250808716, -0.37542155385017395, -0.3943309187889099, -0.5649646520614624, -0.6483315229415894, -0.6374714970588684, -0.5966646075248718, -0.5456744432449341, -0.47298139333724976, -0.08776575326919556, -0.4779514670372009, -0.565043032169342, -0.566727876663208]}, {\"line\": {\"color\": \"#F58518\", \"dash\": \"dash\", \"width\": 12}, \"name\": \"left_circuit : front_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, 1.3210833458288107e-06, 0.0011112254578620195, 0.0007516914629377425, 0.00046209149877540767, 0.0004123686521779746, 0.0010086700785905123, -0.0003751262847799808, 0.0009576626471243799, 0.00045248327660374343, 0.0011376467300578952, 0.0018510556546971202, 0.004282341804355383, 0.001158238621428609, -0.0004593975027091801, -0.001239935983903706, -0.0005733522120863199, -0.0050153909251093864, -0.00857112929224968, 0.012407315894961357, 0.0028871914837509394, -0.04080475494265556, -0.04177450016140938, -0.1067994013428688, -0.11007335036993027, -0.07771340757608414, -0.06494742631912231, -0.03915814682841301, -0.051894914358854294, -0.04948516562581062, -0.0041580661199986935, 0.004097288008779287, 0.010836068540811539, 0.05640672892332077, 0.06465528905391693, 0.060128141194581985, 0.06567133963108063, 0.04729016497731209, 0.028914516791701317, 0.03952953591942787, 0.021857982501387596, 0.003322986885905266, -0.013181525282561779, 0.004966574255377054, -0.005224325694143772, -0.009173557162284851, 0.002577595179900527, 0.014935924671590328, -0.03143204748630524, -0.0071957907639443874, 0.022440973669290543, -0.03405188024044037, -0.0011076685041189194, -0.09580174833536148, -0.17366330325603485, -0.17058412730693817, -0.20817023515701294, -0.2712342143058777, -0.25243982672691345, -0.3070918619632721, -0.3428504467010498, -0.3491678833961487, -0.4188788831233978, -0.3889906108379364, -0.48459845781326294, -0.4672682285308838, -0.7346255779266357, -0.8033497333526611, -0.9233580231666565, -0.8919235467910767]}, {\"line\": {\"color\": \"#F58518\", \"width\": 12}, \"name\": \"left_circuit : left_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, -3.215639299014583e-05, 0.001107049873098731, -3.167440809193067e-05, -0.00036470743361860514, -0.00032452380401082337, -0.0011976852547377348, -0.0027500521391630173, -0.002378954319283366, -0.0029056447092443705, -0.00311667425557971, -0.004268475342541933, -0.0031233043409883976, -0.006224434822797775, -0.006575790233910084, -0.007656416390091181, -0.005382064264267683, -0.010990440845489502, -0.018849177286028862, 0.010745405219495296, 0.00464927963912487, -0.04436840862035751, -0.05458718165755272, -0.13586421310901642, -0.1486646831035614, -0.10158266127109528, -0.07769361138343811, -0.036336857825517654, -0.05693028122186661, -0.06035247817635536, -0.008163964375853539, -0.008359471336007118, -0.014502241276204586, 0.08023164421319962, 0.08890002220869064, 0.08726243674755096, 0.09855187684297562, 0.06699882447719574, 0.020910115912556648, 0.03280404582619667, -0.004291079472750425, -0.028566349297761917, -0.04330920800566673, -0.03617468103766441, -0.031132204458117485, -0.03867015242576599, -0.03884567320346832, -0.006224877201020718, -0.0530967079102993, -0.05314072594046593, -0.013638317584991455, -0.08991017937660217, 0.0011436560889706016, -0.12734778225421906, -0.1868501901626587, -0.16448837518692017, -0.14908716082572937, -0.17722517251968384, -0.19538886845111847, -0.2651654779911041, -0.25627782940864563, -0.24258583784103394, -0.41468536853790283, -0.3475504219532013, -0.5301475524902344, -0.4785098731517792, -0.8525267839431763, -0.8177775144577026, -0.8613607287406921, -0.7504251599311829]}, {\"line\": {\"color\": \"#F58518\", \"dash\": \"dot\", \"width\": 12}, \"name\": \"left_circuit : right_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, -0.0006932219839654863, 0.001940099522471428, 0.002534298226237297, 0.001190227922052145, 0.0013802149333059788, 0.0013973339227959514, 0.0004152457695454359, 8.52161247166805e-05, -0.00023925595451146364, 0.00022838733275420964, -0.002464825054630637, 0.010557367466390133, -0.003367769531905651, -0.0006888193311169744, -0.0018648862605914474, -0.0028499122709035873, -0.008923038840293884, -0.01204373873770237, 0.029526755213737488, 0.017908357083797455, -0.03376109525561333, -0.03830506652593613, -0.11381182819604874, -0.12474477291107178, -0.07803048193454742, -0.05635327100753784, -0.012911041267216206, -0.04014298692345619, -0.0445173978805542, -0.01027151569724083, 0.008174519054591656, 0.020868590101599693, 0.07804156094789505, 0.09654643386602402, 0.09704309701919556, 0.09224767237901688, 0.055876921862363815, 0.00896116066724062, 0.02455570548772812, 0.005047841463238001, -0.012617861852049828, -0.03167636692523956, 0.005094312597066164, -0.005879185162484646, -0.019047316163778305, 0.003417370142415166, 0.019470112398266792, -0.039974652230739594, -0.005180083680897951, 0.03197355195879936, -0.03822532296180725, 0.07368053495883942, -0.10109645873308182, -0.19046691060066223, -0.2143508791923523, -0.22759929299354553, -0.3144455850124359, -0.3181287348270416, -0.38029226660728455, -0.3941081762313843, -0.33732402324676514, -0.47300463914871216, -0.4171852767467499, -0.5547595620155334, -0.447753369808197, -0.8858597278594971, -0.8877810835838318, -0.9856736660003662, -0.8856136202812195]}, {\"line\": {\"color\": \"#54A24B\", \"dash\": \"dash\", \"width\": 12}, \"name\": \"right_circuit : front_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, 0.00017138391558546573, 0.00041677337139844894, 0.0006510528037324548, 0.0004239711561240256, 0.0011805323883891106, 0.0015060125151649117, 0.0027757061179727316, 0.004071537405252457, 0.005674028303474188, 0.00802412535995245, 0.009800240397453308, 0.01606273651123047, 0.020795296877622604, 0.01974334381520748, 0.019392400979995728, 0.01598370634019375, 0.013458388857543468, 0.011638614349067211, 0.008702210150659084, 0.008017671294510365, 0.012178227305412292, 0.0014349666889756918, -0.044787611812353134, -0.06386919319629669, -0.09596466273069382, -0.12030595541000366, -0.052242882549762726, -0.03928159177303314, -0.03697005286812782, 0.011422009207308292, 0.03654766082763672, 0.03666992485523224, 0.03163382038474083, 0.03194689378142357, 0.032435040920972824, 0.04789295047521591, 0.04031417518854141, 0.034321874380111694, 0.03441024571657181, 0.045513805001974106, 0.04528412967920303, 0.03749917075037956, 0.05669951066374779, 0.06017761677503586, 0.03470951318740845, 0.006420323625206947, -0.02595015987753868, -0.013925587758421898, 0.0012662826338782907, -0.026336107403039932, -0.0254130307585001, -0.079166479408741, -0.12838493287563324, -0.1301802098751068, -0.16253919899463654, -0.18014830350875854, -0.2542143166065216, -0.35961827635765076, -0.32882949709892273, -0.4218933582305908, -0.4310300052165985, -0.5311356782913208, -0.5643637776374817, -0.5783022046089172, -0.4657675623893738, -0.5351598858833313, -0.6806021928787231, -0.8644711375236511, -0.9596694707870483]}, {\"line\": {\"color\": \"#54A24B\", \"dash\": \"dot\", \"width\": 12}, \"name\": \"right_circuit : left_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, 2.8554377422551624e-05, -0.00016418426821473986, 0.001029788050800562, 0.00026983380666933954, 0.002156483242288232, 0.0023511655163019896, 0.003272106871008873, 0.007564453408122063, 0.010454903356730938, 0.0161150973290205, 0.02210930548608303, 0.03903473541140556, 0.0459972508251667, 0.04470214992761612, 0.04747873544692993, 0.03888942301273346, 0.031920041888952255, 0.0248271431773901, 0.020175205543637276, 0.01645454205572605, 0.030235275626182556, 0.015246853232383728, -0.03851575404405594, -0.060613855719566345, -0.10210167616605759, -0.14274993538856506, -0.04910259321331978, -0.04056711494922638, -0.04665308818221092, 0.030005045235157013, 0.059493474662303925, 0.05896180868148804, 0.041300151497125626, 0.04363309592008591, 0.037969354540109634, 0.04264392331242561, 0.03392304107546806, 0.010303265415132046, 0.0018938626162707806, 0.019028112292289734, 0.005071243736892939, -0.04333989694714546, -0.010036076419055462, -0.018765924498438835, -0.05300196632742882, -0.10361899435520172, -0.15357142686843872, -0.1491495668888092, -0.1238928809762001, -0.14953045547008514, -0.10083331167697906, -0.16613885760307312, -0.23867206275463104, -0.24855060875415802, -0.21570557355880737, -0.22239673137664795, -0.30365097522735596, -0.4654543995857239, -0.4100033640861511, -0.5269988179206848, -0.5333060622215271, -0.6285701990127563, -0.6689845323562622, -0.6429247856140137, -0.4834791123867035, -0.5749195218086243, -0.690983772277832, -0.9391011595726013, -0.9199713468551636]}, {\"line\": {\"color\": \"#54A24B\", \"width\": 12}, \"name\": \"right_circuit : right_data\", \"type\": \"scatter\", \"x\": [0.39988147865853657, 0.3941440545433122, 0.3884066304280878, 0.3826692063128635, 0.3769317821976392, 0.3711943580824148, 0.3654569339671905, 0.3597195098519661, 0.3539820857367417, 0.3482446616215174, 0.342507237506293, 0.3367698133910687, 0.33103238927584433, 0.32529496516061995, 0.31955754104539563, 0.31382011693017126, 0.30808269281494693, 0.30234526869972256, 0.2966078445844982, 0.29087042046927386, 0.2851329963540495, 0.27939557223882516, 0.27365814812360084, 0.26792072400837647, 0.2621832998931521, 0.2564458757779277, 0.25070845166270334, 0.24497102754747904, 0.23923360343225467, 0.23349617931703032, 0.227758755201806, 0.22202133108658162, 0.21628390697135727, 0.2105464828561329, 0.20480905874090855, 0.19907163462568422, 0.19333421051045985, 0.18759678639523547, 0.18185936228001118, 0.1761219381647868, 0.17038451404956242, 0.16464708993433808, 0.1589096658191137, 0.15317224170388938, 0.14743481758866503, 0.14169739347344065, 0.13595996935821633, 0.13022254524299198, 0.1244851211277676, 0.11874769701254324, 0.11301027289731888, 0.10727284878209456, 0.1015354246668702, 0.09579800055164583, 0.09006057643642151, 0.08432315232119715, 0.07858572820597277, 0.07284830409074841, 0.06711087997552405, 0.061373455860299735, 0.055636031745075365, 0.049898607629851, 0.04416118351462668, 0.03842375939940232, 0.032686335284177956, 0.02694891116895359, 0.021211487053729224, 0.015474062938504904, 0.00973663882328054, 0.003999214708056171], \"y\": [0.0, -1.6758193623900297e-06, 0.0001121868917834945, 0.000252897763857618, -0.0007512258598580956, 0.00012097180297132581, 0.0004055119934491813, 0.0018722756067290902, 0.00467853806912899, 0.007072902750223875, 0.010854504071176052, 0.015930647030472755, 0.029145611450076103, 0.035437844693660736, 0.030968183651566505, 0.027787169441580772, 0.021077124401926994, 0.017102887853980064, 0.015004996210336685, 0.009358704090118408, 0.010635781101882458, 0.0194244422018528, 0.005810684524476528, -0.05601147934794426, -0.06660833954811096, -0.10984792560338974, -0.15278314054012299, -0.05396417900919914, -0.02695552445948124, -0.019630055874586105, 0.04627459496259689, 0.08744000643491745, 0.08614141494035721, 0.06895368546247482, 0.0763024166226387, 0.07443604618310928, 0.08333414047956467, 0.0638299211859703, 0.030450325459241867, 0.02930777706205845, 0.06936121731996536, 0.048585254698991776, 0.016745416447520256, 0.04229533672332764, 0.03855753317475319, -0.006503307726234198, -0.03614789620041847, -0.0740099847316742, -0.06772560626268387, -0.029531113803386688, -0.0672515332698822, -0.03674762323498726, -0.12141446769237518, -0.1668332815170288, -0.1330229789018631, -0.16205622255802155, -0.17774656414985657, -0.28230372071266174, -0.4661405384540558, -0.4513322710990906, -0.5443342328071594, -0.5017483830451965, -0.5635991096496582, -0.5991889238357544, -0.5957707762718201, -0.3629196286201477, -0.5910376310348511, -0.7006110548973083, -0.8593422770500183, -0.9416869282722473]}],                        {\"font\": {\"size\": 50}, \"height\": 1200, \"legend\": {\"bgcolor\": \"rgba(255,255,255,0.3)\", \"font\": {\"size\": 40}, \"x\": 0.03, \"xanchor\": \"left\", \"y\": 0.3, \"yanchor\": \"top\"}, \"margin\": {\"b\": 100, \"l\": 100, \"r\": 100, \"t\": 100}, \"paper_bgcolor\": \"rgba(255,255,255,1)\", \"plot_bgcolor\": \"rgba(255,255,255,1)\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 1600, \"xaxis\": {\"autorange\": \"reversed\", \"gridcolor\": \"rgb(210,210,210)\", \"gridwidth\": 4, \"tickmode\": \"array\", \"tickvals\": [0.4, 0.3, 0.2, 0.1], \"title\": {\"text\": \"sparsity\"}}, \"yaxis\": {\"gridcolor\": \"rgb(210,210,210)\", \"gridwidth\": 4, \"title\": {\"text\": \"$\\\\Huge{\\\\Delta\\\\mathcal{F}}$\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c912fcf1-d8b1-4b5c-850e-4ee960e6cd65');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from circuit_pruner.visualizer.layouts import big_fig_layout\n",
    "\n",
    "fig.update_layout(big_fig_layout)\n",
    "#fig.update_layout({ 'width':3000})\n",
    "\n",
    "fig.update\n",
    "\n",
    "fig.update_layout({\n",
    "                    'height':1200,\n",
    "                    'width':1600,\n",
    "                    'font':{'size':50}},\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(legend= {'bgcolor': 'rgba(255,255,255,0.3)'})\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "                                yanchor=\"top\",\n",
    "                                y=0.3,\n",
    "                                xanchor=\"left\",\n",
    "                                x=0.03\n",
    "                              ))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "                             font=dict(size=40)\n",
    "                    ))\n",
    "\n",
    "fig.update_layout({'showlegend':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64e1b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"plots/faces_activation_diff_big.html\")\n",
    "fig.write_image(\"plots/faces_activation_diff_big.svg\")\n",
    "fig.write_image(\"plots/faces_activation_diff_big.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6681f791",
   "metadata": {},
   "source": [
    "#### Compare IoU of extracted circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4cded32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "target sparsity: 0.25\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8658      (total params * sparsity)\n",
      "original mask: 162498 params\n",
      "effective mask: 162237 params\n",
      "effective_sparsity: 0.2491770141495813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/chris/dropbox/Research-Hamblin/Projects/circuit_pruner_cvpr2022/circuit_pruner/extraction.py:251: UserWarning:\n",
      "\n",
      "This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_8 effective last layer\n",
      "target sparsity: 0.25\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8658      (total params * sparsity)\n",
      "original mask: 159282 params\n",
      "effective mask: 158940 params\n",
      "effective_sparsity: 0.24891712388102802\n",
      "features_8 effective last layer\n",
      "target sparsity: 0.25\n",
      "total params to feature: 56677\n",
      "\n",
      "we found 22047 params that were already zero'd out, your model is already a pruned circuit right? . . . \t\t\t   just making sure, we are subtracting these params from the total.\n",
      "\n",
      "new total params: 34630    (after subtracting previously masked params)\n",
      "kept params in original mask: 8658      (total params * sparsity)\n",
      "original mask: 159122 params\n",
      "effective mask: 158719 params\n",
      "effective_sparsity: 0.24877274039849842\n"
     ]
    }
   ],
   "source": [
    "# extraction at last good sparsity\n",
    "\n",
    "from circuit_pruner.extraction import model_ranks_2_circuit_model\n",
    "\n",
    "ranker = ranks\n",
    "\n",
    "target_sparsities = {'front':0.25,\n",
    "                     'left':0.25,\n",
    "                     'right':0.25}\n",
    "\n",
    "\n",
    "\n",
    "sparse_circuits = {}\n",
    "sparse_masks = {}\n",
    "\n",
    "for aspect in aspects:\n",
    "    sparse_circuit,sparse_mask = model_ranks_2_circuit_model(ranker[aspect],target_sparsities[aspect],\n",
    "                                                           general_circuit,circuit_feature_targets,device,\n",
    "                                                           structure='kernels',use_effective_mask=True,\n",
    "                                                           rank_field='max')\n",
    "    sparse_circuits[aspect] = sparse_circuit.to(device)\n",
    "    sparse_masks[aspect] = sparse_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "588f71d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_pruner.utils import mask_intersect_over_union\n",
    "\n",
    "comparisons = ['front:right','front:left','right:left']\n",
    "\n",
    "ious = {}\n",
    "\n",
    "for comp in comparisons:\n",
    "    m1_name = comp.split(':')[0]\n",
    "    m2_name = comp.split(':')[1]\n",
    "    ious[comp] = mask_intersect_over_union(sparse_masks[m1_name],sparse_masks[m2_name])\n",
    "    \n",
    "    \n",
    "ious['polysemantic'] = [.72,.44,.2,.09,.25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8325b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_pruner.visualizer.featureviz  import featviz_in_recep_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9614504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "        Layer (type)    map size      start       jump receptive_field \n",
      "==============================================================================\n",
      "        0             [224, 224]        0.5        1.0             1.0 \n",
      "        1               [55, 55]        3.5        4.0            11.0 \n",
      "        2               [55, 55]        3.5        4.0            11.0 \n",
      "        3               [27, 27]        7.5        8.0            19.0 \n",
      "        4               [27, 27]        7.5        8.0            51.0 \n",
      "        5               [27, 27]        7.5        8.0            51.0 \n",
      "        6               [13, 13]       15.5       16.0            67.0 \n",
      "        7               [13, 13]       15.5       16.0            99.0 \n",
      "        8               [13, 13]       15.5       16.0            99.0 \n",
      "        9               [13, 13]       15.5       16.0           131.0 \n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:16<00:00, 31.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; flex-direction: row;\"><div style=\"margin-right:10px; margin-top: 4px;\">\n",
       "                            0 <br/>\n",
       "                            <img src=\"data:image/PNG;base64,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\" style=\"image-rendering: pixelated;\">\n",
       "                        </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13)\n",
      "(6, 6)\n",
      "[(46.0, 177.0), (46.0, 177.0)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=131x131 at 0x7FA5CA783C50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featviz_in_recep_field(deepcopy(sparse_circuits['front']),layer,0,margin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6ed0c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "        Layer (type)    map size      start       jump receptive_field \n",
      "==============================================================================\n",
      "        0             [224, 224]        0.5        1.0             1.0 \n",
      "        1               [55, 55]        3.5        4.0            11.0 \n",
      "        2               [55, 55]        3.5        4.0            11.0 \n",
      "        3               [27, 27]        7.5        8.0            19.0 \n",
      "        4               [27, 27]        7.5        8.0            51.0 \n",
      "        5               [27, 27]        7.5        8.0            51.0 \n",
      "        6               [13, 13]       15.5       16.0            67.0 \n",
      "        7               [13, 13]       15.5       16.0            99.0 \n",
      "        8               [13, 13]       15.5       16.0            99.0 \n",
      "        9               [13, 13]       15.5       16.0           131.0 \n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:15<00:00, 33.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; flex-direction: row;\"><div style=\"margin-right:10px; margin-top: 4px;\">\n",
       "                            0 <br/>\n",
       "                            <img src=\"data:image/PNG;base64,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\" style=\"image-rendering: pixelated;\">\n",
       "                        </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13)\n",
      "(6, 6)\n",
      "[(46.0, 177.0), (46.0, 177.0)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=131x131 at 0x7FA5CB106510>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featviz_in_recep_field(deepcopy(sparse_circuits['right']),layer,0,margin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8dab4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "        Layer (type)    map size      start       jump receptive_field \n",
      "==============================================================================\n",
      "        0             [224, 224]        0.5        1.0             1.0 \n",
      "        1               [55, 55]        3.5        4.0            11.0 \n",
      "        2               [55, 55]        3.5        4.0            11.0 \n",
      "        3               [27, 27]        7.5        8.0            19.0 \n",
      "        4               [27, 27]        7.5        8.0            51.0 \n",
      "        5               [27, 27]        7.5        8.0            51.0 \n",
      "        6               [13, 13]       15.5       16.0            67.0 \n",
      "        7               [13, 13]       15.5       16.0            99.0 \n",
      "        8               [13, 13]       15.5       16.0            99.0 \n",
      "        9               [13, 13]       15.5       16.0           131.0 \n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:15<00:00, 32.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; flex-direction: row;\"><div style=\"margin-right:10px; margin-top: 4px;\">\n",
       "                            0 <br/>\n",
       "                            <img src=\"data:image/PNG;base64,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\" style=\"image-rendering: pixelated;\">\n",
       "                        </div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13)\n",
      "(6, 6)\n",
      "[(46.0, 177.0), (46.0, 177.0)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIMAAACDCAIAAAAh/z8xAACKpklEQVR4nFT9Z7xl6VEfClfVE1bY+eTTOUx3T0+O0oxGEsoBhAQYE024IMC8YOPLi+17r4352WBjgwPYvBhMMiKDQYCEAEWUZkaT8/R0DqdPPjvvvdZ6QtX9sLtHfveHPjus1fucqqfyv6rwp//DTwOACDBHEUAiQRARAABARAREZuYYAQAABAABRISZI4uIMAsIiwggMEfvHXNAZMQoIiDAgCAkQAAogIACwMIRQAAEUWZvxxBjCBIZgAAIBEEEEJVSWisCAREEJCJjjNaaiESQGZRS2milFCIhEQIgEjMTEiEys8RIhEgIAhxZmAFRa0UIs3eYRZAAZ3RgAQARFiEiJGTmECICIiIhAICIIAAR3rheZPYviAACzO4HQED5KinhxjMBJMTZFSAAs5eoRQQQRWZEk9lns29DnHECZp/OnoCIIIpwiHH21QCzn8KBQwwheIGAEpBkdiMLAWhAFABEEWbhIMICIhIRWSREDiIRhEUQgUA0RxBGJDIgAIw32AjGaJAIgooosgAIklZKkdKECDNuEImAUgQCwQcB0FqRIhGJPnAEAVSKFJGIEJEPHCODgNJKaQWIzjmIAIhIRICIN0g2o9UNboggIN48uLNTOaOZ3CSz3Di6M9LdONvwOokBCBEAWFjLTSYA4ey4IiAAAyIgAgLfvAJhxpXZd95kD4AAi0gIIfgQguPoEDxL5Bu/rAIgmf0GggjM7BAkxigShUOMDjAARiBGABEUIA4aWIEQEQmHaDQhSWQCEA6EVhEIEwARoVKKlNJaISkQ0FohoggkieXIAkigk8QKSPBhRn1hAQEkpRUCCLgYiyqyKABtNSI555kjICDhDQISKkWzG2e0nWmL19kAN6gENzkFAjxTLDcuuMFKvEk9gZsfCcsNTggAEQnOmChfZRrPjjDPFAUi/m8sQABhYRGJIYQQnCujd8JOJDLEKMhAgoyIgAzCAAwxIEThwDFyDBy9QBTwpBmVCHCIIKBBDEQNrJBIa6UlEimOjCLMikgAIDJoY0UoxmgRbZogKl85BDTWEhEBKlLMSAqTLBFmhIoIrTXBe1d6RNSGjNHKBO8j+4CESusYgojMNDPcPHgzFrIIgBAhCEmMMTKi3JCD/53oCAI3aHZTWmTGVHidDQB08zIB0XJTiG4ooBkrRBABAIWZv8qG1/kzMwvAIPHGgzl6jp7ZxeAjcwSIggxISgEikgAzcIDoOIToXYyBgwOOSCzEQMzIIsKAM5WFzMCktAEEVCCKAIU5RJEAGmMUjBEiMLOgtREEkERbrZVOslRYOESlVaaNiGhtAABRaYVJYsppCUw2NVqrmVKxidVWa6tFIISACNoQEgGSxMjMMc50uGhNpCj6EJjxhoDcUOM39IMI8M3zPlMazAIwU8w3qYg3LceMA6hvHnG5Qf2v6pybEgUANDNU/5v6E2GOzBw5+hA5Bg6eoxOOkcUFCUKCClALaUTEGIUjhCp6F13pnQveSwwIzMyMwCARBRUCIRIqYgWsEJEZAJFQaQIFEpU2WidGKyuiWYgFxLML0TtP2hqjkixVWvnKq8SmiQ2Bow8AYJMkyzIilBhZXJpnzXYdEcfDCYCv1XNtNYOMB+Pgo1JEigBxxgVmAYivG1xmDjECABK9TpbXBWKmqW6c3NmpnQkHwkymbtqSG2Se6UAdOd548bogzrQgyw2Nd+O/xJvMZgFmjjGGOHsBEmIIroohRGYWDKAZFZBBZYFIJICARB+qKvrSV6V3LobAIcTIzOIZBBGIUBMpVAasnfFDoVKklDLWpgaAIUqaJVmWa0pAFIIKLnJkQhJA7z0hkQgB2tQaY401WHlgBCSbpEliCbGcloBVrVlvNOvehUI5UjGrJzY1k/FYmI1RN4wzSxSenT0WAASFIDIzckxISDfVBgIpZBYUEGYBUK+7UACIgASv21gBJCR43XdCAkDNzDMv6qaDCl/VRTckDG/w5IaZwBgkRA6Rb5xfAccxxBBCDAJRiFELWmUSZYxCIMBYlT5WMVSuKn1ZBO+Dj97FEIUBGQgISZMiTVqRskonxhhNKkmMSVObJUlmkSCGqNPEZrm1NWQk1OJ8jFLLU2t06WZnBRUp1EorjQBZlhoD3kURUspYo5kxr0uaZQBEpJI0J63zesYcfOkVoa2nAhB8LEsXIxMhKeKZyw4AMXJkYUElzBJjBBFCAkQQEJavGuWbrirRzGF+3ae94UqJyMyjBRB9k/Qz20AIwCAzzQc3hOGm9woQ4w3VFJlBEQCysA8hxhCYmRQzRCEWRdqQsUjI0flyHMqRLyeuLFxZxqqqKu9cDFFEELVRWpFS2qY2tSa9oWGSxBoio1VSy5MsMalVmjhGa1RaqxtKtbIQhbUh4VqeJVanjkMUBIxRNIoyhICJTbJUFYWPUYiUMYkAWZsowug9kak1tVIEwINejwOnWZLWEu/DqD/mGAlRCBVidEGYI0jwPHMjIfIsHJnRiQPP/FFEwJl5ZwYAuqnBbvhKiF+NM24ofWBhTXQjYgAWIEFCYpxZf8Cb197wABhAIjPP4jERQAghOucrHxhQSAkAojI2U2lOgtGXoRi76SBWE19Mq+nUV64qnXcxsgApZbS21iSJtkYnibGJtjrNrElsmiTWKCKyaWqSxKYZKWIfbGqNyRObEpCECEhKvDXaGqNJBEiiaEKjCDkqpRRAYrVCDFG0Ugxobao1cQjTwCZJtVVa0XQyioGTLDGWSGMIQYQJADUBkQRGjDf//qhI3bSXwMx4w9wxApAiBGC+ES/djDVhFi8iIhLJTYcJCRFx5rJquGk9ZrKnNDECxyiv25yZmkMUoZn1icyIBCgsIgigFCgtiICkjDE61WkNEdk79kGkRPQSq+hLV1Vl4bwLIqiMsmlis0zZTCcJaaNtkqSptcqm1qZJaq1WqLRKrLFJZmxCWkdyigyQESAAUgo5OqUUAChkm2pCjYAiqBUgoSIkiRiDVWQ12USDUkBaAQhwmmU2TbSeOZOYZKlJlFIynoxcVRmt2CokioJV6ZEQGUPkmSOKACwAfDM24JnLcyNIfv0lvR41M8/ixNeDvBsCgTesiRYRIkUKhPmmNSESiMwzpgHATG2hCCCzQGRAAgASANSiMbEkkaOyiUprqDMO7KeT4AtXDCbDYTnsVeNJOS195TgyEtlE11u1tJbrLCebCyhlU5ukxhhjVJIm2ujEWNKoiEgZpQwKYQRAU3nRBhGxCj46r4QNMIk4MEmM2jKRJYXWKkXIIkahMCOIMdoQKKtJmbLyPkiaJYnRgMgckyyPHJhd8JUrK+GY1xOlsZhWVRli8KQUKBUVzbTqTPloNfPvZkZ6FuUw3vRSkQDppsnAG3EA8/8WsN18IIJmFlKgiBgQZtS+mQmZ3TzzjIWQBIgoMoTImrTSKkYG0CLRswApMpoJfFVU48JPptV4VAy6k0HPF9NYlcEFANFG1WvJ4krLNhqiUlFpRENkTZqmqTHaKkJUWiMhKInCDBx9EARrWbyQkijBR4VgjSodB88IsQKOlQsGIE/SJCWlKZrU5tooZZT34l0QZILEKlCahBUnRilFRCyglE4TFImuEl8VzGyNSVMLAOPRNPqgFNGNvxeZWWvNIiEwAipFHF+n7o2fs/gTkWbUvxGmzcI/AEAgIuGb4QIiIurZtaQUKeTXLTsCKTWzBLMkBREBAjIwYGCxWqMyIIGjF1SCJCSgkSE658uimHa75WhYjYfBVyBRK7CZtla35rIDR+YpaxQhrbyKaI1JlLUaUSNIEFEQY1QaIwdSCASACNGDZyRg7yFiQFSiISpEJGCtCEEUyXRSSHCcVlmax6pSwSdzLasxscZbnowmvtBpmhJwapRS2vvofNRaWWucF2stUV5Ox9YYUUgIs1SKIk/WRhFfBmY2VpMiV/oQAqIQ6Zv0lNmRRwERnoUjciNuAwS6kb2SG6ksIH49eENETUrhjHtEKDKTsxv3AJBCFuBZPEIKCARIBEEZbZMAoBVxEJOllKoks1GkmEyL4aCcjKuiiByVAkWEbLRSS8v5vqPzlM6Npmo48lFCPj/HDMVwpEiRoNI2r+UIEYCVTlINirxGQfAKFQmwZwoR0AbOSwkQQLwEg5KgKFbIrhiroCiUVqf98SSU06VDB5KasTbViiajaTGapHXSidUEkYSjKEUCSKSSxBJxXq9PxqPJqNDEBGwsJqyjwGRSeeeVJqVREcmUvfNKkcxyUxxvJB5EEEErRYTMHANrrUhpnOWcmWe6BvCGwX49RtdENDMzHOMsuXUzfzITlplACSOCAGpNSvnAgqSslcDBOSCjLTJKCDAZTwe7/elg5CaT6J212hoUj5ZwcTE/dGo1msZel3Y2Bz6GhVuOe6/769c1cpImppbnzVq9kaYqZImNZfTTUaiK8bR0rgyRjVbCBCJZnqi0ZlLrHQIzV0LBiAalCAWQnULkGBXY7fVJrNyBk8fSRrNWy4xR04nzVamUEhDgmCQpKfTeR2ZEEEFjElKaY2SNQGwsRaFYcnAeCbTVShP7EHxABFJICEKACCGyiBASESqtoogrHQiSUloREsU4y9QSECAAfTVqBgDQSitAAkDheNPPmhkKvOkNzEL2magawBsZImUNOWYXlEqElXAIProyRBdCWcYQjbH1pk2UE9ZzzXRlfwdMc+N61dvzEXn19hOom9svnhPHVKPWSmdh30Iz10b8aLu7uz7e2xp09/riyrKqwsxhI7QKQSA1uj3XyfLUJiZJU23RBw1aobIMqogBGrHTSZIUQWB7o1sOxrc8eHfWaCSJJdSlY1+WqA1wJGSjtQBJAICoTQLCeb02naSCUSEZiy6ASCQFqLS1iqNUZUUoaWpEYmRQpLxwDAGRUM+saXSV9z4SkplFdyzCgkQ3w+iv5lFn7NBIalbxQFKzMgcDoiKWm3EgCDNHEE3KGq2tZRFmUNaSFeVCkijwTjzGGDhyLCv2gQDSVDdbSauRVRNPgpHT7auj/l5p6/VD995O2rz8xTNuXFGml287dMeth6aj/mhj49KL59cv7wQXi2LqnCMCZhGUWcREABKiQurtDo1NEqOSRM+10oW5vNPM0jxFnU4KnoyKYmyPHm3njUyptLdTXHjypSN33ZJ3FrRJU4Xei3NVCEEQSJEirRKDYEJwrFSaZrVWo5iOopsCMpJEjtrQzJ8oxtOqrEgrJIghRBCyN8LrmUZHxBCiD1FEgJCZnQ84S+AhCCoEYGGWmxG0AADoWWQOiEhISAIwyyPOsh8xRhbxPkRGIJ1rldYz1NpHYQZrDDUbMYaiNxSMaSPb29yqxlMOgQjzVnrs9EE/GL564Vq7UeeoJhNfX+ycePDeylXPf+6p6W6BeXbLW29/5wN3XnvpuS//5RdHg6K723OV01qLROZoNJEipSlGEY7AwJGDcMmld2HCLAA7O2qjnrYb2cpCtn9/K0vreyN3bi+M+73Tt61k7SXBWnd7qs5cWz0e64vLZDKb6Fj6irkajiNirdYAkPFkGqOPwSGRsUkxHaJCBQTApNGSJqXKSVVVDgBsZqL3PrLnaBKlNAECM88SdACgtGGOABBjFBY1KzKyMPDN3MWNmpKAEJJGohjjTBZoFuchsggSKiJg4BiBSFjKMpjU2yzNms3I4j1rRSLsnAgqk2hjzXiv76aliJjcnH7wlqahr3zhTDnyuimtpXaf7erxo7m1j3/i0eluL6K6471v/NBb3/jEJz/9F7/xMURgAu8qYUkSkyaJd2UjUwxYVpFJzaRiVqNIlMqMKX0sgweW8bSalGG3N9ncHt16ernebkwm/tK1STWa3nE/NheWcNEOxlO+tLEMVJ+fN2lNG0QHVeG0r5RqaKUwT11Q3hN5MOVYaRNiJQBEaKzSAkXhZpmorJE22rVRdzAeOGOISMQQKorMIhJZlDHKondeIt+oo85iCxDh+NVg+/WiG6GelV99iCxCMZJSDCACpIk0GUMGjY5cFmEycdNp1ZjLGnOtyXDqfVTGGKsiKJtlWa4HexvDrW3xvrbQOHnfAXHF5TM7VemVkjvuO7xw/Ja1/nmu4uVXzvfXN22WHrrv2Psfvvu5p5/6yH/+Xa2M0rhwsN1oznfXep252lJHlSPq90uOAlGU0mhNniUZkRGYy8z++fpgNNkYFoHFCfemYVqFqzvTYbV+2+3Lzfl8ryjXuxU/ceGO+6U216aKp67aXt9ghfU5QrIizrkxjkO9lmGaCwgRaa1jQCLS2hYlKWWs5aqaCtEsFaGtai80E602+qOqKLVJQAEhAsmsoI8AgKgUiVaBhRBJ0+ue0eyhFInw628iog7BC4APPgQGQmU0IPnAzIwKlSFjlbYmzUwUAqDg2djEZmyzBEgZZSs/Ca4w7WZ3a8cVLmmo0w8ddoPhxVd7HWsbrWx5uXn0jnt3e9P1V67oExhRM8j88SN33Xti89qlj/zrX2WWAPHAsc43f++dj/7V2UJRLv62gwvPPzMaT0ItTVs1bWp5vdM6dmz+YKc+3h6lOqt1WkbTubNXinJqMpoCvfzqZq8/7o/8cy9unz69nOY0HsL1vlMvrh0/DbVOO3jfG3jILCRJXmsySFWV2khRDBlA6zTEKJE5slJaJ0niEhHW2meZrTxU5aRyvtmppYnZurYxHkyQwKRaWapKxxwBJAIjyA0cgg+z4y8iMbIiQKKbiv9G3YdoluUF7bwHIhYJIaIi0mATAyoWRRV8pIguhFQwr2UZqGnBVeUFKavl80tzMUB/b9rf6VfTca25qBLFHI21KbmrF7YNqIXVuaWDSa3ZHHfHZ55+sRwOWgtNZ+pVWbXnWqG/8bHf/pzRyhPmNfXz/+XDv/BvfnW4lyzXzULdUmm8Ty1BPbXf8uGvOXzqRJrUE4XIuHd9bfNCN1JH5832qo0b10nHQ/tbh2695Ut/99zG2l5Z8dlzewdX29pAVcpmb8rntw4ew7xWUybpd3u2npNJK19GdlVRRZ+bessYIpDCu8ChVm8EDr29nkZBpYXiaFIUhc/ypN3KR71Bb3ugta7PZZ2l1nQymQynMQgqZazSRouwK50rKqU1Gg0RZ/kOfcNT+moYMStJCwvNalLGmiRPjLVKK2N1s1mvN3ObGFIEgD5EH1gIQVFVBWZIs7TdrNnETqZu1B1WztVbDVIYvXfjsr/ZTxKzfHD+yK3HV/fvXzt3+drLZ4QhaWaHTxztDQo3Ho6vndu78Kor3OJCLUvtj/7DWwfXXzr7mhPP3/HeU81IF88PjJ3La9lP/OyHH3j4A6udAymHaq833u1VE0zzJumoU3Pk9Om0tRql7Vw9r8+//++96+Rdx9Ms9w7WNkejKqDGIoa9sVvb7A9G08l0Gnw5GQ1LX5HC0bS4cnVzOu5CLDH6qiyLqmw2m7Usl4i+8CJQb7SQLAdpNmsHD87XMl0MRwpVVs8X9i0qpfu7w/FgGmOsN7J6M58Vo8ppISJIMLPkMYTgvfdBXgfpKEIEuZnf0wJCpJRWyhrvmQW8Z0EWwRg4MgvHGIW0z/O80bCVQx8RgMbjqYi05/L+XhrKyaS/W+1sIUdNWGvUXEUHbzlmbbp1/uLeZnex05jfv7I2qJyr1l9+nqMvutuLJ+eNhiPLWcvyXGbWnt/QZN522/KhOx/6y4++HBPV2Vf7kX/2fy22Fy58/CP/83efvlZIEUQbs9zu3HF04Y67b91/63LaaM4vNi68eHl7OBVsJ7XsHR9491OPPvHasxe9D91BmVtKrVau7I61ztKai4nVJh3kk0HW6ESyo1FRjnqx2HMxlqXU6o08Scajfqw8kp5b6hibbG3uYeSaJYyhtzfqd4vA2KwlaZbubu0UY88MaZ50FjqTcTkeTnwZlMK0lmZp6l0Izs3O/gx49P+H/7hR1ENNRDBLZWjDEtkFjsAMSJpMEqoSiNI8zfLMpkmW16sARSXTiV9fn+YNe+TIMqSHnvni9Sc//VicVmlqG3O1pYOHIuzGoiq5N9rrNRu1xsLizngSXTXodt1gAACplv2rc7ldy9LkvjvS4SBr1zonljYffPuDYTiuWDVz/P6f/Md5rf5HP/WTf/h3F1gkADJo0mZQuGvd8VdeKU58dufrv/udrcOdfbcez7ujaWRQ9XrLvPm9rdb8s688fW7c6029KwM7dJIEPXZEalJ4SOvJYGzShiLT35sMd0dhtfJhaEwnTWw5ncTSGW3SZq3VWezubG5d3Ei0MmkWIw+GzrPSVtcadVf66bDUJlGaWu1mjHHYG7vSa6Nr9TyvZxI5uEBEpJSxWikVZ/grpYRvgOFmaSutSEWBGNhYSlOD5AUQSSkibQQQs9y223VUmhmNMWlm0zRWpe93pxX407k5tK/1+d2dYns3t9js1PYdX0VRzbw26o6TWtaYa1Oabm5s9CdFklNRjUDYKHVgf97p1Bup6bRqp24/urVRrK4ee8ebyjIoDabTbL7/Oz9kVPKVv/jdTzyxTkrXU3zrOw+YuVNPPLkz2A3BJbtFNVzrnvulJ4/fccddb6hpZaxVLpoMazpL73zjW5LOwtUXzmxe2xqPp4NpZJpGMFmeCZuwO7W1ab3tGrmtynDh7Maho/tszRji6KrJaAiUYlI/drSTaBjudMUFmydL+5YC2sIbBpMkOs/tzuaOK0KSJEBApItx6V1M86RWz7M8izG60sco2mhttdbau+ArP/PQtNEAEOONYFsrIhQQhhjZaINKMQuQsAgpQlDaWlKqrLzzQNZ38jxLdOT6xPnpZDD1VfClG41D5SjP51eWFGQ8dY0kGU2CABGJRLex0aOaWTx2YLS7h77KU3PkRDtN5w8ud+baSyv7T5u4VU+y+okDZVTQWbjzkYfyfcs755/8wmfOzS923v2G+jf/0I8y6J3u4JH3zzO0mM3amfD0U8OtndHlndHVz+5mHbOymnYa3BiFxaVaM8uO33JicWn+3Evnz79ydbi7OxxVqKq075qd5rT0dqc/tzKXGZNaXN8ZXF/bOHRLPZEyFNF5wURnjUxJ1dvZCFPXWV5Y2LeY1pqXL69tXd8tJ5NkuV0V1XhYICpjbOQgUXwVFVGapUlqXekm40KiKK2TNNVahRBc5YXFJCrJEqVU8GFWyyMETYoQMLIEH0lziLGqPEUlhJWLkbEMIRcILEGk8nFcOo2xUbMrq43+OE7K6fnXLvhJ6aty9djRQyeOPP13zy/PzR09uDja67Kospz0e4MQfbNea9fztZcuSIzLB9un7nkj+DRvLx89duvc/FLqlRKb7D/pQuJdPP7w7eWkX/aHK6f3f+u3fuPy4skI3Bv3BrLUydutRppoOnWYvuadeGE3Pr3m1jfH3fWdzb3t4WiSp3x9p7dvtbnc4iyv3f3Qffnq/mf/7pnh+tp4EmVryFkjTdP1vencdv/w/k6zoTevT3a2d+cXmrEqTbagba3WyAHk+vWdaXdca89jrdXsNPd2eptXtke9MRBnaRp8pZCMMQCQWEtAEBkAUNiXbtifhhizPE/SBBFDjDFERFSJyeu5Uso5H3wERCIUBK2NEYBQeZjl8DhWwbtpEVkCMwMq23AxqkQRRkEejSfMfmF+rtNMGq0F793amWt+UvqyOnB45cjRo8984aXpYGKPriJwr7fLrnIx6NzmeVptb4X+KLHq3d/8QK1xfPvqpQP7jh4+dKDVbLdrS+X2brKwwFTb6+7UNY+nVnVW3nf/+ycmG4mdBrzQpcSnz13huSVMM6pZtb+pDq7ao/uyvSK/Nmpf3VzaubJe9HtFVVy7tDnpUGc+XZlr3nnrYUrzR//ii344Ho2V7oe51boIbGyN2w2tNBEGH8uinA76Zb2t87ZSGK1JGo1aWXVCVcRi4KdVNRwszDcbzZqyem6uNR5088yS1jZNyqKqphUwKEQErErvfbSJTRJDimKIMUQEsNbM4G7eB1d5ANBGz0BTGulG4FeVlQUBhUQYhZ33qBUpLJ2blkWaJaSYVIwiLDCtqtSigK/KSa1eByRCY0zDEh2+5Ygvp1cuX9fG9Pf20gRVQiFENx17IbLm9MPLx47eOZwUvsT7H3yw0aqnNifR2ZEm1WuedS1osZI2eABG2VrC6tJUhwJzZcpABw6Y+w5bJCoESwYhUUqWamYppzvm6OqS2thprW/uDdbXRruT6Wgah+NbTx588PSxQWmf/9iXQznpdStIfXuuORHc3Om7YhS8297tnrrn1rTefPm51w7uP9jpzJPC5aVFldhXnnvVDaeWnbVmcV+z2x309gauKCej4bSo2ou5NqbcGyIAKdRamSQpywmRMolRWuGN8vUMio+IUFXeVUGYtTVKawERFu0qh4qYo3feh6BrCWlEjdFxnlqbJ5FBiFCh1mQSZUmHIAJhWoTNrd1Rv3fo8NKVxflxV1cjz84tLTYG23Fnu5eYQAqD985XwUNRmFqtsXokPXTiIEdRIdx9+/2tWjPLjFUpkkVrhUic1NpZxa6MroXJ1SJse6qhyggTC69el/tuVRqxCDIookK41neC0LZiKLSsrDR0KonF1iiJa1ev+1GxNxlek6sn7rvzXQ/f3h1lF/720+XED0eKedQ4Oq9SW3jpDcvRK+Wb3zWam1/uLCZPPvbc6pFjK1k9TWyn2dBWj7xQkhqjAHWM0tvuZ5lxPjCqLM+qoiqmldY6ryVJLQckIJXmJk0SAEQihRi8j5GJ0fs4Q0kprZRRSDNkBuuqckrTLDlVlk5BzJq5NojIxqpGo1ZWzmjIUsPIyhApBRpqxk6Kautaf/PsZXXb4fd+w9u/8DeP7W4Np4eiNQlh5Bj7w6FRntn5ypUBmqaTZ2a5Y5tEmW6uLO6ba84l2mRZpm2utBEgFmDkoELwOol2p/QpcGagzTECnLlaWQ/ByeNP8dmzEyRpL+mFxRi5HKaKKCSal1o1g6FDVd7S3brp7e6FgOuvbdXrjWP33/vB9935q5cmgzNfHu/1pVLdfHDr/uXO6px/Sna70ye/+OIHv/XUsVMHzr268fTjL73j6+asNZpwYWmxKqqk0RjtblXTSVVWeS3Zf3CRASZlVUsTdi6xCpVKa5lJbFl6QkyzRGkVQiQlgCIgpHCGECNClRjSSs2Q6sIAQjHGyEIKtSUAdmUZnDdGJanN8rSWp61mbb5dn2tk9dQmViEBolhDi+2mNUk1rM49c25pcf5Nb7tfgu9uDZAVCxfToppW5bQqSh+jGKXY+7qlZpbONfcv1hv1Wiuxaa3ZSmotm+baptom2hhjTWKNkCag3SoOGJa5Gg1HO1f2JhcunDxY8nR8LOt/6E3x295tvvZ+uHulume1Otwq56TXDP3utQtxvJtBv2PdG2/tHDjaGPZ3yr3Ruc8/GaeT/XX1wQ8/YuaOuvGoGBbXzlzb3Ctvue3k/GIrRvnMJy93ty4niT1937Hd7tb21k5Rlt5xluQrBxZtpivnptNpkqmFfe20kQrweDDa3dwb9seBEbUmpQUghAAIMQbvZzhm9s4xs4CQhhnIQVtNCDHGGaAJAEkEmIVFjFFaE0cOPlitGvU8MZaElKAlIqDgHYjEEHd3B5vdQab1gf1z1mYQodsdL+9fyltNULaaTlxRTAe9opgihqkLLjAApyp0NLeazczUU6XqicnyWpLkxibaGKWUIpq1D7GgQbow4WWU1FduMi63Nq688sTxW0ZpUvnBxuDM02c/9eeXX3jiyqtPb1x4anT9Fd5bs8Mrmd/shAu14rV53c/81RptvekNBx945PjOsLe93n3h459RwG9ZzU5+09sQKDoqhv3nHz9HZO556LTWipk+/kdPDve6NqFbHzha+erKlc3RsHTBHzi02mjmnpkRdKpMqqqy3FnfGe6NhsNJ5aK22qTWpoZoltyIIYhzHgmRIEaOMSKJMqj0LEMuLMyRY4yzxgqNhJFZnDChTS1qlaRJvV4XAKOMBlIIBpAZfBSKQQkNtrs438EVNd9M5+frbqKGw/H+owfTdqu3023UqRj2JpNxajg6JBHwHoEXcmqlaNCkWNZTmxqy1s7qJzMUqCAK8+xklFEyH8bFmMpJf2d3eG1tvg15Dcb97cc/+heD3aGZX828jPrruXgMZdMyWcXeZUbqtsra9aXjB1fmbrG5e/PbjpXd8aN//eTffOrx297xNbecPvaDb933E396OO6tkc53rpy9dP7g0tLC/GLdTWVrlz/x50+94V13njx53BX84pPXVK331redTpMMxE+nfjKa1OfmNNjuZg+I6q1aY66e1vIQuSgqAeAYZ10JSKytSTKNACFEQNRWaUPMM7TaTUz/jV4v1MooFPAxBhdNYlv1er3VqDfrAKSJCIEoTdM0IORpM0109C63Fjx2h9NBz7VarUrr+aVOlmRR0p2Ni2pfprWP1SREYk1FIVphq0EQmQmtpkamDXGiUREQIt3Eqd9oJBAhkN4ktPy0OxoYN1S9nVG3e+TUYZyUZz/5V6E/mlts3fq1D8010q1Xi7ToV1V55cLu5tpku1usD6aeGcloe16bp7/pm2//0Ld90zd8x9sf++JLbmP0qz/3W//5f/70gUy99R+847O/8GsEHEKxsb6NsV1rZUpzEFnfHPX2xsixnJYbW7uPvPeWdmPOBbe5tXXl/LXD9xw8ePxQd6fbP7umDbTma53lBQG1dX2n3x1Yq0PgykVBUkbljVQpHHQHrvJJZpLMkqLgOIRAKITqJvpbRFjPitqzPjVtEm0SRC0RlSKjjVFaOAbHkVRR+BAgeiHQbjw99+plNwaqz60sL63ML0yH/d1LF1WibNP2X94LVYWRpJZ6L4mCmoJ2RljFzNaSpG7DRCskDjf6Am5gpHnWlRG8b8Tp3rCfymR9e7S1PVzs2DTsbT724uW19UHQj7zvfh5v/9rPfcSVhVXghZWlaZxhe4EZJi5Wg0Hwu//lP1/6gz986Q8/9l/+z5/5ln/0Xf9peO3SU5/78v1ve/jhI/nzK0uTjfPeex2rajwqJhGAtMW8Ve/tFZvXrl67Pl04MH/88D4WGY2Hn//scwfvueWNb7hTgbx87mJ3MJhfqqednEldv7KzfmkdhPNGpoxR1iBS1sjzet7f65VTh4RZPa01alVVBR+8iwSiLd2EuYKwELOEEJVSeT3P8zRNUgTiCCCEoFmw9FGAvGdf8HgUdnbGJHq+Wbcgiwfmb3/LPVhrPf/42c1XrhD37nv3aVOjc69uDPYmNfLDSakTsRahimSxVlvQARNfJSbDaoQScdblyHwD08uRY6gqJ66woT8d7palq5lJM3Xrzz370mtbY8xO3H26BfAHP/dLO3v9URlUYidAe5VUjDqr79u3fNftR9/6wfcuPvydAOR9eX3twnu+5gcPrp449MAdJk0++gefGvX3lBveef9RCJOqLOYzSRSXk3IynBqN+1cbxXTywqtXpkxHju8PrpyM+k899tTB20+/5c0PZTZb6+2++JVXbCc7cvvxeru9s7W3s74jzM3F5sL+pdZ8s9aq15p5mqXltCxGJQDmzWxuoY2Ek+GknLjgIwOgUqT1DEkOANomliuHiEbrJE20tURKK6WQmNkHGU8qXYXt3cH25iBrNerzHWQ96pUxyuHDnSP7ljaudT//yS+QuG/50ffdcfLEH3zijyZjV2JIgoJcT6toEnVo3poYDGAjtXZcqAiEBmMAXwIQKD3D8EYfg/dSTGE6jj6Mu5M4KXPjdi9vbW1PHRndai233G//4m8OithJ1ENvPPja5rBtLYMw1ZdXDqRzx2OyuHjE/Ncfvm2Nv+HH3vINMfrpcPtHfuhXv/P/fOe/+2dnTS196rkXL21ceuvDdz/3abO95bc29h5+230E0XmO3rlqirUMTIZKTYd7u1uKfagv7TtyYNGquNXb/OzHv9RcnHvgrfdmSp195fLGlU1l1Mq+1fZ8CwRGvbHEiESurMaDUVV5bVW9kXOIW9e3xqNSKUrzLKtlShuJPGu/AAAyWmmlYoi+8q5yVVGW03IymY6nRX8w6g1Ho1FxfW1v6/pwOChMVrvv9uN33XlrFbONq6PVdifXcOstnSh2WnkUVuHyhWfXOHpLkmQIBIqlk6GrpJ5naSo0HieNDlYRCgeIEIPEUnwF0UuouJpyqKAqwmAb3MAmyG6Pg9/dHfddzPPkSKv65J9+duiINR2/7cifP3bthde6e7sFqfqpe+89cN+b3/rB983PL7z8mbObr375gbnkuQuPO+9F+MwLf/dnn+hHN169d7U5n3zuTz85nvbufeg4x7iz008zbRPFCKVj0DarN5EwTsdrV9bG46ltLezbv5Rrmk7HTzz2Umdu6aG3P9JpdF49f+m15y4pYw+e2D+33BGR/m5v3J/4yguzK6sYWBuT5QlG2V7bHuyNgMWmSb1Z00bP2kRDCDFGQCGWWUswBs/ec4jiZy1aCIAYQwgcs4a99b5jX/OBR97y0K2dml1omCO37SuDfPGxc3u93v66uu/d9y8dX9nqb3zit35ze+CZuZFgrKlBPzZq2LBQbymv0jzTFo1ChCkAKhkOhAO4SnzJ1ZBjiBzGvYHGEDFsbg2U87m15y/uVFKrNXQx3Lhydn2vEiA+cPjg469eLwofI3dLKJtHHv27J56hA//pF39ntZPB0PyTH/qjj/zMfxaJf/HMX8YYTVJ78W8/P95a36Fw6PD+clx84Utfvv+uA4RA4DPDEmMModWuL863pfK9nb3u9h4oZZttkxjgMBkO1i6vJ1Q/dPKWVt7Y7Q/WXt1cPrj/xF0nWp1m8NzbGfjyZg5DKV85ZlAKSaScFMWkNDapNWvNVl0p5SoXfeAYAJgUklLaO4+KrCIgpbRK0gQAEYiIQgiROXBsturtdi1yfOL5i57dA3fecvzQ/LU33vqVj3/xsb/+/CPvf/jONx1463sOfuUzf/nJv92unI8c+46udiGxupEnWS01Nl9KM12q5moduxUtK5lMJSWZijBA3mCgUI48g7V4+dI1S2GuXrt05UIoy06zuTZYnxS9cQjloAKlDZmLlzdGhYuBWWLWfuC1x/8qe99vrv3CT4nAv3vmcfYDZvhvH/n4E2fkN//wX9zy1kfi5I7NVz7iXHHmy8/v++5vA4w7564ceO+dxqg81wxVBErSbGWllRjpdscQLSo0WeaZYwzldLy7tSuOWp3G3Hw71Xa4O67X5w8cOZDlajQc9faGvvQSb8w3iGH2jCVGjsJBbGJJkbXaGOVDiMHPuvgVKpzhPLwLwiCAghCYo4CPMK2C8xwCBxaT52AyF3gyLXeu762f394cVqlR73jwSH21WYwnT335hdsOHTu+emjt1Y3xuCpcJEUq0Uxp3m4sHmzXk/zQyvxyrbWqqjSQQYZRT8qKB2MeDzmG2F2Lo14M6Mfjcryb5qo/GY/dODO6KirvCsA4GE6VSseOh1M3mlRVWcUQS+8c7e9d+3S1+BPbf/6PJsP16WirmKyXZc+5QQjlk09+4gf+06XWiXtadyxjLJl5cumKJgyuyoNPwKXWaEOB6mk9bTTS+WYSHIeoATBrtUDpXndvPOy6sign00lRLa/OHV5cIJHR7tho7aoqMJYVuyoCkIiQVtoabZUiIBQi0NYYa7RRM8jTDPaBNxBQAITAIsxaQCLLrNUlMkeOgiawAKI2hl0gpUmZJEnnWvX5ufZObzodT7oT207ow9/39s89um/9wjp7T8q99uJm5YNRNN80J96wbOsrC+36nNZHFrKVpDFvm828Zq7t6GOrGCtZuyCHj3B3DZoLrLI43A5pXQL297ZV2hxGHfrXtSRa42Cnx2WhE93vjyZVFO9ZondV5UKIwu4sqrq//IvMJQABeAAAiQAsYBhrL/zBv81q6q4f+ydIgIgaXFVsgocGKouq1cjq7SZS3qwltp3qRDuGWmcOOViry8l42De1RKHAtKpqjfrR1VWl6dKFnfHmhDVmWW51VhR74lkb0trYNM0SHZxDFOAARGVRoNyYciAiVemC9zMQ/gyiGWMEAU1akyKtVQQAYABWCmymyxid8wySaowxDqauXq+lihsN99KZjQtXr9515/4jnfrp25bOP/3c7//xX5w8mmqTCACR/uF/eN8gXc70/GqnMx8mcxizaVabkEnqulOXy56XjTgHfImWmrz+KjSPB0zKjbXQWjYq2Vg7X/dxnC9cfPVMO0Vg7I+n7UxvF25cTIAYqlD54EMIHEEEeCiYijAAAgREK8KIQvbtRj+GslBNwuixz6V57nw4tmqHa1+pp7V63hxP1dJy68Dxo7HqL87XAhls5la3/aRyvSmmISV01XQwtERQz/O55QWQOOwNzz9/qSr96smVlZWFfn9STYu8ljVbqXNVdNFVZTEufOWrygmzNjrNrE0S70NkYecBb8zNuDEAIgohaaU0kQIEjhx8RIWUMmmDShcjJyztBaut7Y9KnRRLjTQ1WG+lWCXXN7qT3ma5t9NoxaSBr1zqzq8s7e722zV93zu/6+zVtblkbq7WzKFIJn2bMLgynt+izhyEPF53cHy12DqnMw9x6q88je2jks1tvPBy5+iyCen16+dsLW/MLZ4793ItM+2a2tjYA1+lBJXnwrsQPHMEYUAAtYIyQEolDrHxBzz6DgQCUOQ/l81/oyo+lS7eu/nFP6vX02JqHrl//sozlzuNers11yubp+84UZ9b6Q/d/MqcU7o2v1g5g6OJ0WS0wySpfNkdjvctL1DC5WSyPRn3u8P5pbn6YuPIiQNGoS+nzVpqE0qM6u123aQgFB8C+xhDJMIsT2yaeheZQeEN8eDAwjLrcCRSiKiZBTASEhD4IOyj0TG12hgio8oquigQvNVqMiqGijKr7z5xKHIcTnrnXjvLk9G3fdc7dNLa7HZ/+bEzRObWo4tommljpYA0smNlJe1EPwSMvh/1xS9zWHQ2D4Nduf34tStXDyyFKL64+tT8yr7O0eMXH/9scvju2tKR808/2lloN+bal6+stdJZz4EYEi9eYmRhBFFEqOeUrpCVK0eN/+O14ndv82RYmBAIjZl8bmHfqcnoYlm6hlJ3nWyuZAuf/ezl25aTex68rb833rf/aGrrzrn5A4dBkaAREG0tEWdZvaiccyHNakiM0W1d3/PT0FpcOHH7kUkxGnT3Bjt7o3GF1hqjR8Px3tYestTrVhFSqskoq7Wx1pWumLpas5ZkWVW54AICk1JECgBmgz+0cwEJTJbktVQHLp2LHJk5xECG6mmqjA0REkVCVLnIoNLofSheOnvl2b96Gsh96Bs/hOzOrJ31AbRJ0/37QKxBtTP217a3cFwsJniEe3OmaU7Nxz6QtODil/qvXH/l7C3mzrtf2xmf2p/X0wPnXj5T3++W77j3iaeeb+bNwwf3P/3yiy0NS3P1tUsbkBhG1BCC9yJRERCqxCQN45Sifolf/+9+ceMzH3gWM8YwG3KTmaSmKYtDZaFbQErxAw/uf/K5YVnyG+4/aZtt3vQrq8fBTpP6UgI+cHAhiESfZ1Z0cBGqMstSjNNyRK4oe1vbzYXl1YMrjWYtbo8ef/Z5ZGqutBsda5TeWZ+U0zJLTFazDChIIBQrX7nAnrW1ebOhFE1GRfAhSa0xGgA5RkBUpDQgRBbnmRJIElMEX0ynQWKSZNom1iZViBzAEVgtxuRpkvS6uzXltCI2unNiBaH+t4/+2ed///GFw6s+xNNvf+dOt8fOLytXFL2nnrx6da0PVTHvuh9Mqzvrobkq2ZvfcWj5wOK5F8+d39qNiy9end5+++n6kXvOPP/FxdXtxUOHz545g7o131roX3kpZM0pKinHCzleGoXZ6AWDYBQmxPuMXkzth//Zm167+BsffWm4UE9HZZUqTI0BItQmqyXaoRXev9jY3QUtMt/Kl48eLApXbyad5YVpNcibnSg8HI/JolchiZD5SX+0rTRxqKKm/mAvOqy1m625pjYaRPa6vd3dYWeltXh4QZGZDKc+OKXJ5qbeqhcuTsYlRGYGTUpbTVoT4XRchBDTNFUaZ74W3Gjm01pbw4LOBd8fJ3WbZVolOSg9nVZx7JJcfMRGs1mr54mx9cRqraxKfPDzC0vv+eFvee8thyyVf/urj4bCHX5o+dt/5HuWVHru1WePrxwk8Psa5q23N1/A7evnNq7vdv9Ff1L5gCD2Tz7ytZn67tP1hTc0b+Pe1Uv03F9dO/nme08dP/nM0y/ACiWt9vmXXluqNZM8u3R9b6WT7RR+bW+iUToWx+UsdYvLRr3n0Pyptx2/9trGa8+MvvaWZKGtvnI53VR6axghYi3NW7lJahhyzHOz0/ULncbyyiLmuaqwvbqcWWMbR8Ck7Kp6rW5jiejBubLopalm4cJxLKa1WoaJiZ673X6j1er33aXz102z3j6ynDfqo2E/sK+1cjtIbJ4ykHMuuGC01VZLlCCcEFaFcy4kSWoSNUMAIhESzZKx2miNWvkQK+dV4Fojy7MksAwHm9NpSBq1Wr3W6TSMzTjgoHRxPLm2tYcq/fLHv0LJ+Ft+9scBdAhcVvHg3Y+s5PnuzvbOle5+k8fQbddqc/vLY/uXz8XLv3C1moQwaw8AgN914Q+ecK1nR+9cSN53qja/kJz94peKwyu33nX7F774ZOvIEVOfv7B+uWHcfMKbO/0yYKoxRbk6CCJCiA1jH771uD6+sL3jdkfqzXcdPHlbaxDCpWqNS7Vv1VbDUcGq0ewEdtZMNHDNGGNMfaExmVTN+blaraFNM2nOo3AwuTJ+WkydVIomadaMKKPJuKyKRrNhtSqKWFXBZNZXhY9x5dCh5oHFufm6sAvOGa3JatJaUEVRIURArYwVgRgiIAIq7wMAaqNnXY0AaAwBgDCEELTSyiQGCAWRGft7A5Ubk5Ktaco0JTgqCiFTzwU8SUaHV+bvPH5w5Pjjv/FpP7jmfMht7eS3vO/Cpy7VpH7+0sbFx5/o1Cno4tDRo5nw9PkXf/03v/TJy8PAorS+OafnRrd434ePbsZP7Lk3LKTf+abFjW5/9PTzDz5015/+7csL+xamgUdFaABPy1IJL9q41wuBRSElWh8/uBoXcm1oYyc+cvrNx28/EQZ999jfvv3AqVGm9pzrjnb6aHd2p612pwguUYIg9WZdTAoqt2lbmWZeb7FOSBMEIeUY1cTFZq0xrvYiSwixnipNflJA9NloUHTqGRprCIwOMh5NhpPgpkUREntjDA8zoFLaJj7Msh2ExDRrWgFEAhEOPsYYlaIbswgRYJb3jjO0slagoPLgKjf1sYpV3up49KNxAYCoCKNOs4YxqSYaV366ty6Vv7BX3rpS/z+/5Vsee3jvL//tb1m3c8fDc29730P1fJ+J3ad++ud/6cm9XRcjK2X0yqmF4w+kDy/y/m755fP854/ujYtCQKLAsz1fvDj+/ncffvmF4eTS5M7jB195+flae9/Fvb2RQhJpgxuMY8+DJqppc6hh2mlZb8bLm/HDH/z+1miSr0U1vzp/8K1OeKKroS3PVY3a0Klqi1yfTGI011KjLCB7QmWTDoKyaQbWVkSZhikQR9SJY1dolZSsLJJIxdNKsL67W45deXzxpGfcWd/b3NgGGxU1K0fWNm1iSUVrM0SMDKSMMYhERMjiJYoBBEKFMIM/zcpjMUYyZnYqNSKW04oRTaqTemoxLYIbTIaj8bSzf7ndmhc1MJSgovHEaR3OrvXm2vaVtUmSGjZzXWlslsGwuMoNr18wGXz/9/4ToxLe/eLPfN8vv9CtqhDJyE/9ybd+6O4fzHROqAiQUH8Dwn+I1foLv/Z13/FbPhjvp1vd6q8f3/je73rX7/3OYw88cDcquzsaVKEsS7Wsyt2RA4aIOG8wppgCWM3LjdZ773x36+VXO7fdbpur8nzANx3wV6/a9Wv54aPFcC3I2mqZr3cpT/PIY0yygAmJQkAg1lY5UFppIAJh1EoZyhKSkU8QxhyUwuAlMXbqYDIZnbr/tkY937g+6O9O83p937FVEdnb7aVpkmgknCqTaIWRwWjDiVIIwYUY2RhSRpEiDtE7L8JaEyGxgA8RRTgGLcKR2Uc2iU3STMQhcFmFUW88rsqOArAIgo16Xs9psd7sJJmL4d7Dre4//nC7ndcxfvRL54/um+/vjvP9J7/pw29OdQOGn/ueD/7HEZPn+N4fOPavfvw3jEo0oVYpUgJCEllCJSEsHv/GJx59/499w4cfX3OrqVVTv3310n33Ht5a3zpxePG1py6VWZvH65uuTICNYNOQB6wqrq3ou+66x9PhxWp34cFb9aVIjYS+Y4V/bUP98CF6RsnW3uL+Y1cmNlCmi4s+usSk1phUdIwoxD5WYJNqhtMmcHHWIS0aIylfuVKnGVCVKrO30dvsVq39+5p5fvni9Qsvb9r6/MMP35tYvLq20+0Wh1sdMhjFICVkkBRxDIIRlWEQUGQyY6ziKCHEEKJWNzCcs2EfsxGJBABK4SwsLIuqLCpEIQI3cd29vTKKUno6HXV7w9Fost0d7AyKZ88MfvN/Pr1+4fJt+9Kp+I0zZy6u7XYa2Ru+/b2HF+rjrS/8xId+vh+Eo//PH/nQv/yxX1dkFSoFgjECIyFpbXRS0+mCNgss9l//1396IMvm0s7JfYsXXtk9duv+fXbY602yRoPHvel4Oqp8TWKvCs4zKlyo2UP1vN0+uChqDhLNhb5zQd2C+Neb+mcP4Z9eTu46UnvwYD4cLbdX6wkmmdJatMGMtNUWKKHIPoQpS0QqWWb9rCBRixMuox/blPJEDOJ0Z9AbFM2FxqGjh3bWNl96/LV+v7jnrfftW+yMCj730lqjMdeZ69i0ZpJ6rdGwiVGKiFDhDbEzhrRWAuKDE2GlFSpUxiilCFFrjaSAkABFW20SqwhmAB0BsnlD5xlHMEp3Gq1JFS++ura+PuoXYWGuPnbJ9kuv7Lx0RWuTkCydWjq8L90Z7bXzoXHdn/4H/+F6FXOI//1X33znHT/CwYXJ+qWX/3L4yufHO6PoQ3Cumk6KK2vVhS/z6DKUO+nc4Z/55z+w5oSXb9t35NbB1bVT99wavF5eXqRx1zs/rsKVSdQkWosP0knwoa858ZnPPPue++9Nl07RtS062cLuDr09whcvqO88BXtbitLayuoKFUm+aOfmMM/Ei0KFDhJKKAQFMVZTDiGEWIYogXUMEt2oKjyIMRS9H252+72yvW/+5K0n/GR87sULIvTw1z18x5ElTfoT/+uxzYsbzXbWqOVEVmu7sNBpt1vGaqO1ToywKBRtKMY4K0goRTazpE1V+ap0szYWUqS1IaUtaRNnQw00KaMRda3WqHXmMCZFMckJD6ws7Tt+8NCx/W+7+/jRudp3vmP5+Lve2Tp6cm9cDlxoznXqOU57r55ewrXHPvFsr5r68KNvbRx+4J8rFCm7l155diU7bGpgaHj9g49cesM9T91/19UPvWf3x//15E/+R9I5AnF8/K1vWGktXh+Vx9/y9u64mpbm1LF9snMhjSGEWEXpe55EYeC6kgdWk5ee3/uhb/zu8ePn9aRQX/smOL+GSYr7G7hVoU6osapUPWk2a0mWe5fVGw0VGiZEDpUHERsw9SG6qhhXnoLz3nlXOR+G04pDRcJ+0C2HfdFUW2wuLcx1N9af/dKzm5u7kNsD+xYI8fNfOXf+qccGo+Gxk4dsmnT7kxBckmCSgFISIbhiGqpCICSpQcLg/Sx+yLOkVs+E2YfZUF4gpbQ2mhSGCOyDJ1DRuhAIKU1TZDW81t9odVdOLu5rp0Ux/uLHn/p8eP5n/p8PTsoqy9Wgiy9e6TWaNFq/ftfyCcaRiXtPff6MF2kgvOvf/JjzwLuvibN33vN+pgSd0MsfPvob89D+rpPpD4Ags8QrXff4l2O87OZW/sH3fuvnv/SVjZceu/dtD185V1Z5edeqv/waOxYvYBACS+mhRXzigfr/+vLct4ayfaCtcsAu4YFl2N6Rl1J4cFVe28IjR9FPdbds5HSsWbt2YTpXa4z8pPJKURH7ezjfCS6COKqmI3G5JeTQd4w8JS5jsVUUvUrAm6yRmMnOzl6/YJT5I/sO3357Na6uY/8rn/6iSuzX/8O/v9is98bF+tVr7aZ10Q8Ho6qYhqoSjixiEpumiat8QPIuEpGx1lgrUabjcjYBShEJiw6Vd0FCZAQApFCxEqe17iy0J71i79JoaznM1eJ8K0/ml6994XO/8vunP/j+Q3NLeTq3z1IYDlwxGi817aC/27viLu94BnzPwTzrvNEML/63P3n66x55x9zymGhk9TW65++JvQXBgj8Hxcjd+02fg/rPxtYffey/UotPn94uu3O9i8/d+673vnz2AqWbSxjmQGZDrAlxwtJkedNJ9alPDP/+378lrK2ltx5Xd9wCr5zDt9wiZQDqYnoIrBHwyEi1lrVjrSe3pN1LVT3JIRGJfuSqWjWJIY1zonw19YwQFXJ0sSI/FNebTMdjbzxCbrjs9fb2egXHw7evUn3f2edeLHd3j9xx6zu/+b2jiIcWapPCffwv/m402F09fPt4POz3BzGU9foMnZ9YazUpa3UwOngBpBAEIWZ5jYjKosIb48dZcwStVW6yvJa7EMtJpdnMLaf79y3PLaxceOX6q09fOnn3LfccXT35bUuP3X305EJrVPHpo3Mb/en63mD9+qjRqA40F+N07/d++StQcWT5vp99h4A+f/HJ7/v2b/JC//Sf/tx31M6d/vaB/OyOPutG47AZ5SVQv04COrLJ5o4cH1x4YrGh56YX7vnAO4qJvr6+8aaHjq2/FDYjGEQE0QQgaBRMRbdPLze33fKx44oiTgTfelr+8gn8pjfLay/I5Sfh9q+FjZepc0T6QSd5I2102ovrW+NhtJaCSbLKWjfYXJ5rjoZD01FCyV41rKG3KvRGO3HSLZ2UrmjVk/7Vnf7ecBL5yD1HO8srf/zbnxzsFmLT95y+pTcqPv/U5Y2zZ6UcXT1/+YEPvb2z3LyydX087i8sN5qdHBmMzoup9yxW67SRAGMMPB2Xzrl6PUvzNPjAcTZFCDVpbRLDhCGE6XhSFWXhfKeMPoRcx86c2d1xF89urc4vNFK+8vLZLVs/8uDJpXoSI22v8aWPf/TDP/f+3NTpysb568MHFptzuZm/50ctpRlXSQqhGPzwt6zI46/+5Ldv/OG4mtV2CCABt/nUBThifbX27A+9e+XIUucn//Sud+9NenrzqQv1fbd0lsYfueD3K9glaCsaAxLifKoGlJ7qzB+uMN0B/aHb4NUXITkOb7uPH/0s3f9WGV6B68/h3C18fQq1hNKGkTKBsDg/La6fB4qQoPfeoOr3+7U0L4yziQNDvWmlua+46o5GVRlq9fru2rXBzqBkaR6cby0uvvL8U1vXtkze+MB3fW0zS7ZG5VN/+tGV5fmv/bZ33vnWe1bnWnvj3t7mel7DznKmSQUv3nsRkSgVxyRBhSQQI4foYoxmBvbj4GfjJDQhMkvwwXlvrGnPtwvH2xu9zc2dejs/cHjh8Knmta3wl3/2aCwqNx184Ae+5c6V9s7EPbFdrD35QjlePz1/lCV86W+vxAiL9eTv/dDXRWhEPxhNjsxXkYtBrVH/yb9Y+1QZWPjGBC/ASMnBN931pvn2G07m/+gH78bTPyiRYFLA5uTsxek7vuf916//j/lCXmA0RLek+GyFRuHB0/mwn7yxyjoHjyhh2Niie26D/jqsIC7Pye4Z2HcErl8C43BJwQtdTDJdbzQmPut16vV9a+tndSPvLBAnajyFOPZJEssqZjWm4EaTcYx+7G0IPN3a294ZSVCmlaUNDm7w4ksbLsq+u48sNWtTV5y9cFZLmD90cGmpM/XFYNJ78aXnBuu77dPzNlGDUVGMnIWEA6AoUqoaVySigDg4ZnGVM9YIvz4fFvWN8SkgJkmSLLHsjefRtCw9iEo7zVYtSUVGVxqVXVj44Hu+9lQ7tygcQ3NBY13ruf3rvUG7/0euYkL8nv/7O2Hf3eNRr+yeyRZunZaT1DZ+5b99/tlCW61BgAVFBEUQIIo8Myh+48jt6t2/KtNueOb3dfcqpreZxY3V5fr601e3xnHEcMRgUdfNTM/nyW5Re9ORfa0iVdfPqPd+G6pSMsCyDlfX8ZZT8uiTIIt4+iH+/TPwwCE82YIvbis1SlO9v5m5aRJby/0wunZ91D66ms7Vx9MhG6UyHncLJRwZutPgyqirYmdzwwd20pBx0Y75cDR0TCZP5o+vXuru7uzumsBHHrxPDLxw7trexuU0U6PNvrE6a6SCqt8bKbEI0RXBaq1BexfZs5oN5rZKAFxVISIRwqxShMKKFAI5H0duohKVJIZMzQYqRuGlVy8cPjRXS9O7Hz55fZcffe7s+nKHvU9q2VuOL/tvf+jLv/nyr/2HX3n3Stmo1W5rJyt3vWs8Gr124aXTh29P62rj/HPdM8MLdODw4V6VN3/8l37+6/e/gUyCIhKmULrIxou4554tf+8XGx/6Gn3bB/1nHs8PTJL63NwTOy+WsWC4o0bP5VbtwPK33FI9X3G50FohNXcH7J6H++dhylCbk+jk8hDu/Rr+7a/g55E+fEf85fPypkSWjT9fDAZDXtB5K8sh7V/vzs11tjY3F1TNLiz0R9OMgES7YqyQywp29kJSTUqBAGZnOGjP6aKS4XisU9M+3D58aO6pZ56d7rive9dblw+s9LojECGdJEp1Ok0Xy7w2V1boSrCaFCELTae+lqJRFGg2NVaMUsyeAytSMNtAAkJIFAMLCCJ4F8qpZ8Zalmepia7srg/PnttgVZtrtgKONl988pkvPNr3cGR1ySZ6qWPCeHfjubXPPlMcX2n+03/1Dc758e72vuVToHPUSlHt2rWL//f/9+E/+IOf/8Tv/M472wd82EMeEXhFGm2qrIEnn43/7Cdqxw6qB75Juvi5T73wzre/mcPe577Y9wJNgnpNCeq73nKcdlaTlXsOLK5EF9E6vOMkTKbSe4lNGn09XD/jzm/x1z0Y98rw/1zgdy3GV/YYduSg9ML16xdfDNyvNXilrUZ71zNj9rqDnb0BWOz3J9VkQoKDQTHqDhSGXn9QiWzsbFfFUAxXXtauToru9Og9i8dXl66fubh+5uqoDLlRiqRyrphWo8Ib21g9cDjRzeFepSRNbS1NG1m9kWQ5GotKZbU0Sa02eoYiYJbIwiACEiPfmOhESCYl0moydaP+FJWu5TbZP99cmN/r9je291aXOnccnD99+J2RrYLEB18wta0JZa2aFuvb/L4PnWyeepvb2xidObPynlNRogK9um/56775WOfISVs/qBGl2vEvPOo+9Zf2u/6lQE5HDlcn3urrSe2Pf0P2Kn5ta+eP/+bgA2m+eE9x5Tc/MYylwGGDUFO8g/e9/40v/O3VY/c85NZeppXjshT4iS/jW74GF05Wj34sefAbXl47gB/71QOtdyZrQ9x7jP/V293b38Llc87sLTww//in+v7FK6vzU7Tzi4uTzcF1mGtNC+f3fFKr9QsXg0gRMUxDqArv+9u7470BaDrcaPbHYWunLKfQbu/XotM8lVwuXNo4enhluzupXFnvzBljEkvMbjiYlKOYJ3VrUmuSJCNvS1e6EAIigVJKocQYg5tNIaUZVhxQK6VeH3aaJkYAuv2iuz1sL3fac42sRqGqti/vOh87822w0BsP97Yn8wcOP3ykZnXipnUOLgZ8y/f/OGree/Svlu5+L3NEkcRoM9+0iw8bkxsUUjWwB/StC3DbN4MPuLcdvv0j+pd/mS4qUA0Zjvwf/trfTdW3/psfEUrH//Pje8wIMK/xyaH57u+589xj8aE3vk01kt3p8hQvNPe9Uw1fhBc+jvd9Wzz8yJ/83n/+xm9/E739H8frn5f5d8Gn3+/+y5uvf/TvDVYfXvzG3LWnt55a/uTn1oaDcauFrWVrdVkM1ymxk72icO1UqcoHjMis97pbAXjQ643641rHTvpdH8HU261aVgyTL3/hyaW5ltk/l+b02pXNoqiOHF7QXE0LX89z56rudo/IglD0Mg1Oq9n4lBic9z4apYgA+KszAGfZDlJKz9aMRC8C2hClqWk2sTcodzd6qHS9mXZajWLqtq8NikqbvCRK5hdXllotQ3oYI3iNytrFY7X6XFl0q7RlGo1QDYASTlKBXEgE01BcU2qC2AF28Pgz/D8/jdsR86+BxqrYqfz6R935T/7OyHzf7/2SDwM/efG3Pt5VBIcUOkvtTr2xcvrh2+6/drGbtev3vfHU51/GDzzzUfr7Pw5nP/bkz/179T0/8Lbv/fDv//xPzn3uTJyGe+nnWqfeBb/76ekPff0fXL1ofnf1oXvrrSO3Hzt18LlHX7w2KOeHk85KE/V4snWttv9wbzKdsFaKQapQ7GmYTMYbg96IOaQtc/7lPWXc6p2r973pzY9/9qmtc9fufuv9J+860GjOP/n8pe2r11s1aKboKpYsB9Ta1ACdooiAsQoFe61IawDRwsAAEiUGVkhG0WwONwIikp51QzJzdIG0ylKrjWWQyZS7WyMQTGvJ0vLcPJIo3Ww26rV6CbZptbBMi2hrrZDNHX7vB4qyqvq7nbvf7YpNbfcZm4QYAcEgAI/QHBMu5Oqn4RqpN9wBv5LJ8XfLXM7/cy+O/sy7Z9aT8L2//V8ZEje5svWbv7Wh9Hyijqr4RKRvXs7vuPNdj7147S0P3DHa3Xt+WB5500Nf+lT3zc98vHbP2x/47uEH/uGPbA5G28XYs58ti9BP/vVD7/rMv/++d/6DFv/r33tpe9TY9/K5O287eWQpfXZjMtimth/NLSvTyPrbu6rerDiflqWw1y5GUw52h66qbAc2LoyQdVaDQ8c7t+xf+Ku13XLktjb9g7W5zNq8nqKU3e1taGaRcWQSTZSlOjKpWaobhSJwjEoZrWZDGxkEmaJSlFiDiBzibBi2BhCliBRGhuBj5YJJdLuVgXK9vtvdGbax2axnVQjDwXS9F1h7XasfO5T5RHIXm6vLZN55+MTK+e3dg60l1VzgYsI6iQBRhCMbFnTrIBfJHsDkAHZK/sQu/NK3w58zP9Hlcq3q/13xyNsO/aPvB+9d7+lLv/xbOuGhpW/ah79xFRzAAyca9ZZptRdrjYY2xakB7qy9rG958965T7lXf4FO8e8+tPi2TwJTEI4iQQADw2M+vPPXPnP/kYU3v+H4Y4+f3+zZjfXdUwc6wnEkdtoLE8I8Wt1qQFFUKFWI4EYMZTmZjPrTtCO9dRedZJkFrObm5vtFAQpNrRmCvrgxOrBq2u3WRq2JqANoV1U4HOS1VJSAiNaaiAlZWAMDApMiBJIQmUE0z6qmzK8PgmUNRLMZaBi5LF3lXVbP6o283VYRZDAsuzvgAtdqJq8nowlOpy7TUTGHKkz61dyR1VPf+MYWDF+4unfqzbew8rpxLCJO2AXnGwKBQzaVbPusKs7R/J006MMXN/GzYxjFOHrFz5vy4fc0fuDrIPqw96Uv/Is/XD65GHP+noflpz9aDT3XtNz1vkf2+pMH7jwdgHeH6aFD82qAZz/92SmqPBw1uj2+9EkOPUJn7CrSwVB9Zbb4ThDPbBZbw3MLWW13Otwq8cqkOrFQ7/tqVOlao76xdn2luVIMukl7kSP4cpLO4fBcn4ybblfjXoWEaZYcuP3gxtrepfN788uLeKjW6DSunN9KkjxPs6zZUcQxRB88uABYAYvWibZWImhjCJBZtFaIFKMECBT9rMuRA8cQgQEJtVaacLaSigVYGSTUMXLpPGlqNq1onEzCeDjK0/bifGffcjYsJURVjsqrPdfrlu/4+juWGulnHp3ML+8XZUSbKYBHaIpaD9NXe8XpBMLuZHli9IVd+8LLJk2g3YS9EVr0+5blTfN0K4TxFk0e/+1//Hurrc7q174z0t985Hu6l8toCN/RUPXTf2+6PQ4QlxY6YMzTO/23rB64fvDI7/zpk9+ha0e3Nlb/f+87e8tv+H/5rc98Ynvldpn/T49j3Bw++rl//auPPjUoitHoYm/ookuUKoJsV1W91gyJ2hxxmqb93jhAokFNRgNNmpRz/RFVbtQLIUZk9ISH7zn10qNnrM2S1fkHvub+6YSf/+KZc2QPH1tCnYg4H6JzXsS7KaNIrdEg5FB5AWW0JlIRSEL0lY8+EIpCZGFXOmFRShMREOrZ5C0UMEYba3zkEHkyLrRVyqg80VrrSRl39oajgjsL80oZBNnYclcujRdvWT213MyJSpfWOnOkdEkqCAByhZCZdBN8d2+8MpSN62ppF9qTraQagcxH1XadzO1XjQOxvPrk3KXRY3+1scbZ+3703fpg7cwPf/mTAx9ELND/573tAFnSaDasLcphqzm32C2uT4dvet97f/e3P/E33Sf/xf4W3f3zihL9i08+8guV+AvCixyW0m+47Rfe8+G1f/dr3/Bnf+FZhMWJB2SNuZtUlhWYMVA7ifUQe5NysZyM5ldy3+0plLKQEGZjl0goGa1dV1qBTSVfSLNmv9/1bsLgu/2Br1ySY2ZThCS4QBAixxhcWYRq6kMAbRJjE2EWHwgRQRQBA0YfJDKhmnEghnhjeyQLcJQYGESMoSxLFOmi9N55IqnVTJYrET8aT5iDD1UQFxFquVUC00qanUa7llqkBLBiQZGJYAQ6mJkA5lOXx2eG/kKxd2V8ZstvbZQvn9MX+ycn591T18/9xbVnX/zKpy+91g3v+fZH7ME7/dlf+aWXKsfRAJzQuP/H/6kfT+tcprXM2txqbLeXPnMtravytz/+P/5gXC798dnXlvbzfzrGfoenG/Gpc9Nv/K7q+sXp5cH2L//Nf3/szHsP7j89v7iv0UltIpSUEac+Fo6LKk6cHu1dsc3VyajyVa9Zx9AfloUIqtlcDCQsu8OXHrt46h0PHH3kDb2N8MVPn+tvjxdOHm6uNlycCnqtgYm999PxaDKaFkU1Go56e4PxaFpMpuWkKCaTyWg0Gg6LohARoxXH6MqKI2ujgDDG6J3XIEyIgSWwIKGxRlsThasQCVUUJkabEFAEpWwipDkh2zxQa3QQDE6dVJ5PHW4YoJ0y1izPNuSg0DhCRqpkZpbLo2F3slfb7c27skmwW15Nu8/uP5l/4lN7c0o9cHL1lrl268iR/sbfPPdfL29EjiJE6t+cSGXhPWZ7LUnrBGK0DoBHW9lC7eALw823tNzLF/7q+NKb3lBB56cGP/5TJ3+foYdmijZ74P+4p/nmB7/m3rmHTt55SI5tbH/scxehmC8HXY4lETGYwmmZTG2zwTZx3asIvLgQLj421AmBVzcmuTLEEAaDyR13veHFq9Ot5/9sMndw/7e+t9HhPMXxXlkOR6ORqMiT3hCjR2Ek0crOtv0hEpKgRALB2V6SGDkSISqlkVBQZsu/AESLMClr1SzIwMhSTApB0FantUwQRxNXDAuda9DRhULFhIWm5XT92ijprLymkiPzaT2FjUHRr1NGKkFxIqUriyAJ0mpuX2bd70+Ho0JVxWas5skdrOH6Zm97mrUPzE12Yzed70l9/dLz2fDpS7vexYiICeJtv/cfuZzEzRf16feJBFIZUiKovu2B7MN/g29cfU4nD5zvnt2+5Y5H9uJP+kqEhStEXxB/Zfpsp/+tP/hj71p/8XdtXDn5UP3Fp7o0LjQhqholiXMVkYlKl8GXxaTV0hwrEUmtKqyaraYBQmVM0pororr4/DVkp9tLJ08tdsu93s5GNe0hTVxZgWMittbibF+u1RKFI0oEQkSERCtWs9WBHDkQoLbIETjybM/UDJQJBKAJFaIwRxe888JitM2tTY01SFXJrojRM0GoivH62ubG1s7S4bn7T7RTgut7ZSuVA22jRcZV2J1OvXe+LNLoVHAY3FKr5ikb6uYA8NJecXlz+uLayLMbToqzr+3qudara+ujcji6+mq3O7kydAMGRer9C6lefj9CqZFAJlLuEmqlTUj0APCPPzT39375rs3t69WkH3/l2xRmCpVGMqRT1E114L47PvIPfuJQb2O9s/B2FZuHD96p/cQgpLbeWrlXLZ4ORS+EUBYOiNCPFFeNhtKJdkJJZow22pikkdY6TaXTz37pNTUtkvbC3V/3wHyurpy9cPX5V6rJIMnZ5oJYKcOMcda7O5mUxbTyZRVjiGE2moORBJFBpCqdDw4AiCBEDj7EIAKgESCGEAOgIgSwRlmrQ4zFcBp9qDXrnXbdplm/KCAI6RjiKG/WTx890coyEnytP718eXj6fYdWaumZbiG+PNg0SH40LtFNE2WqYXVoLr/gaTogLJPKQ1VFVlwF7jShirjb6y/kSXfrtVqzWLHTpwYxAKHgT370R4P3ZbcfYiuMh6HyYBgN5gpz4LUp/8p3tn/mV/yll8//zH/8l8+c/0l9cWiaTh/eh9oCYKz8+Hr/Y38dbn/bcapB75nnsZiKsKbayfd+8IXPf04EopsIpWHcE5keXJnXbipo07oZT0BbLYpq83Vf6mo02njq1UN33bHyhodO7k9fubBx7dHnbN02Ti1Y7YfFIELQmspp8FXQxhhEmOGcQFBiDMIYEVGRihKQJXo21hBpAFZawY1tW0QSI4AoQK2UmY0cCuIqX06q4GIzzxfadYs4HY572wPvIFVpUVQb3d75zd76xV0ScSxFiAZi9FEiI9K1zeuj8chyUZNhTYWVfUsiqsI07+SO4HqQPS/DIkKMu7v9QeUHxbhVc+efHw4jINIH723Uj/4wStg6e9nMHSouvCKqrY1WLCMPzsPlQfx4r3rDt8z/+//6yIlmrd5sZvcdMCeOUpIiEbgi/Nkfx+err//2B9NhGD6znm2WwyqAKFt70zvffywUFkBFBl+OBKos1bW61YRZXZvctFdbOjE2tTOFA4IC2rTtwROLV86tP/tXnyem1oHO8vJCYtBNqyzX7flaWrcmNToxShMqjMzeeR98lBCij9Eze5AZDpOEhWMkIELSWiOiBmGarfAWIZYYvQjYRCdpEgWraTlRSlvdqicMNc8Yy7i1dS1M/Yljh4+vthdrjcde2L20NVhuJIcbyWvjycZut7HSFtBTL4Px+NKLrywdOnTHrXPr5+q9fohEJSphrisVrebAtUy2hwPDpVT+f10JIijMP/vRP4nRP/eF37v18Btj7AU/Vo6K7h7lrZfG9mWgf3RAv2l/QloREQCCQIzMha/++KLaDWIy/MA3pet++upAvvDqQ777dH93tyoZ1IkPfcfBZhbHM4hLREKpxrW60VqhSWySzO3ToyIqY9kzkq3N1SqXmhrEcjrojTY2B8GHxr6Fk7cfa5hkOJ4So1bauTCdhmpSGgNiNTCHINFHM5svqjQzBxAFSiGYxIKARIkoCgkJ4caiTcQbiz0FlNJJmmRpahMNHEaD4c52VwhXluYPH1hONe5d3/aT4aGVzr5mPTNqdzjuXl3b2+gRhFyhjn5nc7eqKkKVZtn2qFzf6O9ud5sWbzlxCCl13nbmG+1OFpTamnDdYDF2xbTKDHzxiSKgVqj+1U+dIDruyu4n//zF2upRRSF0x37YLa+8snN96y4Y394ffWyrKoOEwN6FSeGe/8vx8LFi7yeGdOoQfd8t6ptXYA3CH3Xjx691mo32Tu+vty5GAbRf/y9/eOW1qY7T68BBYoVhJ8s4MdhZaHuaSxs126wtrNbrrTytp4hKJ6Z5aD8Zv3vuhd0L54OfLhyYu+v+Y3OJmfa6e1fGYYrsdFmgKzl4FCRlNGotSKS1EAnQrME3BrlRCAJUszFPQjd2xwrr2Uh+ni2yU6S1QcJZ+B5ilSSajA4ueOeUMDunFK3s3z/sjS/G7XaztX518/Tt+/pFtb4z2ldLRKKKMhpNh7u7yb75lf1LVw4tvvTcWZvR/iOtrTuOdq8IVQoioEAUMamFyFpLd296fShKqxbh3//e3yKUX/yVf/+j3//d42HXjxVgrXj1M9Q5pPrXL6QH09j57V/7yv8o8ulgdd+bHhw+NfnD715Y/5145N+2eBTC3xT8xBh3vUChtJJN7l/5wmtlhZLe/dM/eLhpn79Wst8TYIDAfjK3mpndwmrT7LSbc/OZBTbYOTiB7TKp1bxPwrjnJUbEWquWt/XK0YZR4keTtXOb1RiErEqbzKBsAJVkeZrkOrgA6CWyNVohAgtKINKCCokCS4yRZmsSRDgyEmoEQASFFFkkcoQAAj5GIanVc2Vt5UKv1y9d0Ww1OnOtNG/2upOta2dP3X5y30LnnW842pv4j33yRaMjHJlbadd43Njb6kvhp4OBbdf3HTn60hdeevGpK3c8eHL12CmDeuvsK2JibtTBJu0Oq+BjKAOUGMSI0H/5jw9Vld3deam12VCdfX4yVDg37cvgmVdjcrn10BsP7qdsPv2VN34HmAQAU22R5gLLgUe4ul6UfzKUM1NlQTuUagQp86W/+PHhXgJttf8//vyHMlb06meDSA9BEFhhXG6mw0GysHqAVdqZm1tYba1vDWq1Uh90Pkp5fcysxCrbqudNfeTkaop87cL1qj+KHgWSfH6utbg8Hk6K1IcQTJYCKcbZ1iOySYYi1WQ6y/QZrVCpUAWIYIyxhkCAWRBIizDJDQ0VvENSSmljjGiUG5uBA0cHkKRJmma13mB8/fy1lLCR5945hbi52y+3t82RxWlZJhqYwvb2bqLs+sX1pfnOwaX27e9448WvnHn8S6/NHVhOGo3W4mIeajUY++kUVSxK30ooR3u9Hzp1ffIt/0Ki+/Vf++N/+o//0aS/5y+t1VYO6dVTJZ8rLo02n/xE3eqT//wD5v6aNk1EcsEHL9Wu2/2d8+MXN90wLM+fSkfaTPuqNo7bG+e2vnTFl7k++dN/eqsIbXnY/tw15j5pS6pSKEcOL57r+nr7MMTpgf1L7fl6VekLfk+hXjy84Nz1UW8CMcTRIBouenM7BY+2Rom29VbDKFo8dKiWp5OJJ1M3KpKxCCKxmiVLmKOardEW0NqmqQ0uBB8VktLa2CSEwJFJRONsgybM2oMJZxP4jY4A3nsRpxVleeqd7/dH7WazlaXtRu49Xr+6WVThlsOrLc37Ds7vXLr2as73nNi/b6427Wpw4MfhysWNe24/8vC9t1aOzn/llfqkuOveU3RkYe3c2cF2typ2a005MG9lXD57aeIY/+W//3CM6Zkzzxxrn5qMR4Nzawv7T+nFppnWYHv5yqUnPtLrr4ew/L1P32rM6faiyw9Mk/vOjnekuLrftt5z5OuGftosPU4mQHt6/ni8/D++exxSoK/71//hkQ5eKGF9Ir73P4QLW9sPvNNo1g4t7F/vULO+WBT9RmNuvpmbo7XzZ/euX9kpBnLkjhMXXjhf9QflxKkYe/Xd+tK+2rHjc/Mt7zkGTmxWVhy9VmjSei3NjHAMPiAwASMgC5skIaLEGonsSyeCOkl0kqBSGOPsvGsQYI6IpEgpohnuAzlqpYKgd8EkKkl0MfWT4biR5Ymx7bn25rXdcXdwYP+iRVlopYcOtM6/cskNehwW8kQ3WvXJYGiVXHr+gkZ76NjKvXced8HsvHb5sS++0qgZjA1Oae5QIw897m1sDKZgk1Pz2bF7vwGYf+2X//pn/q8fm3pqHDwNKuVJEQYub548sXz/v6ALr3Wv/vp0+NFq8r9GXYCzmr7QNIf3ZXeSqn1u69IRvegtli2lm/sml175Z70rhuzi6n//2e/Nd8twZSjPPumj/5IA1GtZMaX5ZnNp4VB9TvIkyWzz+ppZWZ5bWTRvebv6o9/5/N71YQPNwuH9O9GHgoBUr1eynbYX89Kr6bAyaTqeBPaOvSQ2q9Vym+jgSmtsYIccCBHREqHRhr33U0dIaW6zPNfaRB8BwFiDRBqEEfCGV0skAByFAxOiUcpVoSqjVtpq5b0Ez1ZhPcuTJHXTctgbDlo5ktYKUOJwd29rZ07ZdOKZkBeXs3I8fuXZ815lhw91Hn7g6LOZrJ2/6ihfWD202NJ5sXHtucfLETRbzTSH7/rn/7iqio/98Z8/ePcjqtOBSpTFyUtreG6t8w0PN/7VweFHThZf/hiPfm9LoufAs7UBTBV3J9ir7OmsufrGe0/bNBtf7rqRfPL6rz8VEoE7P/ale1jk012YblavfKbHUiKpWirRJ4duOaTTdmNplFio5x2bpZeuTe6+89iRg9kbv14//sknds5djVBRqrN2i4OIsV70YFCN+7tJYhJrcpswGrZOaZNYY5RiEBLWpJRSs111CpFjCFUUBpskaZZZm8y67WaYZUDQCPDVdZCzBbdBgJAUWaMkSUrnq6lXigyqUDpM0k6ztpfa6aDwhR8NJ+1201q0qfFVOer3llaWE5SpjwtLizZJLl3onXvuHKuTd51Yee9b7pm88a7nrvQ2L23o7miwu11Wsnr4QE5UlDwe7Dz/7GBYLfyD73jnoPS2UOtnhk2VL7z9XjVfQ9ByTTZHj38MzRGTXwHlJSpUDd26feGNb7r7bQdPHN2/r2Nr+cajvbVrj+vJxse8QtG/9YX/RhhL1n/8ke6PvF/vXTkjwFrZeiP1sXno1tu1NgvNRFE0Wk7ffuJvP3cmudw/emDunlPH+k4997efnW5ei/1xY2F+/vDBxuJ8Um8XvYlEznJVbxgEAYnWaq2VNXqWRLLGeAkKhZBma2QBSAwQktJGaw2IwXtmNsaiQmbWNFvnyHG2rBYBAVgiR09KUWYNAlTOxxC1ompSFmTq9azVavR2R9PRpJrm2MwXmrXx4YXr5y6EappgrOfJ2pVi3O+3GnZxuRG33dmvnN1d79961y2U6FY9H7fnBq9dwakcPHz0yL7O/1vVl8Xoll3lrWHvfaZ/qqpbt+rWHXp0t93uxm2cBoPj2EAgQAaIFEFeQBFSpCgREkleorwgFCnKA4KXCCmPREpIQgChEFsEk4BtjKeAA91tt3u4Pdyx5qp/OufsvdbKwz7/bXOvdFV1q/6q8++11/St4ft/X/iqJw2eexl94pPPv/7uyfqwu7q3t/c9B++8sbJVe/nHD0qg0c/NXrj8teeXF3b27uK1Vx68fZtvXW9efJauXDn89nz0zF7f+69/9sHrr392N92nsAe++Plf+PWP3ERR+NWvtk/I0kN9+t5vELFzPJ2M6u3t6/t7CLgzaU6Xi6apR83oQy996KtfuXdvzs89Ofqux68UP/aJL3/mCxfvvbc+7/o9HI1rYm2tJ2foXUptbIWBCcDUUgQmQE0gCUWByHsatq8CMhMgh+DZOUlqBux4w5itDgBUBCwvw2YgYMcpJUkp9uQJPZMRGQAkSVGWsqhCGFfF1nR0fnp5ebqs6hIZdrcmd9G98e07VV00zWgyqy6OUruGnb3t0UTuPFgdn6xeef3spe+++fS2f3GvPvtAfXL/vl+cnb/16tnZ8ge+/+nR7MbRG3ese1jXV85T8bEPbBHxrWdGX/6ji1vr8+/6oaeqa2NChnZiJ1S9NNnGH4yrNH/n7mpNzd6+Q/78b/3p8b0/Gfvu2RuPxfLpG+Gpn/nHW4z4G99c3/4fD//+j4b/+acncf0KEwcfrl7b2T448D50sZ+O6sP5Wb3qqnp8fTZ6/rtvfe1P7hyfrLdGizHZ3o1rq+MzF+pmNnXOrS7mqZtPtsvRGEyXvYAJj+oKAFOKYiIx7zvKcFLmSUMxIST2XBQBkUwiMzIzZ2ZySS4zoBqAigKiY+c8EUKMErsOTH3hC+9NLWmSlAykvVz74Lcn47iS5fn6rFhWIxdKd+upW++9+c7l6WJUlntbI+nk8myR5GK6Ve/f2Gp23TLiV79y+5uTcH3H3xzR3rhOtjrtcH//YP/F7z8/PDq+/eYLn3hM0M12m1futU9tFxHpuU9cPbsXDpe2fdoVXefW5xQCTp+CtpPFpY2eAAG5WPz5Zz578u4Xf/ijz42u7lSPv/Tf/suX/va//EeIsIr633/l9Z/72f0zO//G//oCU3TOTSezJz749HRnJ4qtkjZloVS/cyb7TJVzz+yyfvzga19668G33/S+p77furJz5Ymbzzx/8/Dw9PLoxBdWFAy2IPS+CI6CmRGRJcvk1yF4BcsVDgMgQOccGOZF0ZrETB3nSTvM20HdQEhuoIqmCmZExGSCAoAmkiJ4H5gYGcCpxT5erIrJeMS+r8pk2p0vLYXi6mR/Z9avFicPT2Lf+rKc1FVaufl8jUVVTRgYUruen12c3ImXjT9v+luz9tq13f2nnjp4/DEopn/xvz+3f/0JQJovlmcrePc9Of/w9gsH1dUyrG37d//s8ge31wfb1OzusnN2Oe/uni3utBdq3fzs1a9+eW88+u6f+unpx58//eq3ju507bM/8qmPN6L6619fjbH1YfnGN49O7/5hCAV5fuG7PjgZNdVoGrWIETon3jfr6F570O5vVbsFP7ZVVt93/S//cnn/rXfaZV81xVMfuOrQjt95KDFtX5/VI0p9ixhDIEIF86aKTCBKQJI3hJsCu8xG5LxHIESQpKmPmeKcnTMTUWVCl9v/iIgYVUGSWF545tjMUtLYJjAKjARQF6Ft13G5iuqQXC0kBOuUVmcrh+hr9N75skQjaXulfmtWX9m72mPowXOAG1vj5z6wD6Krh4dvfe1LB8W29zerMjSjRtr51nS6//hj52cn5fT6rMKHfXvvrH1i262Cqyr/3S/OyKwvuV0qX7bx9ikGlN1tPb2Mq/lH/86PNY9fhYDzO/N3H07mu4/92N/b6UXnS/iD/3Tn8evxslu+8c3Dtjsugr863d65fi0002a0tRB3fN7NKCj5Se37ebp9fzkfuYZ7lLg9DaelN7Otvdmo5Dtv31+dnE8Ptp588iDGi8O7ZwRYuJKdmCVDRkBwHLvU9wlE66osqlIVQRUNMtIqoghUBMdMqpJiElEEcANhKiIRqoomNSLnPTvOm3QBkYw0KRuCalX4tO5w3jpfjJCscCU5WCwvDk/qnXrclFdm4/Xi9O7b94lDPQVHhQWPzIp+0UK3bv365PTt14jjnYfzu2/84fr89Ef/4d8ysJvP3PSB/CrWwUYVr9r+W+8e/s4adq+P/9oM0PTVFeJR3AWZSNp5fl+jtSdzKMLuD32vOVR0x98+f/jQh+997tq1ctbgu3P57S8tt6rFaNqeHOnhm19BtNFo/KHnnqxGUx/qVR/RFRHc5VoT25hhuybU/uh0eRhXDS6boJOZryf7N29dW88XZw/miG7viWvXr1y5d9i2i74qAyMbMCAhMiKYqKFTMQQMZVkUZepTFEsiHpGJgDMvPKqZJDExNCBEl9fGqorpwGhOhESZuxO850wlnKKqWOU4BBcapDV4tZSkbZM2XLCQ844gxZTaxXx+6grPriAO3boDKJrZ1PvyfN5fnCzh8nRUj69cna0OH37tK29q7G5941to8drBjgcaFRxgVdbbz9yAsrI3zpZ2Sn+64Js1nSbeG1Fd+TbSmamsUqjLan+sntcX6eHtVcuzne8frdCBx7fm+vnX1nR6XrgzSfP7r1+m9Z0ihN3d3YPHr3fAl4tuNtpeG6Ueiopjr+faT4POXPKVnKc2pna5OHV4+djNPaN47/gSKVy5de25DzymCvffPYbI9fbUcSnoDR0YbthmgZxHA0BWNQMEAMeecmsZYB7BlyimMKyUAHNDr2ymkEIkwg33oJhBZrvr204TEJAxqWVHlPp2qaKC5sbVqKmVdNGtzs/nzFqORpOZb1drsx6ZqSh84Enjb8zKuF+jbvfzi5DObFrce/PNs8v29/7o5ZOjww/d3PvIU1eff/HZ0cHjnvtyUn6wwZ1pjJCOFdnRrQpqxjdX6SpjG8EDjHerZHT7rTWz8zdmZeWl5DcP0w7T4SIevnb0xE53pCcP799nWUwqRhgf3LxqXIGiGSTpwQVR6sEaB+u2XXXCFNt+sV5frM7urS4eVoUxtIf3ztoWQ1U+9uz1adW8c+/+yZ2LyWxUVDMuJoghJpQYJQmZEnMoSwRQg5QUDENRgqpmRlUiItAk2SVnFnIEdJj3ZZoBZr1hZgRTFQVANZMosRcCLuoAhl2foBOP4Jz5OlSzJqGsutU6rnpt66YoRw07ujw9apdLDHUzmjBr7Ho1goKZCIREqKqvKBcvfPxjewe7v/kff/fhob363vHLbz8c/fGrz+x94Ud+4pNPfuwlYk9JFquuLqcJ/YM5KPvtgu+u8aAkLcrbZwJiOimLihPg2dpCksN5mtX4+psXlRxfni2XJ7c9rh239XRMnjD4shnFFuaXi+29bfR4MU/pTG9uFxX3i9VKUBEjw6IK8/EVnE13Vsv18mLl/ZafVDev7/Qx3rt9j8EX1SiUU+ebmIDQjDGlru+VQJ33wRERW0x5E6mYgcpQeyAyFNxwM6sKGjjMyzvziDYREgJASkmTELMhqik5LsvShyB9UrLQ+EAc2CFgjN35+fkyttz40dbMjap1250dH62Xy6Iqq/GkKv0qxtX6spdlN6lrX16cr8YVNuOttfEzz310Oi1+7p/+1Guv3f793/vynbfvH3ft6e07f/Frv/M9z3/zE3/zpe1rByzlatVCPRlz1SU9TXxtFL59mp6YhpO1TAoQAAO+cxKbQO+eK1k8W9p7L7/zgWvt3bfetLhsrjTnJ6ez6dixLeZLV4VxWZ4cnS8uV9cmJYzsvYf9ex1d3wllsIvVKvVnXi8mDTp0qV+eHLfop83WtJyMEfno5HK9iFyOq/FWVU2SUopJAZkpeFv3fbuMTeWqqiKEHlDzGl7LlM/MzKY60NgNZM0IeZcNDJTxSIhgllKSKIAAaPk1znsXnJj0fe8CkWNVXnUxrtr1YhlRx7szX3lxsJgvMuP7zv6+C0FEu3blfXWwt1OUo6Ys1ejqTjkrgyWdL/XK9sw5d+Xqk/sHT3/kYy9+7nNfvP3yuw/uHa5W7cvvPTj97FdfeOHJgxs3fDleXZ5Rs+vq5nxu2jWE9MZxPys5Ktw9bfdn5YOz9Pium192KbbS4fzOX+DVg/XiuKyAYeU5lZUvwnS9WLariyc/eHD04PSdV9+6dX06K6Gdycnh8vYKymDSHns6r4u1t9iuu8WahWZYT+rJtBkV5/P2/HyBLgSPzXgaQtGvUuwEGV0gH1xcc2egkNE4ZSaQzFyAIXgmElWJEUydc0RoaggAhA4BB5gjJ91iIkpM7FiTSDIDDAWzg9gn9IBMXYyyXlsXU4x+FJpRTaXvU7+arwysLKpQT4Bd265SNFVD0/WiTeLIUIxKh4Z2Nl9czJfzZW1mZelDEap6+1Of/uQHn7nz2svffvObb5+dLS7nJ6+9ZqfHJ/sHN0ZXrs3nt12zsze78vDkpK6LpirvHLXb47rt5O0jCSanc39497wZycWDy4AXbFf69cX2laqgWDoaN76PbnGxmh+d++dWz3z44Iuf+crnP+e/7wc+vFtjV0tcx4pkMksOwFG5XFoXCyy3kCpSX9bVqpfYdUnQFWWoQijrlEBFnaMkosmI0XtXVmVZOBUVSabJMSBwTiAQwKIgYu4AQcBkaeB4zLTZeSGXKYgqIhIzGKSoSbSogg8MKGYJEJJEFTE0X3IxKnwZFCDGXk1DUbJnJUJ0KSkah4DG1TrSnXtnMV6maMT+4NaVx64TB/f0s/ul45Oj4+CL67euhTAdjcNyyx5/1s2u7N9/797R3QdGGC0dnz3sUUazg/nhXTAZ++rs6HQ12cIkJ5fat1bVOr/sLi9R4yUpzY/ujmfNxcUlWBtCFTyxI/Q4Ho8e3Dl95407H//rT3/wyZvz733iS5/7Rl3S3/ihD9f78XKRAiqZpXXqBNZp0tFI3TR1wIVHDH27tKTOBXauaprgfdulpOpc7v2WGJNDGDdFcEQAfRJQYyZHhICMmOG9TMoECJqEiIYp4IEcGAkMM4VOTkBSTCkJMhdl4T2361VKeYcfsmPHDgyMOOHG97MjABc8IUdJZFrVdagaA64VxuNm1ep8GdcdrCPefrCC2B7shO1RgZ4NtW+7oizGdV3duDWbTB+MH4YQtq7sHj44QkuKfHpyQr6qm9HF/bdGOwfjori4PAFfpj6u1moaV8vewEznq7PoYC66RNVRjYRrdoGYk+qNG3tvvX7n4XsnL//Jn/3wP9j99CeftfnxFz//pcuTBy9937N9f7GKKyJL4hOV0W1FCyKBAztPKYImY3JoEqoyhEINYlIwZUYG7JNJTMBYV8E5ktgzohGZGqARIZiZaub/zWyCYsqEiASmDrJlMsuka5lcPsUkURCwrMuyDCmmrosxCTv2zhEwCpgggDGzqJoAIgMaGImpmZVlyUWJ6JC5YMfeJ8XTRXz3/uWd907OHpyvLs6uPL7/1NNXa5Jr04pOz0Z1OZtOiGhU1gd710rnD49PuagWR0fG3hsePzza3qXJbHp+dKe5chDIn1+eUjlms8vzzhRALdAaZa1yOZl4S+db40DSBeeRebFYUWE3nn/87u03P/P7f/7CB3ee+finf/wnP3XjRvOHf/D6n305PvXMHnsSrqOremoSla0KkQ+BwSRGCd4TiIoVRcHOxRgZVU0JiRgFVNQQgYDIMi0TErGpZBmYIQBmnDwDr0yZLgpEzQEAMauaqmaJ5Qk9VSvKUJfBVNertSQjolB4Jk69AhIwuODZu365BiTnvaggkgFUVWDvRDVp56EwQPJFXZWjUbN3ZbJo4yuvHz28P2u2mldffdiene1f3wqyvnZ160Mf2C+D80yOqWpG0yiOqPZ8cTH3virr+vzsrKyKUIXV4sRcGcijtpfL2NRh3XZ9u2ISpt7Belz7uFgxtUhmjGE0abt0uY5PfejW1/9Pszg+/le/9Jv/5l8cv/jjP/2Rlz72+NNPfeu1e+vO0AehYhlLgTqqQzbnHSBIUodoCAiEhCEUBAqGAEZkYHl5mTGjc4QAfdubgnfMBECkKaUomXSTmbILUTUEBDfERW7gzDJT1ey1VQYc0AdHhN26T9EAyHtmYolJojnP5DBUQZJ1XXKBkdQ5ZufMwEy7ddu2PRBLiKEoLYTSwXhUlkUAoMf3Zw8u27tHl6/3axkXvuSTe4uL5en5Il6/2uzujKqCQTVUVezjeMs4+PnFvGzKogxHxyfbu1dMbN12oQR26xrWNZZJllWFq8V58DYbY1odFa7vk/qy6rFA57SjN197eP3mtR/4mZ/4z7/0qymlf/3Ln/vkH7zysz//k+vkRuNy1berHoW8WAEuMLk+KhKrCpghKDMaGJKTlBBQRdAsOBKRlMRUiMExmgoimpqKeXYEGgFNzUCRCPPGObGcOYhIHs52ZmBJ8gbWrDKmZgYhkHecYkpREAjQiBgUUlRA8sEVRVDVxXwVNY6auqxC20uMUURi34ta7HtDSOeiRi6cumK0e+3K1avbPoSkMKsLvzeZ1T4wXK7Wx3uN9En6uBDjRVv15D0HQiUH5Iq68s5dXsxHW1MhXrdtVTciGrz13bxykRFKbjX1W422l0ekiVzvCDQ4IV+UzdWrOzH5da+K5ac+en331/7dv/+FX5Su/b+vnx/+29/61KefG+/ewHJXoUxYRCU2SEkUspEBRCViJogpLxgdaqKAoKaakqSEaKAiAsEx+9ADxK4DtSIwABBxDlhFTdUQEdEycRcoELEzU0lCSMRkGck1y8y+ABj7BNmHIzDkDfHoCx+CF5HVsu36vh5VVV32Kc4vLw2AiVTMVJkNEbSPsdf5xcV6KXffuT/a3pntX9m/trU7a6gKvWjsExNNR4WI61aImtYxRoEphF6FAcgVYgaOJluYknjPk3G1WKzRZDwez3XtIFJwJKlNqxpjWclquSZHbafFdBubnYS1Fk05KvsL/fqfnzaTnSeu7vyTX/nF//rL/6E9PZ73+PJrxzdjVU3Ija5YWaUkAomCZzA0ZQJmAjMANDMCYCQiABMz0NjHrkc0dmyGoGYAzOgcSo+xT6DqHDGTWOZmxhwsmRloXp9CADYggAO9nZmZIYBzjohiTJIkw+uECGqxFzD0zhHiqu1SlLqpQ+narrs4vxCVqikYse0SghUhmCpqqkuajblP1PYYdXl8L6El1GhIMQohFo7EMYJF1rJgEy2Y8hCnGhAAIiEmX5bWRo5xNKr6rkUwh8mRFpNCrZV23hTRuiVaPxqXAt6qQouJb7ZFvXC1Pa3rMd9/0L15p3vxmemHbxz8s1/655/97d87f+vdCGG+jELL4CagnUJgVgRFMO+cJ80zd0BEJpmuAyRzPSWJCUSR0RFhYBMzsdRHBHOeuhS7LiH4TJeWMiKIOPyrZmYZbs2xEwKiDR4CmDgXJyS34oBlFCQlRQB2zEyikmJiZnYkSfquQ4SyDsQQ+67tu6qqkbBdrUHUBzYTD70reB3j+fFhuzg7OblSVOXWzmTaFAZaOjT2dWhi36kAIqTUg0Llfdu2DoGcQzMmGDcVaKpKt7VVpRS1XxdNHYKDXiBQB6hSAnkOY3bjyI2FalRNXeF396azOty8rquewFzBfn8y+/G/+6OvvfLK0dt32BGFAlGRwIExG4KiI0JQA1FzDGTqCYkATfrYp74XEQRzTI4ZFIJ36LDv+3bVMyOiOceZgjPv8EYkACBCJDLTvNMaiRDNZU15pBSZhxMAVBVyByEhImpeQQ3oHDNT7GPsxXsE05gkqYbgk0RJCQnL0pUFp66Tviu8c0RtJ9r3ZcXeq99FDLiMF9DFtMZ5XKuZC4WZmKbY9wjinJOhoKhgOsCSYqCxGY9iuwZN09F43dkliaYoIHXhneMl43KZMEzVjYDrqmoEAnp/edl/4/T+jesTTrJe69l5PZuWs5pR6eruXhOK2PdRCKhgT70he0QitRz6K6EhgGdUxDzUmLpOUgJEduSdy+prADkwXfURwcrSe8eGaKK5M5kQc98MAuYaBjvOKNP7ksjoUy6mquaWQIRsGlVUFJGRyDGpaNdFU2Mm71wfEyEhMlhkdsGzmlhsLYp3VFdl8A6ld2XRNCHF5Y4PrirWHfRq7GNKyZAxqRoKiEcoioLQ2ijBB0RQVTN0Pqy7RQjOs/VA3jGhFqy3bu4a6unRIVMI1aic1DhfrzuOVkZlFIwqBF1wpEqHD87HBVWFR0ir+Up7bgI11cgEYuyTUlRSoEDeAA2AMU/JCaIxI4KklGIfU0qmhkTM5LzLhIAmEruEhcPsLFOSpKFgIMp8vwaQG/zABrZTZmbHgGZqDhEh7+7Idgqz4hjkdn5CADDVXOHwnpgpxSRJmNl5p2aactCmAMjEYBbbTlNickURnHcqmrrOl5y6uLhcsl+51bKLxsUIUotKoawMQjQrq5JB0IQ5R3uKChp7DjWjiaRRVTFhbFfjaUOIy8vzyaxpxtP1an05l/OH62ZWU7HlmBC8deKcL32IaqMqbE1HzAgaHSEAGWBwTlIP5HxRAzlWcEZRKIJDIiIDMIcAKmqiIlEhxT6lhIBE4IjZMQCKKACagoD2bc8IjkmB0UySEg7nSDg4ZQNAACLKO34RUEE2uBM80gra+HBAhKGOZHlKkghRVWKMYOA8IWIOc33hmFASalRD7dtYBu9D0CQpxn7ZpqhQ+SiWEqIlBfVATlsUKFyFFpMkdgVqwtQTM5HPQQupMIF3CKYWo+PGOy4CNaUL3vVr64KWDbtiVBPPj+YPj9ajrbIZl1Vdr9Y9OR+KEBMktbbtgvdt13vPqiJJm6pAsD6JgXlfqBqpJTU2Kb2LKRkCGagkk2SIBmqSGNQxmeUmpxzjIAAy5W0FKmBEmE1WvuM0tDxlX52bDQZa5uwTkgxcwBvzZIPATA0Jc91PbSA2QgQDizGpKBF4x2jWdz1SxkhyaC2I4F3hvDO1FEVNDKGaNBwYpK+bqqzYeU79mhEBTTVaMiavQohIkggRYk+qDilJDwK5t52dz6B9VYWq8qZQNuNQTy/O10mLg5sHB49x29vFZUvMVV0AEJh5zjzrFlNaJVl33YhCNrtt13mHSKCKbEORxiAygWnMyJypiiQwAWMzcURAACoImJG6nCiYGYI5wj6pqpLP1gFRzTLKlM8dMgO1AViOkkxMRUWiy9+R0zrYjMnj5g+AYbaYTESomkHCodYtkjKPAjGqikgizMTbmFuwRPIQFSTRtIyWekJTSNwnFQ2OmUFMHHkzk75FMxXJAENw3LetRkE0zrO0np1zpgnBEDlpdD64suqUU1JAj4jMVtXlYtW6qCJqIoSQoihY4UNRuNnIEZqZLdfiGEFTSiJJAA2J8w4yM1WEDGyCCmhCAALNNRvJY0CAhorIkHmlVcwUCfKqATQDI1RFyNIFQFADzAwHZpxxVsjsxynG5Ex1qNnlcDaLcBBKLqq+X73IipW1SFX6mBCBCcE0JQHISQpISoqAZnldS657gCSThISG5IARWTkAsoiCmloEIgQlAkLsu9iuOybyjieT2nsnXWRQZiTvO9C27bs+cT0KdcPlqD1rD0+WBuALR+QladeJqUkScxxT77yrChe8W6xWqsJMqHneFvNh5I6I3gRMiADBNBvlDDmAIjKImpmJqKHB0EuJA098os1lzpC3iqJtlmkNJsfyVUYwDozDzRYVUZEcOw3GZ+h9ymN3g2AffQFV9X0LlgETUcyNIGaSEiEyU3ZfkPFzJmRAMAJQNHBETOxcSmJiUQRAzaBmI+aBsUdiu7a+TwhYVmXhGQ0lRkT1wUNurAPokmKom6oORRmjbM3qpMbsQvAxRrDKDCnqKgIhVGUpZn0fV8vlYrFoRpWjkI9QEcEMIe8KEBUhMEYxyDaLzJJpIsxsvZkJEEVgGLY0EzURyWeWNYo2fZWDYcoBrA2jXLjxFqoIannWFAAcPDJjOGzfgiGUBTDIyURWiKHKmtES1bzjgBARLUWRJM4zIRqBEeVxfDPEPCSTZWlmRqnTvk9mCIih8KEoyAcD6NuujysgdN6qsshdV2CWUiyco9ztQPlmmS/LUFSrNvZxTt4DMhO1XVqsekQbEDpVJkDHJLparlR673BUujq4JMlSAmJiMgUEzMEaASRTNAITNEHjXMUkz1lSMakkAyDnmACTiKRkKkTGlA2Aqg4mOhsR3DjmHI3igO/l6SHNeRsAOHjkrDf+xDbFVBiangYwRAEoT+UhDCqbYXclFcnJaIp5rCGrDmYYK6WUedFzGGAGSJ6ZQvC+KACs7WK37mLfFXVVj2rHTvJUrwhn4A3BAJDIgNTM+QrJ9UlNrRUpyBtaktSu+q5Pzjt2xGg5CUXT2K1BuklT+MyN1bZiKGJF6WFYWg651Wh4bgQ0TSqAYJJMBdGZQUqaMwNmJiRTzWIwU5MNrJd5hyyv5FXcvOV8gYiIHeWPTdRywmxgpm7Y17ERxSCGIXqFIbfbRLpmQAibvgQEGDoQzIaaVEqimvd7gZoRopgpgJnlKsjQcAi5j4S6ro9dJzEBQDMZNeMGAGIfDZCYfY5ek+XSABKLIQApICEjoAF67/q+D0WoSx8cqWESQcS8objrOk196aEpaiKMMfZdBGByngMTYh/FVGkDCiEAgYEpIjoCU8HhYqkppZgAiXLDkiRJAqoECmgiopJlz1k0lnUNNN9pU8suOXcNIFj+mpqaqoG5waUM+OzGYdOjy5EDiPctXz7NnKwQkaSkSQAhE0eqaoyJjZlQBs3L5VUcouihuQQNoO361CdQ9cEVdVnVlan1fW+GLvgQHBFKjGaKxABkSKpomEc+CDIeoQJmfdebSC5MMmGGdCQlTT2Ceu9UNSWVpEyOXABiRJIkqU8q4kqvqiIKmUvViAgk4z9567NZEsk3bzDWkiwl1eQYmckEU5JNn35+bR6y26TMAMScI5pHkyoIpprjXHSZ3y7ff4MB+h3GTkENCC1Hv5btlqlmRDeTEZg9SgQ37nyo0FrmSht63HLxNssEM5AlWRVCETL1pIrEPplZUZbOMRKlFCVJ8A4o3yFQRFUAxLaLCECOB0cl2rbJOXbeoWmMIm1HYGDCOWoVNQPiAhiRWBQ0JRGNfXIOHWKMvaZ8KGoGpjjcYjMzk5TA0DSrvppINimgImYEjhCJyfJIb54HsmEwJTeSMTEz2UAf9x259EYyLh/QEMUCACg8ch0GAINKAb6vNzDYvWwMkYhykcPMCMk7p/p+uGagZia6+cVIjJbtGBj44Nk7JFKFFJMa+FAAsRhoTPmnKyJmuQ+wPaSUCBEADcE5TwiemcCQIIdfDhQgISI7NoCYNIkaUDarYCApqUpKYibMXiV2XZfVH0xUDBRSTGCqBpJU+ui8BxMVQMt4KjBayoi15UV+rKqaNJt3eHRU+T5SvusGOSfPYA4Y5MgKwA0oyAah2ngcePQd+djzSwevPqTvOYE3IlRFEVHVYXYVjBSMNKtzRnHzgg1CAkRVBUTnnS+CYwZDFVOD3Gc1iH9Y8ZK3LeRx/iExcoxEjABioCL5OYnQVLsYc/9pDuUloZolBTMUFTXFrCl9jwgqQmhokrpkMdnAyWFJEgJm7VDR2EcEe4TB5XFpU8PNe09RcvMAQg4as2O1jLw+SiZM1YaX5ysuKvIopnLfIbhNevcdpw8bYTxSqY2k0AyypULaaBi8X4eCRzlNTn6GJoYhAMgN0j6EzTQ4gAExEbnhUzDK8zbEiCxDpIdITDl/NBOAzTiCqRlCnnoSNdgE3pBE1QCBgDgmMUDEIWLJozyEkHpRURHJ712SpiSbxlTM3zkEVAAihhnmMM2SICSjIVnYmGuDnFUgUg6dhjjTBlzEBjGo6aODdfl0BljkUTqdpUrwPgbyviuwwUFskr6cLQzYyCOx2iYdAUJHG3ECIhIxUW4/Md0kKLlJHRBVdPgUiYgBUPMIhwERZTe9eRLNsVxMKSc3qgMcw0w5F04ywG6qssFQUSRh5jg3NYCoeXeu5k5tSWmTXqOZghrnRxncbm7wGnY8qA65lxlIUtzc41yqBgAlABhwOfsOmUh+ZhxgVjNz+FePGO0RcPudiNX7AlEzNMsISpaTyNCQYNlNZcG8/3cAzHOuMhSekHHofcuqg1lVTPNdyLAvmeXdSjZ0UQ80xvD+g5pGMREdLIJovkp5k71a3qVEqiZpmOrUFE0FNn4zSQ6RUC0nEzikF4M1NM6E6ESPwAxEJAAlVM3igOyrh99HG8huk4jluRWAXGhRQsynN1idzdm7bJc2gVV+QNwoyl/15vnd559hmg3PI9sGG1tGA6IJA/JktulO5yzb9580l2yzhODR787jaKiaLRCxywYaMqn3xnsB5IhadfATgMoEw/nqxkKCqaooqGVpm6lJyomN5j25hjr0URAiDXFPHgEdSjSGZiaQ8Z5NaESIZjrElI9KC7aBiHCToxEaImV13fxf5ucaMuXsuJ3pxgjmEzQA0CHQ1Hz98g0EpI0Fy1ZIzXDjD/CRzuRZ8M3zZUmCEubkCTZPiRtLuAnLBrVDeN88ig0tFGgb55EzbcTsGkAH0CUnTKqiCCBD1mpmIGaSREQJKatrhtsyopySIDwKBBDBgOyR5VPVXMrJim6bFr73z31zq3KYT0RgCgq2OcBHpmSAqwBUFRFMJZuN3NUBaAb4/wGEq2pOcsrSMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=131x131 at 0x7FA5CA60E290>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featviz_in_recep_field(deepcopy(sparse_circuits['left']),layer,0,margin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afa8deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_pruner.utils import plot_iou_from_masks\n",
    "iou_fig = plot_iou_from_masks(sparse_masks['front'],sparse_masks['right'])\n",
    "#iou_fig.update_layout(height = 700,width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14534a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "tozeroy",
         "line": {
          "color": "#4C78A8"
         },
         "marker": {
          "size": 20
         },
         "type": "scatter",
         "x": [
          "1",
          "2",
          "3",
          "4"
         ],
         "y": [
          0.9947368502616882,
          0.8562138676643372,
          0.6877380013465881,
          0.8374999761581421
         ]
        }
       ],
       "layout": {
        "font": {
         "size": 60
        },
        "height": 1500,
        "margin": {
         "b": 100,
         "l": 100,
         "r": 100,
         "t": 100
        },
        "paper_bgcolor": "rgba(255,255,255,1)",
        "plot_bgcolor": "rgba(255,255,255,1)",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1500,
        "xaxis": {
         "title": {
          "text": "Layer"
         }
        },
        "yaxis": {
         "range": [
          0,
          1
         ],
         "title": {
          "text": "IoU"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"4169dd72-f7a6-4074-9c42-b761b365706f\" class=\"plotly-graph-div\" style=\"height:1500px; width:1500px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4169dd72-f7a6-4074-9c42-b761b365706f\")) {                    Plotly.newPlot(                        \"4169dd72-f7a6-4074-9c42-b761b365706f\",                        [{\"fill\": \"tozeroy\", \"line\": {\"color\": \"#4C78A8\"}, \"marker\": {\"size\": 20}, \"type\": \"scatter\", \"x\": [\"1\", \"2\", \"3\", \"4\"], \"y\": [0.9947368502616882, 0.8562138676643372, 0.6877380013465881, 0.8374999761581421]}],                        {\"font\": {\"size\": 60}, \"height\": 1500, \"margin\": {\"b\": 100, \"l\": 100, \"r\": 100, \"t\": 100}, \"paper_bgcolor\": \"rgba(255,255,255,1)\", \"plot_bgcolor\": \"rgba(255,255,255,1)\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 1500, \"xaxis\": {\"title\": {\"text\": \"Layer\"}}, \"yaxis\": {\"range\": [0, 1], \"title\": {\"text\": \"IoU\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4169dd72-f7a6-4074-9c42-b761b365706f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from circuit_pruner.visualizer.layouts import big_fig_layout\n",
    "\n",
    "iou_fig.update_layout(big_fig_layout)\n",
    "#fig.update_layout({ 'width':3000})\n",
    "\n",
    "\n",
    "iou_fig.update_layout({\n",
    "                    'height':1500,\n",
    "                    'width':1500,\n",
    "                    'font':{'size':60}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "769dc7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_fig.write_html(\"plots/faces_frontright_iou_big.html\")\n",
    "iou_fig.write_image(\"plots/face_frontright_iou_big.svg\")\n",
    "iou_fig.write_image(\"plots/face_frontright_iou_big.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4437b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd2a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e043821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2b9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e92d5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23c405da",
   "metadata": {},
   "source": [
    "##### Generate left and right profile folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b7d1eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "root_dir = '/mnt/data/chris/dropbox/Research-Hamblin/Projects/circuit_pruner_cvpr2022/image_data/faces/'\n",
    "\n",
    "profile_images = os.listdir(root_dir+'profile/')\n",
    "\n",
    "for im_name in profile_images:\n",
    "    im = Image.open(root_dir+'profile/'+im_name)\n",
    "    direction = im_name.split('.')[0][-1]\n",
    "    if direction == 'l':\n",
    "        l_im = im\n",
    "        r_im = im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        l_im_name = im_name\n",
    "        r_im_name = im_name.replace('l','r')\n",
    "    else:\n",
    "        r_im = im\n",
    "        l_im = im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        r_im_name = im_name\n",
    "        l_im_name = im_name.replace('r','l')\n",
    "\n",
    "    r_im.save(root_dir+'right/'+r_im_name)\n",
    "    l_im.save(root_dir+'left/'+l_im_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuit_pruner",
   "language": "python",
   "name": "circuit_pruner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
